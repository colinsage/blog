---
title: influxdb-compress
date: 2018-05-28 16:22:29
tags:
---

## 前言
influxdb里持续化数据的文件是tsm格式，上篇有说明，这篇重点说说这个文件里涉及的压缩算法。
其中压缩的部分是data block部分。influxdb数据模型里的field_value支持float, int， uint, bool,
string等类型，针对每种类型都有对应的压缩方式。时间戳没有像beringei那样和value混合起来一起压缩，
而且单独进行压缩存储。因此一共有6种场景的压缩方式。
每个block都是包含三部分时间戳压缩后的字节数组长度，时间戳压缩后的字节数组，field_value压缩后的字节数组。

## 时间戳的压缩
beringei的时间戳压缩主要思路是计算出delta-of-delta的值D, 然后不同值预范围的值用对应的bit前缀+最少的bit的
D。具体要点如下：
1. Header存储起始时间戳T0
2. 第1个时间戳用14bit存储delta值:T1-T0
3. 从第2个到最后一个存储delta-of-delta值D: (Tn - Tn-1) - (Tn-1 - Tn-2)
4. 如果D==0， 用1个bit 0 来存储表示
5. 如果D∈[-63,64], 用'10' + 7bit的D来存储
6. 如果D∈[-255,256], 用'110' + 9bit的D来存储
7. 如果D∈[-2047,2048], 用'1110' + 12bit的D来存储
8. 如果是其它值，用用'1111' + 32bit的D来存储

influxdb里的时间戳压缩，思路是先对一组时间戳进行统计分析，然后根据统计结果进行相应的编码。
统计结果包括4个部分，时间戳的delta值数组，delta的最大值，delta间的最大公约数，是否全相等。
### RLE (run-length encode)
如果delta全相等，则进行RLE压缩。具体压缩方式如下:
  + 第1个字节前4bit，置为'0010',表示压缩类型
  + 第1个字节后4bit，表示最大公约数以10为底的对数
  + 接着8个字节，表示第一个时间戳
  + 接着1-8个字节，表示第1个delta值与公约数的除结果
  + 接着1-8字节，表示重复的delta个数
如果有1000个时间戳，delta为1000000000且全相等（单位ns，此处delta为1s），最大公约数1000000000，则
一共需要1+8+4+2=14个字节，112bit。  如果是beringei，一共需要64+14+999=1077bit。这种场景下，
influxdb的RLE压缩方式更优。

### Raw Pack
如果delta的最大值大于1152921504606846975，则不进行压缩，直接打包原始值。具体方式如下：
  + 第1个字节前4bit，置为'0000',表示当前压缩类型。
  + 后面每个8个字节保存1个时间戳

### Simple8b Pack
其它情况，对delta数组再使用simple8b压缩后存储，具体方式如下:
  + 第1个字节前4bit，置为'0001',表示当前压缩类型。
  + 第1个字节后4bit，表示最大公约数以10为底的对数
  + 接着8个字节，表示第一个时间戳
  + 接着对delta数据使用simple8b压缩后的字节数组。如果最大公约数大于1，可以把delta数组里的
  每个数除以最大公约数后再压缩，这样使用的bit位会更少一些。

simple8b的思路是，把多个整数打包存在64bit里。
+ 支持16种打包类型，
+ 64bit的前4bit表示打包类型
+ 后面60bit用来存放对应类型可放入的整数。
例如[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 25] 这个整数数组一共12数，最大的数是25，需要至少用
5bit来表示。 60/5=12 刚好可以保持12个整数。 具体编码如下：
```
0110，高4bit， 对应第6个打包类型。
11001，倒数第1个数，十进制25。使用逆序存放数据。
01011，倒数第2个数
01010，倒数第3个数
01001，倒数第4个数
01000，倒数第5个数
00111，倒数第6个数
00110，倒数第7个数
00101，倒数第8个数
00100，倒数第9个数
00011，倒数第10个数
00010，倒数第11个数
00001，倒数第12个数

最终的整数10进制为7830995874016792000，16进制为6cad4941cc520c00
```
从上面可以，simple8b对于值比较小且波动不大的整数压缩较好。如果波动比较大会浪费比较多的bit位。

如果有1000个时间戳，其中998个delta为1000000000，中间两个连续点出现波动两个分别是
1500000000,500000000.最大公约数是500000000，一共需要1+8+4*8+8+8=57字节, 457bit。
使用beringei需要64+997+36*2=1133bit

### 小结
1. influxdb支持的时间戳精度到纳秒，实际中很少用到这么高的精度。如果最低精度到s，可以把时间戳对齐
到秒，秒之后的值清零，以提高压缩率。
2. 当时间戳的delta大部分相同的情况下，influxdb的压缩效果要优于beringei

## Int的压缩
由于metric的value部分，可以是正数，也可以是负数。而负数高位bit是1，不便于压缩。使用ZigZag编码
可以把负数转成正数。对正数，将它乘以2；对负数，将它的数值乘2减1
```
64位整数的zigzag编码公式是： uint64(uint64(x<<1)^uint64((int64(x) >> 63)))

```
编码后的整数压缩与时间戳压缩类似，分别使用了RLE, RawPack, Simple8b Pack. 不再赘述

无符号整数与整数压缩方式完全相同，只是存储的block类型不同。

## Float压缩
对于浮点数的压缩，beringei里使用了XOR编码， influxdb使用了一样的方式。具体要点如下：
+ 第1个数不压缩，使用64bit
+ 第二个数开始，与前一个数进行异或，然后统计结果数，非0位前面是0bit的个数（LZ)，非零bit后面0bit的个数(TZ)，
中间非0bit的个数(MB)。
+ 如果异或后的结果为0，则存储'0'，占用1个bit
+ 如果异或后的结果不为0，按下面结果存储
  - 如果LZ和TZ与前一个值的完全一样，存储 '10'+ 中间非0bit
  - 如果LZ和TZ与前一个值不一样，存储'11',接着5个bit存储LZ，6个bit存储MB，最后存储中间非0bit。

```
假设有3个浮点数，二进制形式如下：
01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)
01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)
01000000 00101100 01100110 01100110 01100110 01100110 01100110 01100110  (14.2)

中间结果
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000100 01100110 01100110 01100110 01100110 01100110 01100110

压缩结果
01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000
0
11 01101 110010 100 01100110 01100110 01100110 01100110 01100110 0110011
```
对于有大量0bit的浮点数，这种方式可以有效减少存储位。

## Boolean压缩
influxdb支持boolean类型的value值，它的压缩思路就是用每个bit表示1个boolean值。
+ 每8个bit，即1个字节作为一个单元。
+ 每编码一个boolean值，先把当前字节往左移1位，后面补0
+ 如果被编码的boolean为true，再把最后1bit置为1

```
原始值: true, false, false, false, true, true, true, false
编码后结果: 10001110
```

## String 压缩
对于string类型的value，编码过程如下：
+ 对于每个值，先在编码器的buf里保存value的长度(UvarInt)
+ 保存原始的字符串
+ 遍历完成后，对所有buf里是数据，使用snappy的方式压缩

### Snappy压缩
  snappy在LZ77基础上发展而来的。lz77的压缩思路是，建立一个滑动窗口，分成两个部分，搜索缓冲区
和待编码区。编码器遍历待编码区，从搜索缓冲区找到最大匹配字符串，然后输出(offset, length).
offset是当前位置距离匹配字符串的偏移量，length是匹配字符串的长度。 zlib在LZ77基础上，
再对LZ77的结果进行huffman编码，以此来提高压缩率。

   snappy改进了查找匹配字符串的方式。它设计了一个map，key是4字节整数的hash值，value是待压缩字节数组
对应整数的index。压缩编码没有了滑动窗口，但是还是要从之前的数据中找到匹配字符串。先计算当位置4个
字节整数的hash值，使用这个hash值到map里可以找到相同的hash值的值位置。然后比较两个位置的原始值是否相等
如果相等，说明找到开头匹配的字符串，然后继续匹配后续字符串，直到找到最大匹配。如果不相等，index往后
移1位，继续计算4字节整数的hash。

   从上面可以看出，snappy在查找匹配字符串上结合hash表快了不少。并且总是与最近相同字符串的匹配，
有可能匹配的不是最大匹配。 snappy有自己的结果编码方式，没有huffman编码。因此snappy相比zlib，
压缩更快,但是压缩率要稍低一点。

## 小结
   对于时序数据的压缩，针对每种数据类型无论是压缩率还是计算量肯定还有更有更好的方式。
这需要对现有数据进行统计分析，找出隐藏的规律。压缩算法的选择上也不能只追求压缩率，
数据在不同的位置应该有不同的压缩策略，在压缩率和性能上取一个合适的平衡。
在内存的数据，更高吞吐的压缩算法可能更合适；在落盘的历史数据，更高的压缩率可能更合适。

## references
[ZIP压缩算法详细分析及解压实例解释](http://www.cnblogs.com/esingchan/p/3958962.html)
