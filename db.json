{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/fexo/source/css/styles.css","path":"css/styles.css","modified":1,"renderable":1},{"_id":"themes/fexo/source/images/avatar.jpg","path":"images/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.eot","path":"fonts/PoiretOne-Regular.eot","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.ttf","path":"fonts/PoiretOne-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.woff","path":"fonts/PoiretOne-Regular.woff","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.eot","path":"fonts/calligraffitti-regular-webfont.eot","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.woff","path":"fonts/calligraffitti-regular-webfont.woff","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.eot","path":"fonts/fontello.eot","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.woff2","path":"fonts/calligraffitti-regular-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.ttf","path":"fonts/fontello.ttf","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.woff","path":"fonts/fontello.woff","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.svg","path":"fonts/fontello.svg","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/fontello.woff2","path":"fonts/fontello.woff2","modified":1,"renderable":1},{"_id":"themes/fexo/source/js/app.js","path":"js/app.js","modified":1,"renderable":1},{"_id":"themes/fexo/source/js/scroll-spy.js","path":"js/scroll-spy.js","modified":1,"renderable":1},{"_id":"themes/fexo/source/js/bundle.js","path":"js/bundle.js","modified":1,"renderable":1},{"_id":"themes/fexo/source/js/fastclick.js","path":"js/fastclick.js","modified":1,"renderable":1},{"_id":"themes/fexo/source/js/util.js","path":"js/util.js","modified":1,"renderable":1},{"_id":"themes/fexo/source/js/zenscroll.js","path":"js/zenscroll.js","modified":1,"renderable":1},{"_id":"themes/fexo/source/css/styles.css.map","path":"css/styles.css.map","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.ttf","path":"fonts/calligraffitti-regular-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.svg","path":"fonts/PoiretOne-Regular.svg","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.svg","path":"fonts/calligraffitti-regular-webfont.svg","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/Lobster-Regular.eot","path":"fonts/Lobster-Regular.eot","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/Lobster-Regular.ttf","path":"fonts/Lobster-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/Lobster-Regular.woff","path":"fonts/Lobster-Regular.woff","modified":1,"renderable":1},{"_id":"themes/fexo/source/fonts/Lobster-Regular.svg","path":"fonts/Lobster-Regular.svg","modified":1,"renderable":1},{"_id":"themes/maupassant/source/css/donate.css","path":"css/donate.css","modified":1,"renderable":1},{"_id":"themes/maupassant/source/css/default.css","path":"css/default.css","modified":1,"renderable":1},{"_id":"themes/maupassant/source/donate/index.html","path":"donate/index.html","modified":1,"renderable":1},{"_id":"themes/maupassant/source/css/style.scss","path":"css/style.scss","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/alipay.svg","path":"img/alipay.svg","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/AliPayQR.png","path":"img/AliPayQR.png","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/BTCQR.png","path":"img/BTCQR.png","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/github.svg","path":"img/github.svg","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/WeChatQR.png","path":"img/WeChatQR.png","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/wechat.svg","path":"img/wechat.svg","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/bitcoin.svg","path":"img/bitcoin.svg","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/paypal.svg","path":"img/paypal.svg","modified":1,"renderable":1},{"_id":"themes/maupassant/source/js/codeblock-resizer.js","path":"js/codeblock-resizer.js","modified":1,"renderable":1},{"_id":"themes/maupassant/source/img/like.svg","path":"img/like.svg","modified":1,"renderable":1},{"_id":"themes/maupassant/source/js/donate.js","path":"js/donate.js","modified":1,"renderable":1},{"_id":"themes/maupassant/source/js/fancybox.js","path":"js/fancybox.js","modified":1,"renderable":1},{"_id":"themes/maupassant/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/maupassant/source/js/smartresize.js","path":"js/smartresize.js","modified":1,"renderable":1},{"_id":"themes/maupassant/source/js/totop.js","path":"js/totop.js","modified":1,"renderable":1},{"_id":"themes/maupassant/source/js/share.js","path":"js/share.js","modified":1,"renderable":1},{"_id":"themes/maupassant/source/js/gitment.browser.js","path":"js/gitment.browser.js","modified":1,"renderable":1}],"Cache":[{"_id":"themes/fexo/LICENSE","hash":"db4cb5aef6072a96721b5428fdd999647c049d55","modified":1519726591337},{"_id":"themes/fexo/.csscomb.json","hash":"0bff596879c2556634b9a92abe5b1606dc77fd1c","modified":1519726591354},{"_id":"themes/fexo/README.md","hash":"35cd346c229e17ed83609ee94b5d6493c4ab9982","modified":1519726591388},{"_id":"themes/fexo/.gitignore","hash":"32223fbe296f8e3026c689bad8f3dea9d0fcbb43","modified":1519726591389},{"_id":"themes/fexo/_config.yml","hash":"db46d61222498f82ee0f4a7ae41cef46e4eb6bdc","modified":1519727280220},{"_id":"themes/fexo/gulpfile.js","hash":"5995b9c4e8e18d1670ad30b2881d49fa17e56415","modified":1519726591390},{"_id":"themes/fexo/package.json","hash":"38850a4aa4a01c697bdf2bed87709fe0c8c3fe69","modified":1519726591390},{"_id":"source/_posts/2017-10-18-influxdb-stress.md","hash":"350b5da23895e1b57edd052ac47adc980e0bab2a","modified":1519722310567},{"_id":"source/_posts/2017-10-18-misc.md","hash":"7b50a0bd83927fea991e958d4fe305d13a593252","modified":1519722310568},{"_id":"source/_posts/2017-10-19-influxdb-read.md","hash":"5625d1508b792d4856948b1ca6add93916b8a21a","modified":1536115652582},{"_id":"source/_posts/2017-10-27-misc.md","hash":"382bd97278175e4e94d51a6140927092b696cb7a","modified":1519722310572},{"_id":"source/_posts/2017-10-19-influxdb-write.md","hash":"51c55857c0c55f0e292485c7b958e166972495d5","modified":1519722310570},{"_id":"source/_posts/2017-11-01-influxdb-cluster.md","hash":"eea90e8caba02dc0b5c911a7cb8e863fdd4dfcce","modified":1523937601777},{"_id":"source/_posts/2017-11-13-misc.md","hash":"75e152d2bc8ae655a10e29007cd3ed0b573df1f2","modified":1527126651699},{"_id":"source/_posts/2017-11-17-tsdb-requirements.md","hash":"0a8939c2ac09ca8a2358312b26286e07f19343ef","modified":1529402776993},{"_id":"source/_posts/2018-02-28-tips.md","hash":"21e552b12608ca44711d1b640e1009bea64f10e1","modified":1529918322465},{"_id":"source/_posts/2017-11-27-raft.md","hash":"bac109b192afeacd4083bfaf9b8df7e4171adb4c","modified":1519722310573},{"_id":"source/_posts/2017-12-04-influxdb-http.md","hash":"52c801ef2ca6dde15981a8d6dee6bd77b4315283","modified":1519722310573},{"_id":"source/_posts/2018-02-27-influxdb-monitor.md","hash":"7b6e9d5c0eeb8a3c32b660ec98d231b19fe11ea4","modified":1520326142068},{"_id":"source/_posts/2018-02-28-tsdb-references.md","hash":"14be473ab51e297138b6aeacbef831be89662444","modified":1533898927018},{"_id":"source/_posts/2018-03-20-grpc-go.md","hash":"bc0a585711013d489a8f4b319a9724f3482e909c","modified":1527064523211},{"_id":"source/_posts/2018-05-22-influxdb.md","hash":"867bc62e7360eb1d278a10ac48ed10744bd3b2b2","modified":1526960685861},{"_id":"source/_posts/2018-05-28-influxdb-compress.md","hash":"4334e032d3aaec05cc1dac4a94b31dbc5aa79806","modified":1531131727260},{"_id":"source/_posts/2018-06-06-think.md","hash":"21740a14f62b10abb74ca1c677af75d256276397","modified":1528886698135},{"_id":"source/_posts/2018-06-15-monitor-control.md","hash":"4335ffb90fbc64038d8389b79fb4515e5bbbec6d","modified":1529056768158},{"_id":"source/_posts/2018-08-01-etcd.md","hash":"d0e462763a29a9466d94b27e4cdc84cef47b4de9","modified":1534211460032},{"_id":"themes/fexo/.git/config","hash":"78a9f656fdfea85aaa63de99ef0857e7149d11d2","modified":1519726591391},{"_id":"themes/fexo/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1519726591395},{"_id":"themes/fexo/.git/index","hash":"f4f6d5ec502a156437464be8c0224c0a139409c9","modified":1519727042986},{"_id":"themes/fexo/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1519726591400},{"_id":"themes/fexo/.git/packed-refs","hash":"e60e09c9e808d873c989a4576d804f0fe946859c","modified":1519726591408},{"_id":"themes/fexo/languages/default.yml","hash":"1a6762d52295b0f7586f40c35e713c0fd33c2a2b","modified":1519726591387},{"_id":"themes/fexo/languages/en.yml","hash":"b58364c7dfac61eddd64510f74ca7516da48f0cf","modified":1519726591387},{"_id":"themes/fexo/languages/no.yml","hash":"bf11017d77f64fbafb9c99ac219d076b20d53afc","modified":1519726591388},{"_id":"themes/fexo/languages/zh-CN.yml","hash":"1a6762d52295b0f7586f40c35e713c0fd33c2a2b","modified":1519726591388},{"_id":"themes/fexo/languages/zh-TW.yml","hash":"6141b4c7a094c74bd9df7c08908d92b561c1a0c0","modified":1519726591387},{"_id":"themes/fexo/layout/about.ejs","hash":"f1f06842f3fac2c7dd74811722431c5720e6cf8d","modified":1519726591340},{"_id":"themes/fexo/layout/archive.ejs","hash":"9c22251c328e937c444a9f5d4b324f97a78d324f","modified":1519726591339},{"_id":"themes/fexo/layout/category.ejs","hash":"e8c8209f74ac0c96c29dbdff38d0f43664417342","modified":1519726591338},{"_id":"themes/fexo/package-lock.json","hash":"96cbc6874ae373b7ebd91a8b2a5166e7502514fa","modified":1519726591389},{"_id":"themes/fexo/layout/index.ejs","hash":"9d33cd03e7a8adf8bbc124c248def36c15e681d0","modified":1519726591338},{"_id":"themes/fexo/layout/layout.ejs","hash":"ae485be0f6c0c431245e0cac21dc109c9d0125e8","modified":1519726591340},{"_id":"themes/fexo/layout/link.ejs","hash":"0144bdb1bc5f19763535b79b3302bf85bc0afbff","modified":1519726591338},{"_id":"themes/fexo/layout/post.ejs","hash":"8cf15be489f8f3c11ac0215c16cbce36c854555f","modified":1519726591338},{"_id":"themes/fexo/layout/project.ejs","hash":"ea63f5ffda0d260b5dc2c2e852caddd082e37efa","modified":1519726591340},{"_id":"themes/fexo/layout/search.ejs","hash":"8c6fc59bed1facf14dd6a48bdf8dd44452583f4d","modified":1519726591339},{"_id":"themes/fexo/layout/tag.ejs","hash":"ea8f39f11e6f8750edbf4130abf26168a403b1b4","modified":1519726591339},{"_id":"source/_posts/2017-10-19-influx-write/mip-20171019150351540.png","hash":"e404354721e95bf53c7a36a165b9fb18277afc93","modified":1519722310572},{"_id":"themes/fexo/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1519726591402},{"_id":"themes/fexo/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1519726591401},{"_id":"themes/fexo/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1519726591403},{"_id":"themes/fexo/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1519726591404},{"_id":"themes/fexo/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1519726591402},{"_id":"themes/fexo/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1519726591404},{"_id":"themes/fexo/.git/hooks/pre-rebase.sample","hash":"18be3eb275c1decd3614e139f5a311b75f1b0ab8","modified":1519726591402},{"_id":"themes/fexo/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1519726591403},{"_id":"themes/fexo/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1519726591403},{"_id":"themes/fexo/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1519726591405},{"_id":"themes/fexo/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1519726591396},{"_id":"themes/fexo/.git/logs/HEAD","hash":"8db114670998832ee5b57a27065b6d8916f6057c","modified":1519726591397},{"_id":"themes/fexo/source/css/styles.css","hash":"edda7b8f56586203f06fb0fb1cce0f6707a7f234","modified":1519726591356},{"_id":"themes/fexo/source/images/avatar.jpg","hash":"06b315b1cde634d2313044a83c40b1ac10961134","modified":1519726591357},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.eot","hash":"2a4ef0d00fb77d16e37c3da429698b029e7d2d2f","modified":1519726591360},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.ttf","hash":"2b186ce205301f7f3abd441f0372b72adcd2aee3","modified":1519726591363},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.woff","hash":"1cebcedde2c52261591bc322b176638798336a24","modified":1519726591365},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.eot","hash":"4c7bcece73621f648fa71d58fa13c28670fed8ca","modified":1519726591361},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.woff","hash":"1364845a3815740c572e29c83fd8d54f1c1ef5de","modified":1519726591360},{"_id":"themes/fexo/source/fonts/fontello.eot","hash":"7732065eeaec4614e9548955d9bd30ccd7b149c1","modified":1519726591363},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.woff2","hash":"ba50c427166090361b0dab4c72136c7b451e86d4","modified":1519726591364},{"_id":"themes/fexo/source/fonts/fontello.ttf","hash":"e255d37ca14348e9a8532667a757ab552e58caff","modified":1519726591361},{"_id":"themes/fexo/source/fonts/fontello.woff","hash":"45737fea847f3942ef405f00ea4df940fbb6bbd9","modified":1519726591362},{"_id":"themes/fexo/source/fonts/fontello.svg","hash":"33a984f4482a5ba5e7bc67d82e8db63cda4e3ae1","modified":1519726591366},{"_id":"themes/fexo/source/fonts/fontello.woff2","hash":"1dfbc23328582f7cd9bcbe538224f6c762023e43","modified":1519726591367},{"_id":"themes/fexo/source/js/app.js","hash":"a6d6e7fba3d69d0dec2c4d18debe0dc4cc7ab319","modified":1519726591359},{"_id":"themes/fexo/source/js/scroll-spy.js","hash":"81b81362fcd63592045a673b54ce1edb7a6e3028","modified":1519726591359},{"_id":"themes/fexo/source/js/bundle.js","hash":"fe2b6d4fbc32c78cd9868fb3b75ad71cf5250f24","modified":1519726591358},{"_id":"themes/fexo/source/js/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1519726591359},{"_id":"themes/fexo/source/js/util.js","hash":"8136da2bec1faf5fe3e14fa436f501292fca8c07","modified":1519726591357},{"_id":"themes/fexo/source/js/zenscroll.js","hash":"bea2a3571555fdae64e8fc56f161f9a4f427b335","modified":1519726591358},{"_id":"themes/fexo/source/sass/_base.scss","hash":"83f01dbe82e47ce781c6e7eb8a793d95d97e168b","modified":1519726591386},{"_id":"themes/fexo/source/sass/_fonts.scss","hash":"10e188d379782ae2ee10427544919557036d0137","modified":1519726591368},{"_id":"themes/fexo/source/sass/_animate.scss","hash":"8de97c948cb4b9c9b7a87c0f7332ed534c378e26","modified":1519726591380},{"_id":"themes/fexo/source/sass/_common.scss","hash":"b1fc97d6d24a92a9a7a9d39be4fe844f5c0f6d44","modified":1519726591379},{"_id":"themes/fexo/source/sass/_fontello.scss","hash":"f2d6b86bb63459884cf63e8c045fd10c827396eb","modified":1519726591386},{"_id":"themes/fexo/source/sass/_highlight-js.scss","hash":"38a5c4d9f3a2943aff9bde1d624d710587e3bc05","modified":1519726591379},{"_id":"themes/fexo/source/sass/_normalize.scss","hash":"e58275a588bb631a37a2988145eea231ed23176b","modified":1519726591385},{"_id":"themes/fexo/source/sass/_styles.scss","hash":"86ebe05d6a2931dd6fceef1e50c31ca996dc20be","modified":1519726591368},{"_id":"themes/fexo/source/sass/_type.scss","hash":"cc7a25654593030f5214d5adf85f12a954c373c5","modified":1519726591385},{"_id":"themes/fexo/source/sass/_variable.scss","hash":"7b05581ef035a88bd1191914ff992103c7812bdf","modified":1519726591380},{"_id":"themes/fexo/layout/_partial/article.ejs","hash":"745f11c21dcf5d01f4aad3818777fc62e45d2f84","modified":1519726591354},{"_id":"themes/fexo/layout/_partial/baidu-push.ejs","hash":"6950255d74efac8811d5b05d0d7a263c3c96486d","modified":1519726591353},{"_id":"themes/fexo/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1519726591341},{"_id":"themes/fexo/layout/_partial/baidu-analytics.ejs","hash":"c19e4abec19c23840fff7f8a51f4aefbb2b7e8ca","modified":1519726591352},{"_id":"themes/fexo/layout/_partial/load-script.ejs","hash":"4675c917548817118f4a3c5d84acc98d6c61a1d8","modified":1519726591353},{"_id":"themes/fexo/layout/_partial/style.ejs","hash":"d1e80d7cf8b22929f5c6d8590eac38b069ea055d","modified":1519726591354},{"_id":"themes/fexo/layout/_partial/head.ejs","hash":"794916e761ea82fb606a2173af68e9bf524f6efb","modified":1519726591352},{"_id":"themes/fexo/layout/_partial/home.ejs","hash":"225b8a001c7aace46f2b39676e968e7cba9a4277","modified":1519726591352},{"_id":"source/_posts/2017-10-19-influx-read/mip-2017101919283058.png","hash":"5b0695dca7e2f82c7e2a76ed1a4a1f640a1ec7a2","modified":1519722310569},{"_id":"themes/fexo/source/css/styles.css.map","hash":"dd689c0ab08f3e7923ede7fab9a193c63f253d90","modified":1519726591356},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.ttf","hash":"4688935c427ae40dcbf16523bc11d9fc10e359b5","modified":1519726591362},{"_id":"themes/fexo/source/sass/pages/_tag.scss","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1519726591382},{"_id":"themes/fexo/.git/refs/heads/master","hash":"834e14ffb65857cd32c5784ce5214e923e1583cc","modified":1519726591406},{"_id":"themes/fexo/source/fonts/PoiretOne-Regular.svg","hash":"e21109783f218cb7849b12e867e0b775ce3fadda","modified":1519726591367},{"_id":"themes/fexo/source/fonts/calligraffitti-regular-webfont.svg","hash":"76e1e4cee6f2b5d596c635631938ee5eb6ab3e67","modified":1519726591367},{"_id":"themes/fexo/source/sass/pages/_about.scss","hash":"7d61e627ea5376390081e0b93db426ffc6c4dee8","modified":1519726591382},{"_id":"themes/fexo/source/sass/pages/_archive.scss","hash":"fefd54282a42ebb68b711f1cfefa1f67abbde05b","modified":1519726591382},{"_id":"themes/fexo/source/sass/pages/_category.scss","hash":"713242d10c0c8687c9e2f287f1beeb38de6cdbad","modified":1519726591381},{"_id":"themes/fexo/source/sass/pages/_home.scss","hash":"b65bb069ed28fbf223c5bb7e760882f79d20fa46","modified":1519726591384},{"_id":"themes/fexo/source/sass/pages/_link.scss","hash":"d3a249423c7ee88d1cb3a12e03f6c42a0a4d45a1","modified":1519726591384},{"_id":"themes/fexo/source/sass/pages/_index.scss","hash":"d9fe73a87585abad06a7dd77b67ec7ce6c24402c","modified":1519726591381},{"_id":"themes/fexo/source/sass/pages/_project.scss","hash":"cab0947fc9d7926a07badaa567803cc7a0968f10","modified":1519726591383},{"_id":"themes/fexo/source/sass/pages/_post.scss","hash":"c6f694568af362f9fe1e7e2b9909e47303178116","modified":1519726591384},{"_id":"themes/fexo/source/sass/pages/_search.scss","hash":"fd28f01829628c9d21f9391d5067ddcd836dad13","modified":1519726591383},{"_id":"themes/fexo/source/sass/component/_back-top.scss","hash":"1c67da7007f4b9d8c65deea3d82c0f579e65f2c2","modified":1519726591373},{"_id":"themes/fexo/source/sass/component/_category-box.scss","hash":"a807145b74d1b98270ea19ae35edd25b4c448bfa","modified":1519726591371},{"_id":"themes/fexo/source/sass/component/_comments.scss","hash":"3e9b61bc08f38f947f54e942986a19a7f95ce723","modified":1519726591376},{"_id":"themes/fexo/source/sass/component/_donation.scss","hash":"75102b0e6e4ef0a674f04fc8996c8f7ad058143d","modified":1519726591371},{"_id":"themes/fexo/source/sass/component/_index.scss","hash":"a741a0bfb47d0acdef12cdeb968c104bb002f86d","modified":1519726591369},{"_id":"themes/fexo/source/sass/component/_item-category-name.scss","hash":"119840d160cd263b57e79e2099a81079d7eeee3d","modified":1519726591374},{"_id":"themes/fexo/source/sass/component/_hint.scss","hash":"2812b4e10313168f2e082b740c60d64a151d94c8","modified":1519726591371},{"_id":"themes/fexo/source/sass/component/_item-post.scss","hash":"1fb2e9be2d2edbb538cfbce7c80d5847f88e2f05","modified":1519726591377},{"_id":"themes/fexo/source/sass/component/_item-title.scss","hash":"cdaca2858abc9428ef01103a7fbea8f095d856aa","modified":1519726591375},{"_id":"themes/fexo/source/sass/component/_item-year.scss","hash":"12c147dd4ab9587cd622083c86c2f6cf07d8e26a","modified":1519726591372},{"_id":"themes/fexo/source/sass/component/_list-post.scss","hash":"43564f6443385bf34e15672d1477d1c7560f5563","modified":1519726591377},{"_id":"themes/fexo/source/sass/component/_modal.scss","hash":"2f0ed96df388ec28445b1ce5c6a61a0a697f9a68","modified":1519726591378},{"_id":"themes/fexo/source/sass/component/_page-header.scss","hash":"893d0595ef48323dce449ef0d17308ce02b36087","modified":1519726591370},{"_id":"themes/fexo/source/sass/component/_pagination.scss","hash":"12c1880c518aee2e3ccf59661d01c308639f8a9e","modified":1519726591376},{"_id":"themes/fexo/source/sass/component/_table.scss","hash":"4899fb31d1be8d5c9c397fcbcfc2ff0c5b2e7f7f","modified":1519726591373},{"_id":"themes/fexo/source/sass/component/_prev-net.scss","hash":"1d282b3302e222adbc96a259f69d85afed980bcf","modified":1519726591369},{"_id":"themes/fexo/source/sass/component/_toc.scss","hash":"3b4c083cb2ba4a88ca35b6d8259ee991c83b3406","modified":1519726591372},{"_id":"themes/fexo/source/sass/component/_toolbox-mobile.scss","hash":"f15b215b9bb103ee1773a01d8badd81bb7643710","modified":1519726591377},{"_id":"themes/fexo/source/sass/component/_tag-box.scss","hash":"7601951d09a75a7c39493bfa1b1da5ac989d9cda","modified":1519726591378},{"_id":"themes/fexo/source/sass/component/_toolbox.scss","hash":"964a480d4e7fad100463195cde2a3f67f9765c23","modified":1519726591370},{"_id":"themes/fexo/layout/_partial/component/back-top.ejs","hash":"47f2b8306b901f0fffc6aa0cfa40db697a0c5aff","modified":1519726591351},{"_id":"themes/fexo/layout/_partial/component/changyan.ejs","hash":"a5f39aa1ee2f213324889ba05b5f99eaabf13fc9","modified":1519726591341},{"_id":"themes/fexo/layout/_partial/component/category.ejs","hash":"2429158ff177b8876de765498b54d0c91b3fc551","modified":1519726591343},{"_id":"themes/fexo/layout/_partial/component/disqus.ejs","hash":"21de7498d235a52337335108fce7446e1a21ea1c","modified":1519726591342},{"_id":"themes/fexo/layout/_partial/component/donation.ejs","hash":"d5b7f72e008d764f5b5fb13ba6ac7adb8bc0a3e8","modified":1519726591351},{"_id":"themes/fexo/layout/_partial/component/category-box.ejs","hash":"f18e08e5c8718d5cd6672fc01e25ba457db0a385","modified":1519726591346},{"_id":"themes/fexo/layout/_partial/component/date.ejs","hash":"163fbd874481cb9e2b6da5282701a3fbaa4e367a","modified":1519726591348},{"_id":"themes/fexo/layout/_partial/component/comments.ejs","hash":"8d719cdeeda9d5ab5fbfb5f302fc6edd5bb684b8","modified":1519726591347},{"_id":"themes/fexo/layout/_partial/component/gitalk.ejs","hash":"37ccc1b114d6fc83c1d47fe7b931d42899f7325f","modified":1519726591341},{"_id":"themes/fexo/layout/_partial/component/gentie.ejs","hash":"9b78a138fb93a71b481ab25c8dea2e082e5e9d6c","modified":1519726591347},{"_id":"themes/fexo/layout/_partial/component/gitment.ejs","hash":"cf48268f8b8b0f5a5de6c3d4cf0def9917d5f32d","modified":1519726591349},{"_id":"themes/fexo/layout/_partial/component/item-category-name.ejs","hash":"8ab52c9b5d5db1d3c1d343ecb405c4e15cd144ac","modified":1519726591342},{"_id":"themes/fexo/layout/_partial/component/hypercomments.ejs","hash":"321339582edb1dd9c4e4ca13108fe494d08494fc","modified":1519726591351},{"_id":"themes/fexo/layout/_partial/component/item-tag.ejs","hash":"1b4c4e090c33ccfd44b531a5de9af16eec266512","modified":1519726591344},{"_id":"themes/fexo/layout/_partial/component/item-year.ejs","hash":"906a6aea44a30e83c4c4e449294c7e4d831c188e","modified":1519726591347},{"_id":"themes/fexo/layout/_partial/component/item-post.ejs","hash":"722e5dbde2d4683eea08f2af922358db45b253b1","modified":1519726591345},{"_id":"themes/fexo/layout/_partial/component/page-header.ejs","hash":"14bad32082d87d7eeb45c0e9079e72f0ae65dbf4","modified":1519726591349},{"_id":"themes/fexo/layout/_partial/component/modal.ejs","hash":"8edceb2fd6c770691bd5cf4a35236c1def8410fe","modified":1519726591350},{"_id":"themes/fexo/layout/_partial/component/prev-net.ejs","hash":"d1cb2e61814bcbd25ccb1628f99b18316e029892","modified":1519726591342},{"_id":"themes/fexo/layout/_partial/component/pagination.ejs","hash":"ffbb548aee6e15cae924ee7f922f28b2403e8e45","modified":1519726591343},{"_id":"themes/fexo/layout/_partial/component/title.ejs","hash":"e2fcdd904123186648513cfca4c7ad04921d2d57","modified":1519726591344},{"_id":"themes/fexo/layout/_partial/component/tag-box.ejs","hash":"d648ea91ec9dc72bca80d70fbb66f7655bd0ea12","modified":1519726591346},{"_id":"themes/fexo/layout/_partial/component/tag-list.ejs","hash":"8535c40b573744ced738b051383c0feca80eb0e9","modified":1519726591344},{"_id":"themes/fexo/layout/_partial/component/toc.ejs","hash":"000be428e925f5595af29eeba37ba6111f7f6511","modified":1519726591349},{"_id":"themes/fexo/layout/_partial/component/toolbox.ejs","hash":"fcfcccc5b231c4050f1a665b70f7738f9d070541","modified":1519726591348},{"_id":"themes/fexo/layout/_partial/component/uyan.ejs","hash":"afe757c6f45d24640b22d90db6f2799000c6f994","modified":1519726591350},{"_id":"themes/fexo/layout/_partial/component/valine.ejs","hash":"3cbf565937f31001c901e451677e7adbe228bfe6","modified":1519726591345},{"_id":"themes/fexo/.git/objects/pack/pack-07a5c30209c819fe5958d4df94aaca9b263cd242.idx","hash":"604b3fab89b89d9c6a17ee9caf74f6ec39475847","modified":1519726591395},{"_id":"themes/fexo/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1519726591407},{"_id":"themes/fexo/.git/logs/refs/heads/master","hash":"8db114670998832ee5b57a27065b6d8916f6057c","modified":1519726591399},{"_id":"themes/fexo/.git/logs/refs/remotes/origin/HEAD","hash":"8db114670998832ee5b57a27065b6d8916f6057c","modified":1519726591400},{"_id":"themes/fexo/source/fonts/Lobster-Regular.eot","hash":"4f0c85f63beb0d95610317e16f1d4acdd2962eee","modified":1519726591365},{"_id":"themes/fexo/source/fonts/Lobster-Regular.ttf","hash":"50a84291b7012bfdcf9ff5116d6c7aa3f257f37f","modified":1519726591366},{"_id":"themes/fexo/source/fonts/Lobster-Regular.woff","hash":"298b80b1c9f694e1a055d62a5d809863c89baf50","modified":1519726591362},{"_id":"themes/fexo/source/fonts/Lobster-Regular.svg","hash":"be1cab622c673942fb4d11a23c012227938b4792","modified":1519726591364},{"_id":"themes/fexo/.git/objects/pack/pack-07a5c30209c819fe5958d4df94aaca9b263cd242.pack","hash":"ae98c19ba6f0213ccb19f1c149832d2eaf67a979","modified":1519726591394},{"_id":"themes/maupassant/.travis.yml","hash":"0339959f29deddc365e8fe8bd85da524410b9a23","modified":1536131583135},{"_id":"themes/maupassant/LICENSE","hash":"f0ac2f92770650c9835183f79010c0d307b34acd","modified":1536131583135},{"_id":"themes/maupassant/README.md","hash":"a3dcfa9b646980ee5811ec03b4c5786618b85ff9","modified":1536131583136},{"_id":"themes/maupassant/_config.yml","hash":"d67293dac1559afd76219b5a9c7e5a006e1f9346","modified":1536131583137},{"_id":"themes/maupassant/package.json","hash":"f092433469eb87362e831326425a6a5c3c9fea0d","modified":1536131583148},{"_id":"themes/maupassant/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1536131583129},{"_id":"themes/maupassant/.git/config","hash":"037345b11c41abb3dbbbd6e0242ced24979a7097","modified":1536131583131},{"_id":"themes/maupassant/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1536131578656},{"_id":"themes/maupassant/.git/index","hash":"45d51ef9c3793d3064aa7e0a4dcd2e76f377d2d4","modified":1536131583162},{"_id":"themes/maupassant/.git/packed-refs","hash":"af879af1afdc3423352746eef12e7698c689fa99","modified":1536131583125},{"_id":"themes/maupassant/languages/de-DE.yml","hash":"5d3556a885e355a8c2da65ef3e7b3ee36a628bfa","modified":1536131583138},{"_id":"themes/maupassant/languages/en.yml","hash":"c3fb5c155560a00889a75882c680afe1197ebf1a","modified":1536131583138},{"_id":"themes/maupassant/languages/es-ES.yml","hash":"58e1d04bcd1834fa9d2960e18e027abbbccbedc9","modified":1536131583138},{"_id":"themes/maupassant/languages/fr-FR.yml","hash":"b47906ec0abf867fb3e3360bc046b7afb68aee25","modified":1536131583139},{"_id":"themes/maupassant/languages/ko.yml","hash":"909a33e0befa6978e8e72157c6b415b48551ee31","modified":1536131583139},{"_id":"themes/maupassant/languages/zh-CN.yml","hash":"710b204e637c18b86ac7c681f7d1cf8dfeddf4bb","modified":1536131583140},{"_id":"themes/maupassant/languages/ru.yml","hash":"2476a631f4d3c668de04af85a6c2c97ba2a57e96","modified":1536131583140},{"_id":"themes/maupassant/languages/zh-TW.yml","hash":"bf3ab970f2ab3f29ddeb9f59bf98163be635e284","modified":1536131583140},{"_id":"themes/maupassant/layout/archive.pug","hash":"665582bb4092fcd81bfaf4d08fc1689abee1e6c4","modified":1536131583146},{"_id":"themes/maupassant/layout/base.pug","hash":"a4e32bcb580b76af9ad0582d9d3f0107e34509ed","modified":1536131583146},{"_id":"themes/maupassant/layout/index.pug","hash":"0435a4e5f5c6976e05b3079d335453c246f5ba6e","modified":1536131583147},{"_id":"themes/maupassant/layout/base-without-sidebar.pug","hash":"16c4d1079450f801b5ac079d3cc101856d8f387c","modified":1536131583146},{"_id":"themes/maupassant/layout/page.pug","hash":"8cfd307b13cad8be34a1e75c4566f96c1722e08e","modified":1536131583147},{"_id":"themes/maupassant/layout/post.pug","hash":"ead043c9083507b919f5c504b89a50f90d928e57","modified":1536131583147},{"_id":"themes/maupassant/layout/timeline.pug","hash":"84fbfc92ccdf291b491140d89557553141a5d3f9","modified":1536131583147},{"_id":"themes/maupassant/layout/single-column.pug","hash":"0593f261dc208bb0b5c4232eb41eff597a291bd9","modified":1536131583147},{"_id":"themes/maupassant/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1536131578658},{"_id":"themes/maupassant/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1536131578657},{"_id":"themes/maupassant/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1536131578659},{"_id":"themes/maupassant/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1536131578659},{"_id":"themes/maupassant/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1536131578657},{"_id":"themes/maupassant/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1536131578659},{"_id":"themes/maupassant/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1536131578658},{"_id":"themes/maupassant/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1536131578659},{"_id":"themes/maupassant/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1536131578657},{"_id":"themes/maupassant/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1536131578660},{"_id":"themes/maupassant/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1536131578655},{"_id":"themes/maupassant/.git/logs/HEAD","hash":"cf8568b4c9364e63d5a68d755cb18c6dd62f8b03","modified":1536131583130},{"_id":"themes/maupassant/layout/_partial/after_footer.pug","hash":"bf5e24891d18c19b31ef7887cd22ae2a74f9ad4b","modified":1536131583141},{"_id":"themes/maupassant/layout/_partial/footer.pug","hash":"650781b5bc8c632658ad6880ba663b1e3bfb5798","modified":1536131583142},{"_id":"themes/maupassant/layout/_partial/comments.pug","hash":"69fa52eac8dfcf8073db7e540a4b0e87f41654f6","modified":1536131583141},{"_id":"themes/maupassant/layout/_partial/head.pug","hash":"e672914a8451b269c1033cd8c55e026beb3a9135","modified":1536131583142},{"_id":"themes/maupassant/layout/_partial/helpers.pug","hash":"acdf9e2d52ee86c831fa15ce1570930c5779bc78","modified":1536131583142},{"_id":"themes/maupassant/layout/_partial/mathjax.pug","hash":"e3a5e2d44ac261e3168a0b10e968f9a57bc5a237","modified":1536131583142},{"_id":"themes/maupassant/layout/_partial/paginator.pug","hash":"53f9cb77448e84a98da5eb688e2e12b173c555bb","modified":1536131583143},{"_id":"themes/maupassant/layout/_partial/mathjax2.pug","hash":"75cfa2cda3ff0681d03bbe89326818b824e5e524","modified":1536131583143},{"_id":"themes/maupassant/layout/_partial/post_nav.pug","hash":"a2d698c84bb6da08195fe870dbd7215f65388d3f","modified":1536131583143},{"_id":"themes/maupassant/layout/_partial/tag.pug","hash":"0f0e6770e9d5dd8040e330d71bbbfadd2df36a28","modified":1536131583144},{"_id":"themes/maupassant/layout/_partial/totop.pug","hash":"8225bbc3cdb9648bc2e6872e5c616a9a1e4def4f","modified":1536131583144},{"_id":"themes/maupassant/layout/_partial/wordcount.pug","hash":"004c8a3edc19d428179b83a0f97eae3c1a6d3cfa","modified":1536131583144},{"_id":"themes/maupassant/layout/_widget/links.pug","hash":"c45aa7ec00158579e58f1f8dfd890447bb5e5e54","modified":1536131583145},{"_id":"themes/maupassant/layout/_widget/recent_comments.pug","hash":"4102d446f13b02ff617f055c2a8f726bca12744a","modified":1536131583145},{"_id":"themes/maupassant/layout/_widget/recent_posts.pug","hash":"19431336d724d2118e46da43683bce9063176541","modified":1536131583145},{"_id":"themes/maupassant/layout/_widget/search.pug","hash":"6e8e4123cca38840c4607c1a056205972b82bb7b","modified":1536131583145},{"_id":"themes/maupassant/layout/_widget/tag.pug","hash":"132f049ce677d0e38f50073174c4ee4b825d4a06","modified":1536131583146},{"_id":"themes/maupassant/layout/_widget/category.pug","hash":"7c6aed762934ca51aa2669b886254da24b77bc14","modified":1536131583144},{"_id":"themes/maupassant/source/css/donate.css","hash":"f019876946aeb80e567ece250d54c1327c794583","modified":1536131583149},{"_id":"themes/maupassant/source/css/default.css","hash":"7fbb18b73b44ed11193739c55fce53a6f173cf68","modified":1536131583149},{"_id":"themes/maupassant/source/donate/index.html","hash":"bd5cbe475b7bce89a8c96375c56c8e3e188d6afc","modified":1536131583150},{"_id":"themes/maupassant/source/css/style.scss","hash":"b44da192f0875e144bf7990a99b42e31e986e099","modified":1536131583150},{"_id":"themes/maupassant/source/img/alipay.svg","hash":"46cc0552a9f6d700d618db3fcad25e1b8e697e36","modified":1536131583153},{"_id":"themes/maupassant/source/img/AliPayQR.png","hash":"7787b5d91cbf0e19a1260df24f7d949771c7d45b","modified":1536131583151},{"_id":"themes/maupassant/source/img/BTCQR.png","hash":"7d1c80f953bfb6f0a37d432b04c936ea165bfd97","modified":1536131583153},{"_id":"themes/maupassant/source/img/github.svg","hash":"90ba9a3b0dc19e70e742a39b014194f801e00f97","modified":1536131583154},{"_id":"themes/maupassant/source/img/WeChatQR.png","hash":"8c41aca7883e5ff714c56556f5fff8e7e7c38093","modified":1536131583153},{"_id":"themes/maupassant/source/img/wechat.svg","hash":"330496ad42446a29f37a2b97fc388ebd77a8cb9f","modified":1536131583156},{"_id":"themes/maupassant/source/img/bitcoin.svg","hash":"635f7cca5e675d192be2717788175c7a2146013a","modified":1536131583154},{"_id":"themes/maupassant/source/img/paypal.svg","hash":"92f3bc495f20a0190d3041be03345c46d6238c25","modified":1536131583156},{"_id":"themes/maupassant/source/js/codeblock-resizer.js","hash":"5d0b786d60bf225d9eabcc9cece2719ff4d9b6cd","modified":1536131583157},{"_id":"themes/maupassant/source/img/like.svg","hash":"22a2754dc454d7b0321b70914fb2936b8d2ea8ab","modified":1536131583156},{"_id":"themes/maupassant/source/js/donate.js","hash":"780beaaf44b1e6c057752bdbc085b1048937e5e7","modified":1536131583157},{"_id":"themes/maupassant/source/js/fancybox.js","hash":"13c4781570339f4fba76a3d7f202e442817dd605","modified":1536131583158},{"_id":"themes/maupassant/source/js/search.js","hash":"0c0630e2ef213701d393b041f10572e951a27985","modified":1536131583160},{"_id":"themes/maupassant/source/js/smartresize.js","hash":"3ef157fd877167e3290f42c67a624ea375a46c24","modified":1536131583161},{"_id":"themes/maupassant/source/js/totop.js","hash":"7dbf8fcf582a4fb6eb9b2c60d6de9f9c2091ec4c","modified":1536131583161},{"_id":"themes/maupassant/source/js/share.js","hash":"a2f9de374523dc7f2ddb90ed5f24b668c20d9272","modified":1536131583161},{"_id":"themes/maupassant/.git/refs/heads/master","hash":"e5c0f939055304f017fc7686e2a02d268d7efe87","modified":1536131583129},{"_id":"themes/maupassant/.git/objects/pack/pack-51e8c1926f960dc64f9865427c3a3d53bc7d0696.idx","hash":"0fd09319cf5b7b86f0659aef9f66b3fe6f5886e2","modified":1536131583115},{"_id":"themes/maupassant/source/js/gitment.browser.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1536131583159},{"_id":"themes/maupassant/.git/logs/refs/heads/master","hash":"cf8568b4c9364e63d5a68d755cb18c6dd62f8b03","modified":1536131583130},{"_id":"themes/maupassant/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1536131583128},{"_id":"themes/maupassant/.git/logs/refs/remotes/origin/HEAD","hash":"cf8568b4c9364e63d5a68d755cb18c6dd62f8b03","modified":1536131583128},{"_id":"themes/maupassant/.git/objects/pack/pack-51e8c1926f960dc64f9865427c3a3d53bc7d0696.pack","hash":"728f2ab1e468e7109e22e1c899ba8b93fa1e91cb","modified":1536131583114}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"influx_stress造数据令人困惑的问题","date":"2017-10-18T12:47:59.000Z","_content":"\n## 1.简介\n  influx_stress是influxdb社区版里的一个命令。主要功能是可以解析一个脚本文件，然后执行里面的动作，包括造数据，写db，读db。\n从而对单机版进行读写压力测试。 目前有两个版本，其中v2性能更好一点。下面主要讨论v2版本存在的问题。\n\n## 2.造数据  \n### 2.1 问题    \n以下是官方文档的节选\n\n```\nYou can write points like this:\n\nINSERT mockCpu\ncpu,\nhost=server-[int inc(0) 100],location=[east|sourth|west|north]\nvalue=[float rand(1000) 0]\n100000 10s\n\nExplained:\n\n# INSERT keyword kicks off the statement, next to it is the name of the statement for reporting and templated query generation\nINSERT mockCpu\n# Measurement\ncpu,\n# Tags - separated by commas. Tag values can be templates, mixed template and fixed values\nhost=server-[float rand(100) 100],location=[int inc(0) 10],fixed=[fix|fid|dor|pom|another_tag_value]\n# Fields - separated by commas either templates, mixed template and fixed values\nvalue=[float inc(0) 0]\n# 'Timestamp' - Number of points to insert into this measurement and the amount of time between points\n100000 10s\n```  \n其中tags, fields支持模板，可以按照模板中的表达式生成对应的值。\n最后一行的100000， 表示制造的总数据量。\n看到文档， 想当然的以为插入的数据有100000行。实际执行select count后发现并不是这样， 上面这个例子最终只有25000行数据可以查询到。\n和预期的差太多了， 好奇怪。  \n\n翻了代码发现，在解析的过程中把每个模板表达式解析成1个模板函数。 例子有三个，两个tag和一个field。它是如何使用的呢？\n1. 根据tags的配置， 理论上应该有400个timeseries，因此会把100000分成250时间点。 每个时间点的数据时间戳相同， 包含400条数据。\n这个还是符合预期的。\n2. 生成每个时间点单个timeserie的数据，可以理解成db里的一行数据。依次调用模板函数，每个函数内部有个计数。当超过上限后恢复成1.\n例如location=[east|sourth|west|north]，计数器是4，循环依次输出里面字符串。\n3. 对于1行数据，调用了2次模板函数，每个的计数器都加1. 前面100行的tag组合都不一样，但是第101行开始host的计数器又恢复到1，location的计数器也恢复到1. 这样按计划产生的400行数据，只有100行的tags组合是不一样的。\n4. influxdb查询事会把相同时间戳，tags的数据进行去重。上例中，某个时间戳查询结果只有100行结果。\n5. 总共会产生250个时间点。那么100*250=25000就是最后返回的查询结果。\n\n### 2.2 解决\n  理解了里面运行机制， 那么可以只用1个tag， 那么生成与查询的结果就符合预期了。但是这样使用场景就太局限了。\n因此还是有必要修改一下代码，让生成的数据符合预期。应该是400个timeseries，那就生成400个不同的timeseries。\n怎么做呢？\n1. 加个计数器，每产生1行数据加1\n2. 计数器与series_count取模，得到当前series编号s_n\n3. 从左往右，依次根据s_n，(s_n - 1)计算出当前tag模板函数的计数.\n4. 如果有变化，则调用模板函数，其他tag使用上次生成的值，退出循环，结束此次模板替换。\n5. 如果无变化，继续根据s_n，(s_n - 1)计算右边下一个tag的计数，判断是否有变化。\n6. s_n计算当前模板函数计数的方式：  \n<img src=\"http://chart.googleapis.com/chart?cht=tx&chl=c=[s_n mod  (n_{i} * n_{i-1} * \\cdots * n_1 )] / (n_{i-1} * n_{i-2} * \\cdots * n_1 )\" style=\"border:none;\">\n\n改动点：\n+ ./stress/v2/statement/insert.go\n+ ./influxdb/stress/v2/statement/function.go\n","source":"_posts/2017-10-18-influxdb-stress.md","raw":"---\ntitle: influx_stress造数据令人困惑的问题\ndate: 2017-10-18 20:47:59\ntags:\n- influxdb\n- tsdb\n---\n\n## 1.简介\n  influx_stress是influxdb社区版里的一个命令。主要功能是可以解析一个脚本文件，然后执行里面的动作，包括造数据，写db，读db。\n从而对单机版进行读写压力测试。 目前有两个版本，其中v2性能更好一点。下面主要讨论v2版本存在的问题。\n\n## 2.造数据  \n### 2.1 问题    \n以下是官方文档的节选\n\n```\nYou can write points like this:\n\nINSERT mockCpu\ncpu,\nhost=server-[int inc(0) 100],location=[east|sourth|west|north]\nvalue=[float rand(1000) 0]\n100000 10s\n\nExplained:\n\n# INSERT keyword kicks off the statement, next to it is the name of the statement for reporting and templated query generation\nINSERT mockCpu\n# Measurement\ncpu,\n# Tags - separated by commas. Tag values can be templates, mixed template and fixed values\nhost=server-[float rand(100) 100],location=[int inc(0) 10],fixed=[fix|fid|dor|pom|another_tag_value]\n# Fields - separated by commas either templates, mixed template and fixed values\nvalue=[float inc(0) 0]\n# 'Timestamp' - Number of points to insert into this measurement and the amount of time between points\n100000 10s\n```  \n其中tags, fields支持模板，可以按照模板中的表达式生成对应的值。\n最后一行的100000， 表示制造的总数据量。\n看到文档， 想当然的以为插入的数据有100000行。实际执行select count后发现并不是这样， 上面这个例子最终只有25000行数据可以查询到。\n和预期的差太多了， 好奇怪。  \n\n翻了代码发现，在解析的过程中把每个模板表达式解析成1个模板函数。 例子有三个，两个tag和一个field。它是如何使用的呢？\n1. 根据tags的配置， 理论上应该有400个timeseries，因此会把100000分成250时间点。 每个时间点的数据时间戳相同， 包含400条数据。\n这个还是符合预期的。\n2. 生成每个时间点单个timeserie的数据，可以理解成db里的一行数据。依次调用模板函数，每个函数内部有个计数。当超过上限后恢复成1.\n例如location=[east|sourth|west|north]，计数器是4，循环依次输出里面字符串。\n3. 对于1行数据，调用了2次模板函数，每个的计数器都加1. 前面100行的tag组合都不一样，但是第101行开始host的计数器又恢复到1，location的计数器也恢复到1. 这样按计划产生的400行数据，只有100行的tags组合是不一样的。\n4. influxdb查询事会把相同时间戳，tags的数据进行去重。上例中，某个时间戳查询结果只有100行结果。\n5. 总共会产生250个时间点。那么100*250=25000就是最后返回的查询结果。\n\n### 2.2 解决\n  理解了里面运行机制， 那么可以只用1个tag， 那么生成与查询的结果就符合预期了。但是这样使用场景就太局限了。\n因此还是有必要修改一下代码，让生成的数据符合预期。应该是400个timeseries，那就生成400个不同的timeseries。\n怎么做呢？\n1. 加个计数器，每产生1行数据加1\n2. 计数器与series_count取模，得到当前series编号s_n\n3. 从左往右，依次根据s_n，(s_n - 1)计算出当前tag模板函数的计数.\n4. 如果有变化，则调用模板函数，其他tag使用上次生成的值，退出循环，结束此次模板替换。\n5. 如果无变化，继续根据s_n，(s_n - 1)计算右边下一个tag的计数，判断是否有变化。\n6. s_n计算当前模板函数计数的方式：  \n<img src=\"http://chart.googleapis.com/chart?cht=tx&chl=c=[s_n mod  (n_{i} * n_{i-1} * \\cdots * n_1 )] / (n_{i-1} * n_{i-2} * \\cdots * n_1 )\" style=\"border:none;\">\n\n改动点：\n+ ./stress/v2/statement/insert.go\n+ ./influxdb/stress/v2/statement/function.go\n","slug":"influxdb-stress","published":1,"updated":"2018-02-27T09:05:10.567Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0z400003l659ktqtof7","content":"<h2 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1.简介\"></a>1.简介</h2><p>  influx_stress是influxdb社区版里的一个命令。主要功能是可以解析一个脚本文件，然后执行里面的动作，包括造数据，写db，读db。<br>从而对单机版进行读写压力测试。 目前有两个版本，其中v2性能更好一点。下面主要讨论v2版本存在的问题。</p>\n<h2 id=\"2-造数据\"><a href=\"#2-造数据\" class=\"headerlink\" title=\"2.造数据\"></a>2.造数据</h2><h3 id=\"2-1-问题\"><a href=\"#2-1-问题\" class=\"headerlink\" title=\"2.1 问题\"></a>2.1 问题</h3><p>以下是官方文档的节选</p>\n<pre><code>You can write points like this:\n\nINSERT mockCpu\ncpu,\nhost=server-[int inc(0) 100],location=[east|sourth|west|north]\nvalue=[float rand(1000) 0]\n100000 10s\n\nExplained:\n\n# INSERT keyword kicks off the statement, next to it is the name of the statement for reporting and templated query generation\nINSERT mockCpu\n# Measurement\ncpu,\n# Tags - separated by commas. Tag values can be templates, mixed template and fixed values\nhost=server-[float rand(100) 100],location=[int inc(0) 10],fixed=[fix|fid|dor|pom|another_tag_value]\n# Fields - separated by commas either templates, mixed template and fixed values\nvalue=[float inc(0) 0]\n# &apos;Timestamp&apos; - Number of points to insert into this measurement and the amount of time between points\n100000 10s\n</code></pre><p>其中tags, fields支持模板，可以按照模板中的表达式生成对应的值。<br>最后一行的100000， 表示制造的总数据量。<br>看到文档， 想当然的以为插入的数据有100000行。实际执行select count后发现并不是这样， 上面这个例子最终只有25000行数据可以查询到。<br>和预期的差太多了， 好奇怪。  </p>\n<p>翻了代码发现，在解析的过程中把每个模板表达式解析成1个模板函数。 例子有三个，两个tag和一个field。它是如何使用的呢？</p>\n<ol>\n<li>根据tags的配置， 理论上应该有400个timeseries，因此会把100000分成250时间点。 每个时间点的数据时间戳相同， 包含400条数据。<br>这个还是符合预期的。</li>\n<li>生成每个时间点单个timeserie的数据，可以理解成db里的一行数据。依次调用模板函数，每个函数内部有个计数。当超过上限后恢复成1.<br>例如location=[east|sourth|west|north]，计数器是4，循环依次输出里面字符串。</li>\n<li>对于1行数据，调用了2次模板函数，每个的计数器都加1. 前面100行的tag组合都不一样，但是第101行开始host的计数器又恢复到1，location的计数器也恢复到1. 这样按计划产生的400行数据，只有100行的tags组合是不一样的。</li>\n<li>influxdb查询事会把相同时间戳，tags的数据进行去重。上例中，某个时间戳查询结果只有100行结果。</li>\n<li>总共会产生250个时间点。那么100*250=25000就是最后返回的查询结果。</li>\n</ol>\n<h3 id=\"2-2-解决\"><a href=\"#2-2-解决\" class=\"headerlink\" title=\"2.2 解决\"></a>2.2 解决</h3><p>  理解了里面运行机制， 那么可以只用1个tag， 那么生成与查询的结果就符合预期了。但是这样使用场景就太局限了。<br>因此还是有必要修改一下代码，让生成的数据符合预期。应该是400个timeseries，那就生成400个不同的timeseries。<br>怎么做呢？</p>\n<ol>\n<li>加个计数器，每产生1行数据加1</li>\n<li>计数器与series_count取模，得到当前series编号s_n</li>\n<li>从左往右，依次根据s_n，(s_n - 1)计算出当前tag模板函数的计数.</li>\n<li>如果有变化，则调用模板函数，其他tag使用上次生成的值，退出循环，结束此次模板替换。</li>\n<li>如果无变化，继续根据s_n，(s_n - 1)计算右边下一个tag的计数，判断是否有变化。</li>\n<li>s_n计算当前模板函数计数的方式：<br><img src=\"http://chart.googleapis.com/chart?cht=tx&chl=c=[s_n mod  (n_{i} * n_{i-1} * \\cdots * n_1 )] / (n_{i-1} * n_{i-2} * \\cdots * n_1 )\" style=\"border:none;\"></li>\n</ol>\n<p>改动点：</p>\n<ul>\n<li>./stress/v2/statement/insert.go</li>\n<li>./influxdb/stress/v2/statement/function.go</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1.简介\"></a>1.简介</h2><p>  influx_stress是influxdb社区版里的一个命令。主要功能是可以解析一个脚本文件，然后执行里面的动作，包括造数据，写db，读db。<br>从而对单机版进行读写压力测试。 目前有两个版本，其中v2性能更好一点。下面主要讨论v2版本存在的问题。</p>\n<h2 id=\"2-造数据\"><a href=\"#2-造数据\" class=\"headerlink\" title=\"2.造数据\"></a>2.造数据</h2><h3 id=\"2-1-问题\"><a href=\"#2-1-问题\" class=\"headerlink\" title=\"2.1 问题\"></a>2.1 问题</h3><p>以下是官方文档的节选</p>\n<pre><code>You can write points like this:\n\nINSERT mockCpu\ncpu,\nhost=server-[int inc(0) 100],location=[east|sourth|west|north]\nvalue=[float rand(1000) 0]\n100000 10s\n\nExplained:\n\n# INSERT keyword kicks off the statement, next to it is the name of the statement for reporting and templated query generation\nINSERT mockCpu\n# Measurement\ncpu,\n# Tags - separated by commas. Tag values can be templates, mixed template and fixed values\nhost=server-[float rand(100) 100],location=[int inc(0) 10],fixed=[fix|fid|dor|pom|another_tag_value]\n# Fields - separated by commas either templates, mixed template and fixed values\nvalue=[float inc(0) 0]\n# &apos;Timestamp&apos; - Number of points to insert into this measurement and the amount of time between points\n100000 10s\n</code></pre><p>其中tags, fields支持模板，可以按照模板中的表达式生成对应的值。<br>最后一行的100000， 表示制造的总数据量。<br>看到文档， 想当然的以为插入的数据有100000行。实际执行select count后发现并不是这样， 上面这个例子最终只有25000行数据可以查询到。<br>和预期的差太多了， 好奇怪。  </p>\n<p>翻了代码发现，在解析的过程中把每个模板表达式解析成1个模板函数。 例子有三个，两个tag和一个field。它是如何使用的呢？</p>\n<ol>\n<li>根据tags的配置， 理论上应该有400个timeseries，因此会把100000分成250时间点。 每个时间点的数据时间戳相同， 包含400条数据。<br>这个还是符合预期的。</li>\n<li>生成每个时间点单个timeserie的数据，可以理解成db里的一行数据。依次调用模板函数，每个函数内部有个计数。当超过上限后恢复成1.<br>例如location=[east|sourth|west|north]，计数器是4，循环依次输出里面字符串。</li>\n<li>对于1行数据，调用了2次模板函数，每个的计数器都加1. 前面100行的tag组合都不一样，但是第101行开始host的计数器又恢复到1，location的计数器也恢复到1. 这样按计划产生的400行数据，只有100行的tags组合是不一样的。</li>\n<li>influxdb查询事会把相同时间戳，tags的数据进行去重。上例中，某个时间戳查询结果只有100行结果。</li>\n<li>总共会产生250个时间点。那么100*250=25000就是最后返回的查询结果。</li>\n</ol>\n<h3 id=\"2-2-解决\"><a href=\"#2-2-解决\" class=\"headerlink\" title=\"2.2 解决\"></a>2.2 解决</h3><p>  理解了里面运行机制， 那么可以只用1个tag， 那么生成与查询的结果就符合预期了。但是这样使用场景就太局限了。<br>因此还是有必要修改一下代码，让生成的数据符合预期。应该是400个timeseries，那就生成400个不同的timeseries。<br>怎么做呢？</p>\n<ol>\n<li>加个计数器，每产生1行数据加1</li>\n<li>计数器与series_count取模，得到当前series编号s_n</li>\n<li>从左往右，依次根据s_n，(s_n - 1)计算出当前tag模板函数的计数.</li>\n<li>如果有变化，则调用模板函数，其他tag使用上次生成的值，退出循环，结束此次模板替换。</li>\n<li>如果无变化，继续根据s_n，(s_n - 1)计算右边下一个tag的计数，判断是否有变化。</li>\n<li>s_n计算当前模板函数计数的方式：<br><img src=\"http://chart.googleapis.com/chart?cht=tx&chl=c=[s_n mod  (n_{i} * n_{i-1} * \\cdots * n_1 )] / (n_{i-1} * n_{i-2} * \\cdots * n_1 )\" style=\"border:none;\"></li>\n</ol>\n<p>改动点：</p>\n<ul>\n<li>./stress/v2/statement/insert.go</li>\n<li>./influxdb/stress/v2/statement/function.go</li>\n</ul>\n"},{"title":"20171018-misc","date":"2017-10-18T09:02:09.000Z","_content":"\n## 2017.10.18\n### 1. 迁移vps\n   目前使用的linode的东京1机房的vps，经常重启维护， 每次都要手工恢复，比较麻烦。这个vps上scp命令经常不能正确执行， 也是个头疼的问题。\n刚好又发现其他机房支持$5/mon的套餐，就动了换机房的心思。\n   通过support，寻求官方技术支持。 由于时差，大概隔了一天才回复。不过有商业支持，的确是很爽的，可以少走弯路，节省时间。   \n   按照说明，通过clone的方式最便捷。 不幸的是，过去的($10/mon)1G套餐磁盘是24G, 现在那个最低套餐磁盘只有20G.\n镜像不能复制过去，那就只能手工复制搞了。复制过程中，发现东京2机房网络叫一个烂，丢包非常严重，基本的终端命令都不能输入，无奈作罢。\n   东京1虽然贵一点，但是网络好，无明显丢包，而且rt只有60ms左右，比有些国内的站点延迟还小。\n国内王者荣耀，ping经常在90ms左右，这个将来完全也作为游戏加速器。最后决定暂时不迁了， 为了这个网络每月多付5刀也是值得的。\n\n### 2. 家庭大门监控\n   昨天小区遇到盗贼，有些邻居的家被盗了。当时心里就想着，家里门口应该安装一个监控。\n这样一方面可以威慑盗窃罪，另一方面遇盗后也能比较方便的抓住坏人。刚好，老婆淘到1个旧的萤石C2S监控摄像头。\n于是，可以动手玩一玩了。  这个监控摄像头功能不少。  \n优点:\n1. 云端存储。可以保留一周内的视频\n2. 对话。可在手机上和摄像头前面的人对话。\n3. 夜间红外。光线不好的情况下，可以录黑白的视频。\n\n\n 不好的地方：\n1. 彩色模式不敏感。 光线较强时，还是黑白的。\n2. 密码问题。那个设备验证码试了很多次都是错的。最后reset才恢复。\n3. 需要外接电源。目前是接在门口弱电箱的插线板上。要是能自发电，就完美了。或者有电池，可以每周换一次。\n\n### 3. 博客笔记\n  目前笔记产品很多，主要是云产品。由于某些限制，不能使用云笔记。于是寻找本地的替代方案。\nHexo之前用过，界面美观，使用简单。主要问题是图片保存比较麻烦，尤其是屏幕截图的。我经常使用Atom编辑markdown文件。\n希望能在atom里，保存屏幕截图的图片并生成正确的路径。   \n\n找到1个插件 **Markdown-img-paste** 基本满足需求，但是保存的目录hexo不识别。\n找到源码，改了一下可以完美保存支持hexo的图片。\n[github-link](https://github.com/colinsage/markdown-img-paste/tree/support-hexo)   \n  可以checkout下来到~/.atom/packages， 然后切换到support-hexo分支。重启Atom会自动加载。\n","source":"_posts/2017-10-18-misc.md","raw":"---\ntitle: 20171018-misc\ndate: 2017-10-18 17:02:09\ntags:\n- tips\n- life\n---\n\n## 2017.10.18\n### 1. 迁移vps\n   目前使用的linode的东京1机房的vps，经常重启维护， 每次都要手工恢复，比较麻烦。这个vps上scp命令经常不能正确执行， 也是个头疼的问题。\n刚好又发现其他机房支持$5/mon的套餐，就动了换机房的心思。\n   通过support，寻求官方技术支持。 由于时差，大概隔了一天才回复。不过有商业支持，的确是很爽的，可以少走弯路，节省时间。   \n   按照说明，通过clone的方式最便捷。 不幸的是，过去的($10/mon)1G套餐磁盘是24G, 现在那个最低套餐磁盘只有20G.\n镜像不能复制过去，那就只能手工复制搞了。复制过程中，发现东京2机房网络叫一个烂，丢包非常严重，基本的终端命令都不能输入，无奈作罢。\n   东京1虽然贵一点，但是网络好，无明显丢包，而且rt只有60ms左右，比有些国内的站点延迟还小。\n国内王者荣耀，ping经常在90ms左右，这个将来完全也作为游戏加速器。最后决定暂时不迁了， 为了这个网络每月多付5刀也是值得的。\n\n### 2. 家庭大门监控\n   昨天小区遇到盗贼，有些邻居的家被盗了。当时心里就想着，家里门口应该安装一个监控。\n这样一方面可以威慑盗窃罪，另一方面遇盗后也能比较方便的抓住坏人。刚好，老婆淘到1个旧的萤石C2S监控摄像头。\n于是，可以动手玩一玩了。  这个监控摄像头功能不少。  \n优点:\n1. 云端存储。可以保留一周内的视频\n2. 对话。可在手机上和摄像头前面的人对话。\n3. 夜间红外。光线不好的情况下，可以录黑白的视频。\n\n\n 不好的地方：\n1. 彩色模式不敏感。 光线较强时，还是黑白的。\n2. 密码问题。那个设备验证码试了很多次都是错的。最后reset才恢复。\n3. 需要外接电源。目前是接在门口弱电箱的插线板上。要是能自发电，就完美了。或者有电池，可以每周换一次。\n\n### 3. 博客笔记\n  目前笔记产品很多，主要是云产品。由于某些限制，不能使用云笔记。于是寻找本地的替代方案。\nHexo之前用过，界面美观，使用简单。主要问题是图片保存比较麻烦，尤其是屏幕截图的。我经常使用Atom编辑markdown文件。\n希望能在atom里，保存屏幕截图的图片并生成正确的路径。   \n\n找到1个插件 **Markdown-img-paste** 基本满足需求，但是保存的目录hexo不识别。\n找到源码，改了一下可以完美保存支持hexo的图片。\n[github-link](https://github.com/colinsage/markdown-img-paste/tree/support-hexo)   \n  可以checkout下来到~/.atom/packages， 然后切换到support-hexo分支。重启Atom会自动加载。\n","slug":"misc","published":1,"updated":"2018-02-27T09:05:10.568Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0z800013l65qkr5aruf","content":"<h2 id=\"2017-10-18\"><a href=\"#2017-10-18\" class=\"headerlink\" title=\"2017.10.18\"></a>2017.10.18</h2><h3 id=\"1-迁移vps\"><a href=\"#1-迁移vps\" class=\"headerlink\" title=\"1. 迁移vps\"></a>1. 迁移vps</h3><p>   目前使用的linode的东京1机房的vps，经常重启维护， 每次都要手工恢复，比较麻烦。这个vps上scp命令经常不能正确执行， 也是个头疼的问题。<br>刚好又发现其他机房支持$5/mon的套餐，就动了换机房的心思。<br>   通过support，寻求官方技术支持。 由于时差，大概隔了一天才回复。不过有商业支持，的确是很爽的，可以少走弯路，节省时间。<br>   按照说明，通过clone的方式最便捷。 不幸的是，过去的($10/mon)1G套餐磁盘是24G, 现在那个最低套餐磁盘只有20G.<br>镜像不能复制过去，那就只能手工复制搞了。复制过程中，发现东京2机房网络叫一个烂，丢包非常严重，基本的终端命令都不能输入，无奈作罢。<br>   东京1虽然贵一点，但是网络好，无明显丢包，而且rt只有60ms左右，比有些国内的站点延迟还小。<br>国内王者荣耀，ping经常在90ms左右，这个将来完全也作为游戏加速器。最后决定暂时不迁了， 为了这个网络每月多付5刀也是值得的。</p>\n<h3 id=\"2-家庭大门监控\"><a href=\"#2-家庭大门监控\" class=\"headerlink\" title=\"2. 家庭大门监控\"></a>2. 家庭大门监控</h3><p>   昨天小区遇到盗贼，有些邻居的家被盗了。当时心里就想着，家里门口应该安装一个监控。<br>这样一方面可以威慑盗窃罪，另一方面遇盗后也能比较方便的抓住坏人。刚好，老婆淘到1个旧的萤石C2S监控摄像头。<br>于是，可以动手玩一玩了。  这个监控摄像头功能不少。<br>优点:</p>\n<ol>\n<li>云端存储。可以保留一周内的视频</li>\n<li>对话。可在手机上和摄像头前面的人对话。</li>\n<li>夜间红外。光线不好的情况下，可以录黑白的视频。</li>\n</ol>\n<p> 不好的地方：</p>\n<ol>\n<li>彩色模式不敏感。 光线较强时，还是黑白的。</li>\n<li>密码问题。那个设备验证码试了很多次都是错的。最后reset才恢复。</li>\n<li>需要外接电源。目前是接在门口弱电箱的插线板上。要是能自发电，就完美了。或者有电池，可以每周换一次。</li>\n</ol>\n<h3 id=\"3-博客笔记\"><a href=\"#3-博客笔记\" class=\"headerlink\" title=\"3. 博客笔记\"></a>3. 博客笔记</h3><p>  目前笔记产品很多，主要是云产品。由于某些限制，不能使用云笔记。于是寻找本地的替代方案。<br>Hexo之前用过，界面美观，使用简单。主要问题是图片保存比较麻烦，尤其是屏幕截图的。我经常使用Atom编辑markdown文件。<br>希望能在atom里，保存屏幕截图的图片并生成正确的路径。   </p>\n<p>找到1个插件 <strong>Markdown-img-paste</strong> 基本满足需求，但是保存的目录hexo不识别。<br>找到源码，改了一下可以完美保存支持hexo的图片。<br><a href=\"https://github.com/colinsage/markdown-img-paste/tree/support-hexo\" target=\"_blank\" rel=\"noopener\">github-link</a><br>  可以checkout下来到~/.atom/packages， 然后切换到support-hexo分支。重启Atom会自动加载。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"2017-10-18\"><a href=\"#2017-10-18\" class=\"headerlink\" title=\"2017.10.18\"></a>2017.10.18</h2><h3 id=\"1-迁移vps\"><a href=\"#1-迁移vps\" class=\"headerlink\" title=\"1. 迁移vps\"></a>1. 迁移vps</h3><p>   目前使用的linode的东京1机房的vps，经常重启维护， 每次都要手工恢复，比较麻烦。这个vps上scp命令经常不能正确执行， 也是个头疼的问题。<br>刚好又发现其他机房支持$5/mon的套餐，就动了换机房的心思。<br>   通过support，寻求官方技术支持。 由于时差，大概隔了一天才回复。不过有商业支持，的确是很爽的，可以少走弯路，节省时间。<br>   按照说明，通过clone的方式最便捷。 不幸的是，过去的($10/mon)1G套餐磁盘是24G, 现在那个最低套餐磁盘只有20G.<br>镜像不能复制过去，那就只能手工复制搞了。复制过程中，发现东京2机房网络叫一个烂，丢包非常严重，基本的终端命令都不能输入，无奈作罢。<br>   东京1虽然贵一点，但是网络好，无明显丢包，而且rt只有60ms左右，比有些国内的站点延迟还小。<br>国内王者荣耀，ping经常在90ms左右，这个将来完全也作为游戏加速器。最后决定暂时不迁了， 为了这个网络每月多付5刀也是值得的。</p>\n<h3 id=\"2-家庭大门监控\"><a href=\"#2-家庭大门监控\" class=\"headerlink\" title=\"2. 家庭大门监控\"></a>2. 家庭大门监控</h3><p>   昨天小区遇到盗贼，有些邻居的家被盗了。当时心里就想着，家里门口应该安装一个监控。<br>这样一方面可以威慑盗窃罪，另一方面遇盗后也能比较方便的抓住坏人。刚好，老婆淘到1个旧的萤石C2S监控摄像头。<br>于是，可以动手玩一玩了。  这个监控摄像头功能不少。<br>优点:</p>\n<ol>\n<li>云端存储。可以保留一周内的视频</li>\n<li>对话。可在手机上和摄像头前面的人对话。</li>\n<li>夜间红外。光线不好的情况下，可以录黑白的视频。</li>\n</ol>\n<p> 不好的地方：</p>\n<ol>\n<li>彩色模式不敏感。 光线较强时，还是黑白的。</li>\n<li>密码问题。那个设备验证码试了很多次都是错的。最后reset才恢复。</li>\n<li>需要外接电源。目前是接在门口弱电箱的插线板上。要是能自发电，就完美了。或者有电池，可以每周换一次。</li>\n</ol>\n<h3 id=\"3-博客笔记\"><a href=\"#3-博客笔记\" class=\"headerlink\" title=\"3. 博客笔记\"></a>3. 博客笔记</h3><p>  目前笔记产品很多，主要是云产品。由于某些限制，不能使用云笔记。于是寻找本地的替代方案。<br>Hexo之前用过，界面美观，使用简单。主要问题是图片保存比较麻烦，尤其是屏幕截图的。我经常使用Atom编辑markdown文件。<br>希望能在atom里，保存屏幕截图的图片并生成正确的路径。   </p>\n<p>找到1个插件 <strong>Markdown-img-paste</strong> 基本满足需求，但是保存的目录hexo不识别。<br>找到源码，改了一下可以完美保存支持hexo的图片。<br><a href=\"https://github.com/colinsage/markdown-img-paste/tree/support-hexo\" target=\"_blank\" rel=\"noopener\">github-link</a><br>  可以checkout下来到~/.atom/packages， 然后切换到support-hexo分支。重启Atom会自动加载。</p>\n"},{"title":"Influxdb之read流程分析","date":"2017-10-19T07:51:15.000Z","_content":"## 前言\n   由于influxdb的更新很快，以下描述对应的是1.6.2版本的代码。\n从使用角度看，查询主要涉及两类，元数据和时序数据。例如查询database，retention_policy,\nmeasurement，tag_key, tag_value, field_name 等都属于查询元数据。\n时序数据查询过程中也会进行元数据查询以便定位数据。\n\n## 主要流程\n\n---\n## 入口\n当使用http协议时，在handler的serveQuery处理方法。\n使用命令行时，insert语句也是转换成对应的http URL，Path是 \"/query\"\n\n## 类型\n+ 元数据修改\n+ 元数据查询\n+ 数据查询\n\n## 数据查询\n+ influxsql解析成statement\n+ statement创建iterator\n+ 聚合计算\n\n## 非聚和\n1. 先根据measurement创建AuxIterator。最小粒度单个timeseries，逐级merge而成。\ninterator的嵌入结构如下:\n{% asset_img \"mip-2017101919283058.png\" \"iterator层级\" %}\n2. 根据fields创建iterator，第1步的AuxIterator有新创建的FieldAuxIterator的引用\n3. AuxIterato执行backgroud\n4. 返回第2步创建的FieldAuxIterators\n\n### 创建基本类型Iterator\n基本类型Iterator包括FloatIterator, IntegerIterator, StringIterator, BooleanIterator\n1. 从元数据索引(内存 or TSI)中读取measurements所有seriesKeys\n2. 根据查询stmt里的Dimensions，对sereiesKeys进行分组形成tagset，然后组内seriesKeys排序，再对tagset排序。\n3. 对tagset里的seriesKeys再进行分组，然后创建goroutine处理每个分组\n\n### 读取的递进过程\n两条线并行进行：\n1. 返回结果的Iterator\n2. 获取底层数据的Iterator。\n    两类Cursor，cur (floatCursor)和aux(CursorAt, 对原生cursor的封装)。\n\n### 创建iterator的层级\nnode_s -> source_s > shard_s -> tagset_s -> serieskey_s\n> 1. 远程的iterator到node级别\n> 2. 涉及merger的有: node, source, shard, tagset. 基本上每级都会进行合并\n> 3. source 是对多个shard进行source划分, 分别创建再merge合并\n\n## 聚合\n   聚合类型的查询会创建CallIterator类型的iterator。创建之前会从index查询出符合匹配条件的seriesKey\n然后根据groupby的条件，为每个group创建tagset。每个tagset里包含多个属于该group的seriesKey。\n   然后再根据tagset创建最底层数据类型的iterator。如果为tagset创建的iterator数目多余cpu的个数，\n则会创建并行读取的iterator，这是个支持异步读取的iterator。\n### merge涉及的层次\n共5层.\n+ shard内serie.\n+ shard\n+ sharggroup\n+ shardmapping\n+ query\n\n\n## Questions\n### Q1: emitor里有个iterator，是如何同步多个iterator的时间戳？\nA: 创建buildAuxIterators时，先创建1个AuxIterator。 然后再根据fields创建多个FieldAuxIterator\n同时把这些fieldAuxIterator注册到顶级AuxIterator, 最后返回fieldAuxIterator.   \n   对于不同shard的interator，如何同步的呢？  \n创建了一个SortedMergeIterator，里面有个小根heap。堆里的元素是子Iterator与point的组合结构item。\n初始化时，从每个子Iterator读1个point，然后构造heap。读取时，从顶部pop出item，读取里面的point用于返回，\n同时再从子Iterator里读一个point，然后再把这个item push到heap里。\n\n### Q2: 为何limit会比较慢\nA: 由于iterator的装饰特性, 先执行内部的mergerInterator, 再执行limit.  mergeInterator会根据所有的时间线创建1个堆,\n以便于排序. 如果维度很高,创建这个堆的过程也很耗时. 即使查询条件limit=1, 也需要一段时间来执行mergeInterator.\n","source":"_posts/2017-10-19-influxdb-read.md","raw":"---\ntitle: Influxdb之read流程分析\ndate: 2017-10-19 15:51:15\ntags: influxdb sql tsm\n---\n## 前言\n   由于influxdb的更新很快，以下描述对应的是1.6.2版本的代码。\n从使用角度看，查询主要涉及两类，元数据和时序数据。例如查询database，retention_policy,\nmeasurement，tag_key, tag_value, field_name 等都属于查询元数据。\n时序数据查询过程中也会进行元数据查询以便定位数据。\n\n## 主要流程\n\n---\n## 入口\n当使用http协议时，在handler的serveQuery处理方法。\n使用命令行时，insert语句也是转换成对应的http URL，Path是 \"/query\"\n\n## 类型\n+ 元数据修改\n+ 元数据查询\n+ 数据查询\n\n## 数据查询\n+ influxsql解析成statement\n+ statement创建iterator\n+ 聚合计算\n\n## 非聚和\n1. 先根据measurement创建AuxIterator。最小粒度单个timeseries，逐级merge而成。\ninterator的嵌入结构如下:\n{% asset_img \"mip-2017101919283058.png\" \"iterator层级\" %}\n2. 根据fields创建iterator，第1步的AuxIterator有新创建的FieldAuxIterator的引用\n3. AuxIterato执行backgroud\n4. 返回第2步创建的FieldAuxIterators\n\n### 创建基本类型Iterator\n基本类型Iterator包括FloatIterator, IntegerIterator, StringIterator, BooleanIterator\n1. 从元数据索引(内存 or TSI)中读取measurements所有seriesKeys\n2. 根据查询stmt里的Dimensions，对sereiesKeys进行分组形成tagset，然后组内seriesKeys排序，再对tagset排序。\n3. 对tagset里的seriesKeys再进行分组，然后创建goroutine处理每个分组\n\n### 读取的递进过程\n两条线并行进行：\n1. 返回结果的Iterator\n2. 获取底层数据的Iterator。\n    两类Cursor，cur (floatCursor)和aux(CursorAt, 对原生cursor的封装)。\n\n### 创建iterator的层级\nnode_s -> source_s > shard_s -> tagset_s -> serieskey_s\n> 1. 远程的iterator到node级别\n> 2. 涉及merger的有: node, source, shard, tagset. 基本上每级都会进行合并\n> 3. source 是对多个shard进行source划分, 分别创建再merge合并\n\n## 聚合\n   聚合类型的查询会创建CallIterator类型的iterator。创建之前会从index查询出符合匹配条件的seriesKey\n然后根据groupby的条件，为每个group创建tagset。每个tagset里包含多个属于该group的seriesKey。\n   然后再根据tagset创建最底层数据类型的iterator。如果为tagset创建的iterator数目多余cpu的个数，\n则会创建并行读取的iterator，这是个支持异步读取的iterator。\n### merge涉及的层次\n共5层.\n+ shard内serie.\n+ shard\n+ sharggroup\n+ shardmapping\n+ query\n\n\n## Questions\n### Q1: emitor里有个iterator，是如何同步多个iterator的时间戳？\nA: 创建buildAuxIterators时，先创建1个AuxIterator。 然后再根据fields创建多个FieldAuxIterator\n同时把这些fieldAuxIterator注册到顶级AuxIterator, 最后返回fieldAuxIterator.   \n   对于不同shard的interator，如何同步的呢？  \n创建了一个SortedMergeIterator，里面有个小根heap。堆里的元素是子Iterator与point的组合结构item。\n初始化时，从每个子Iterator读1个point，然后构造heap。读取时，从顶部pop出item，读取里面的point用于返回，\n同时再从子Iterator里读一个point，然后再把这个item push到heap里。\n\n### Q2: 为何limit会比较慢\nA: 由于iterator的装饰特性, 先执行内部的mergerInterator, 再执行limit.  mergeInterator会根据所有的时间线创建1个堆,\n以便于排序. 如果维度很高,创建这个堆的过程也很耗时. 即使查询条件limit=1, 也需要一段时间来执行mergeInterator.\n","slug":"influxdb-read","published":1,"updated":"2018-09-05T02:47:32.582Z","_id":"cjlohe0zb00033l65gcyoq3gi","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>   由于influxdb的更新很快，以下描述对应的是1.6.2版本的代码。<br>从使用角度看，查询主要涉及两类，元数据和时序数据。例如查询database，retention_policy,<br>measurement，tag_key, tag_value, field_name 等都属于查询元数据。<br>时序数据查询过程中也会进行元数据查询以便定位数据。</p>\n<h2 id=\"主要流程\"><a href=\"#主要流程\" class=\"headerlink\" title=\"主要流程\"></a>主要流程</h2><hr>\n<h2 id=\"入口\"><a href=\"#入口\" class=\"headerlink\" title=\"入口\"></a>入口</h2><p>当使用http协议时，在handler的serveQuery处理方法。<br>使用命令行时，insert语句也是转换成对应的http URL，Path是 “/query”</p>\n<h2 id=\"类型\"><a href=\"#类型\" class=\"headerlink\" title=\"类型\"></a>类型</h2><ul>\n<li>元数据修改</li>\n<li>元数据查询</li>\n<li>数据查询</li>\n</ul>\n<h2 id=\"数据查询\"><a href=\"#数据查询\" class=\"headerlink\" title=\"数据查询\"></a>数据查询</h2><ul>\n<li>influxsql解析成statement</li>\n<li>statement创建iterator</li>\n<li>聚合计算</li>\n</ul>\n<h2 id=\"非聚和\"><a href=\"#非聚和\" class=\"headerlink\" title=\"非聚和\"></a>非聚和</h2><ol>\n<li>先根据measurement创建AuxIterator。最小粒度单个timeseries，逐级merge而成。<br>interator的嵌入结构如下:</li>\n<li>根据fields创建iterator，第1步的AuxIterator有新创建的FieldAuxIterator的引用</li>\n<li>AuxIterato执行backgroud</li>\n<li>返回第2步创建的FieldAuxIterators</li>\n</ol>\n<h3 id=\"创建基本类型Iterator\"><a href=\"#创建基本类型Iterator\" class=\"headerlink\" title=\"创建基本类型Iterator\"></a>创建基本类型Iterator</h3><p>基本类型Iterator包括FloatIterator, IntegerIterator, StringIterator, BooleanIterator</p>\n<ol>\n<li>从元数据索引(内存 or TSI)中读取measurements所有seriesKeys</li>\n<li>根据查询stmt里的Dimensions，对sereiesKeys进行分组形成tagset，然后组内seriesKeys排序，再对tagset排序。</li>\n<li>对tagset里的seriesKeys再进行分组，然后创建goroutine处理每个分组</li>\n</ol>\n<h3 id=\"读取的递进过程\"><a href=\"#读取的递进过程\" class=\"headerlink\" title=\"读取的递进过程\"></a>读取的递进过程</h3><p>两条线并行进行：</p>\n<ol>\n<li>返回结果的Iterator</li>\n<li>获取底层数据的Iterator。<br> 两类Cursor，cur (floatCursor)和aux(CursorAt, 对原生cursor的封装)。</li>\n</ol>\n<h3 id=\"创建iterator的层级\"><a href=\"#创建iterator的层级\" class=\"headerlink\" title=\"创建iterator的层级\"></a>创建iterator的层级</h3><p>node_s -&gt; source_s &gt; shard_s -&gt; tagset_s -&gt; serieskey_s</p>\n<blockquote>\n<ol>\n<li>远程的iterator到node级别</li>\n<li>涉及merger的有: node, source, shard, tagset. 基本上每级都会进行合并</li>\n<li>source 是对多个shard进行source划分, 分别创建再merge合并</li>\n</ol>\n</blockquote>\n<h2 id=\"聚合\"><a href=\"#聚合\" class=\"headerlink\" title=\"聚合\"></a>聚合</h2><p>   聚合类型的查询会创建CallIterator类型的iterator。创建之前会从index查询出符合匹配条件的seriesKey<br>然后根据groupby的条件，为每个group创建tagset。每个tagset里包含多个属于该group的seriesKey。<br>   然后再根据tagset创建最底层数据类型的iterator。如果为tagset创建的iterator数目多余cpu的个数，<br>则会创建并行读取的iterator，这是个支持异步读取的iterator。</p>\n<h3 id=\"merge涉及的层次\"><a href=\"#merge涉及的层次\" class=\"headerlink\" title=\"merge涉及的层次\"></a>merge涉及的层次</h3><p>共5层.</p>\n<ul>\n<li>shard内serie.</li>\n<li>shard</li>\n<li>sharggroup</li>\n<li>shardmapping</li>\n<li>query</li>\n</ul>\n<h2 id=\"Questions\"><a href=\"#Questions\" class=\"headerlink\" title=\"Questions\"></a>Questions</h2><h3 id=\"Q1-emitor里有个iterator，是如何同步多个iterator的时间戳？\"><a href=\"#Q1-emitor里有个iterator，是如何同步多个iterator的时间戳？\" class=\"headerlink\" title=\"Q1: emitor里有个iterator，是如何同步多个iterator的时间戳？\"></a>Q1: emitor里有个iterator，是如何同步多个iterator的时间戳？</h3><p>A: 创建buildAuxIterators时，先创建1个AuxIterator。 然后再根据fields创建多个FieldAuxIterator<br>同时把这些fieldAuxIterator注册到顶级AuxIterator, 最后返回fieldAuxIterator.<br>   对于不同shard的interator，如何同步的呢？<br>创建了一个SortedMergeIterator，里面有个小根heap。堆里的元素是子Iterator与point的组合结构item。<br>初始化时，从每个子Iterator读1个point，然后构造heap。读取时，从顶部pop出item，读取里面的point用于返回，<br>同时再从子Iterator里读一个point，然后再把这个item push到heap里。</p>\n<h3 id=\"Q2-为何limit会比较慢\"><a href=\"#Q2-为何limit会比较慢\" class=\"headerlink\" title=\"Q2: 为何limit会比较慢\"></a>Q2: 为何limit会比较慢</h3><p>A: 由于iterator的装饰特性, 先执行内部的mergerInterator, 再执行limit.  mergeInterator会根据所有的时间线创建1个堆,<br>以便于排序. 如果维度很高,创建这个堆的过程也很耗时. 即使查询条件limit=1, 也需要一段时间来执行mergeInterator.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>   由于influxdb的更新很快，以下描述对应的是1.6.2版本的代码。<br>从使用角度看，查询主要涉及两类，元数据和时序数据。例如查询database，retention_policy,<br>measurement，tag_key, tag_value, field_name 等都属于查询元数据。<br>时序数据查询过程中也会进行元数据查询以便定位数据。</p>\n<h2 id=\"主要流程\"><a href=\"#主要流程\" class=\"headerlink\" title=\"主要流程\"></a>主要流程</h2><hr>\n<h2 id=\"入口\"><a href=\"#入口\" class=\"headerlink\" title=\"入口\"></a>入口</h2><p>当使用http协议时，在handler的serveQuery处理方法。<br>使用命令行时，insert语句也是转换成对应的http URL，Path是 “/query”</p>\n<h2 id=\"类型\"><a href=\"#类型\" class=\"headerlink\" title=\"类型\"></a>类型</h2><ul>\n<li>元数据修改</li>\n<li>元数据查询</li>\n<li>数据查询</li>\n</ul>\n<h2 id=\"数据查询\"><a href=\"#数据查询\" class=\"headerlink\" title=\"数据查询\"></a>数据查询</h2><ul>\n<li>influxsql解析成statement</li>\n<li>statement创建iterator</li>\n<li>聚合计算</li>\n</ul>\n<h2 id=\"非聚和\"><a href=\"#非聚和\" class=\"headerlink\" title=\"非聚和\"></a>非聚和</h2><ol>\n<li>先根据measurement创建AuxIterator。最小粒度单个timeseries，逐级merge而成。<br>interator的嵌入结构如下:</li>\n<li>根据fields创建iterator，第1步的AuxIterator有新创建的FieldAuxIterator的引用</li>\n<li>AuxIterato执行backgroud</li>\n<li>返回第2步创建的FieldAuxIterators</li>\n</ol>\n<h3 id=\"创建基本类型Iterator\"><a href=\"#创建基本类型Iterator\" class=\"headerlink\" title=\"创建基本类型Iterator\"></a>创建基本类型Iterator</h3><p>基本类型Iterator包括FloatIterator, IntegerIterator, StringIterator, BooleanIterator</p>\n<ol>\n<li>从元数据索引(内存 or TSI)中读取measurements所有seriesKeys</li>\n<li>根据查询stmt里的Dimensions，对sereiesKeys进行分组形成tagset，然后组内seriesKeys排序，再对tagset排序。</li>\n<li>对tagset里的seriesKeys再进行分组，然后创建goroutine处理每个分组</li>\n</ol>\n<h3 id=\"读取的递进过程\"><a href=\"#读取的递进过程\" class=\"headerlink\" title=\"读取的递进过程\"></a>读取的递进过程</h3><p>两条线并行进行：</p>\n<ol>\n<li>返回结果的Iterator</li>\n<li>获取底层数据的Iterator。<br> 两类Cursor，cur (floatCursor)和aux(CursorAt, 对原生cursor的封装)。</li>\n</ol>\n<h3 id=\"创建iterator的层级\"><a href=\"#创建iterator的层级\" class=\"headerlink\" title=\"创建iterator的层级\"></a>创建iterator的层级</h3><p>node_s -&gt; source_s &gt; shard_s -&gt; tagset_s -&gt; serieskey_s</p>\n<blockquote>\n<ol>\n<li>远程的iterator到node级别</li>\n<li>涉及merger的有: node, source, shard, tagset. 基本上每级都会进行合并</li>\n<li>source 是对多个shard进行source划分, 分别创建再merge合并</li>\n</ol>\n</blockquote>\n<h2 id=\"聚合\"><a href=\"#聚合\" class=\"headerlink\" title=\"聚合\"></a>聚合</h2><p>   聚合类型的查询会创建CallIterator类型的iterator。创建之前会从index查询出符合匹配条件的seriesKey<br>然后根据groupby的条件，为每个group创建tagset。每个tagset里包含多个属于该group的seriesKey。<br>   然后再根据tagset创建最底层数据类型的iterator。如果为tagset创建的iterator数目多余cpu的个数，<br>则会创建并行读取的iterator，这是个支持异步读取的iterator。</p>\n<h3 id=\"merge涉及的层次\"><a href=\"#merge涉及的层次\" class=\"headerlink\" title=\"merge涉及的层次\"></a>merge涉及的层次</h3><p>共5层.</p>\n<ul>\n<li>shard内serie.</li>\n<li>shard</li>\n<li>sharggroup</li>\n<li>shardmapping</li>\n<li>query</li>\n</ul>\n<h2 id=\"Questions\"><a href=\"#Questions\" class=\"headerlink\" title=\"Questions\"></a>Questions</h2><h3 id=\"Q1-emitor里有个iterator，是如何同步多个iterator的时间戳？\"><a href=\"#Q1-emitor里有个iterator，是如何同步多个iterator的时间戳？\" class=\"headerlink\" title=\"Q1: emitor里有个iterator，是如何同步多个iterator的时间戳？\"></a>Q1: emitor里有个iterator，是如何同步多个iterator的时间戳？</h3><p>A: 创建buildAuxIterators时，先创建1个AuxIterator。 然后再根据fields创建多个FieldAuxIterator<br>同时把这些fieldAuxIterator注册到顶级AuxIterator, 最后返回fieldAuxIterator.<br>   对于不同shard的interator，如何同步的呢？<br>创建了一个SortedMergeIterator，里面有个小根heap。堆里的元素是子Iterator与point的组合结构item。<br>初始化时，从每个子Iterator读1个point，然后构造heap。读取时，从顶部pop出item，读取里面的point用于返回，<br>同时再从子Iterator里读一个point，然后再把这个item push到heap里。</p>\n<h3 id=\"Q2-为何limit会比较慢\"><a href=\"#Q2-为何limit会比较慢\" class=\"headerlink\" title=\"Q2: 为何limit会比较慢\"></a>Q2: 为何limit会比较慢</h3><p>A: 由于iterator的装饰特性, 先执行内部的mergerInterator, 再执行limit.  mergeInterator会根据所有的时间线创建1个堆,<br>以便于排序. 如果维度很高,创建这个堆的过程也很耗时. 即使查询条件limit=1, 也需要一段时间来执行mergeInterator.</p>\n"},{"title":"20171027-misc","date":"2017-10-27T01:54:16.000Z","_content":"\n### 注册用的密码\n大量的网站要注册密码，使用相同的密码又不安全。一个垃圾站点泄露密码后，所有的账号都不安全了。   \n\n一种思路是对不同的网站分类，不同类别使用不同的密码。 这样可以一定程度缓解问题。 还是存在一定风险。\n当同类的泄露之后，相同级别的站点密码也需要及时修改。可以在这种思路基础之上，再加一个改变。\n在同级别的站点的密码不使用相同的， 但使用相同生成规则和salt, 再加上站点的二级域名.\n```\npasswd=rule(domain, salt)\n// 例如csdn.com, 二级域名=csdn，使用的salt=2017，rule=简单拼接，那么passwd=csdn2017\n```\n\n另一种思路是使用密码管理软件。这类软件还没使用过，不好评价。可能不是所有场景都能输入密码。\n目前使用过的浏览器表单保存工具，使用体验也不是太好。\n\n### jvm垃圾回收占用cpu超过\n   有个job被反馈cpu超用，主要是gc线程在使用cpu。后来追加了参数\"-XX:SurvivorRatio=5\n-XX:ParallelGCThreads=4\"后， 问题消除。   这里最主要的是ParallelGCThreads这个参数。\n为了提高垃圾回收的性能，java在parallel回收的时候可以设置同时并行处理的线程数也就是ParallelGCThreads，\n如果你没有设置该参数，当核数小于8时，该参数jvm会默认设置成online的cpu的核数但并不包括被shutdown的cpu的核数。\n当核数大于8时，该参数按下述公式设置.\n```\nParallelGCThreads＝8+( Processor - 8 ) ( 5/8 )\n```\n   问题出在没有设置这个参数，而程序又是跑在物理机(64核)上的。这样默认开启的线程数就太多了，\n大量gc线程没事儿干，一直处于自旋锁状态，所以cpu才会超用。\n   jvm参数的设置不能一招鲜吃遍天，有时还得考虑运行的具体环境。\n","source":"_posts/2017-10-27-misc.md","raw":"---\ntitle: 20171027-misc\ndate: 2017-10-27 09:54:16\ntags:\n---\n\n### 注册用的密码\n大量的网站要注册密码，使用相同的密码又不安全。一个垃圾站点泄露密码后，所有的账号都不安全了。   \n\n一种思路是对不同的网站分类，不同类别使用不同的密码。 这样可以一定程度缓解问题。 还是存在一定风险。\n当同类的泄露之后，相同级别的站点密码也需要及时修改。可以在这种思路基础之上，再加一个改变。\n在同级别的站点的密码不使用相同的， 但使用相同生成规则和salt, 再加上站点的二级域名.\n```\npasswd=rule(domain, salt)\n// 例如csdn.com, 二级域名=csdn，使用的salt=2017，rule=简单拼接，那么passwd=csdn2017\n```\n\n另一种思路是使用密码管理软件。这类软件还没使用过，不好评价。可能不是所有场景都能输入密码。\n目前使用过的浏览器表单保存工具，使用体验也不是太好。\n\n### jvm垃圾回收占用cpu超过\n   有个job被反馈cpu超用，主要是gc线程在使用cpu。后来追加了参数\"-XX:SurvivorRatio=5\n-XX:ParallelGCThreads=4\"后， 问题消除。   这里最主要的是ParallelGCThreads这个参数。\n为了提高垃圾回收的性能，java在parallel回收的时候可以设置同时并行处理的线程数也就是ParallelGCThreads，\n如果你没有设置该参数，当核数小于8时，该参数jvm会默认设置成online的cpu的核数但并不包括被shutdown的cpu的核数。\n当核数大于8时，该参数按下述公式设置.\n```\nParallelGCThreads＝8+( Processor - 8 ) ( 5/8 )\n```\n   问题出在没有设置这个参数，而程序又是跑在物理机(64核)上的。这样默认开启的线程数就太多了，\n大量gc线程没事儿干，一直处于自旋锁状态，所以cpu才会超用。\n   jvm参数的设置不能一招鲜吃遍天，有时还得考虑运行的具体环境。\n","slug":"misc","published":1,"updated":"2018-02-27T09:05:10.572Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zc00043l65dg0a9kxn","content":"<h3 id=\"注册用的密码\"><a href=\"#注册用的密码\" class=\"headerlink\" title=\"注册用的密码\"></a>注册用的密码</h3><p>大量的网站要注册密码，使用相同的密码又不安全。一个垃圾站点泄露密码后，所有的账号都不安全了。   </p>\n<p>一种思路是对不同的网站分类，不同类别使用不同的密码。 这样可以一定程度缓解问题。 还是存在一定风险。<br>当同类的泄露之后，相同级别的站点密码也需要及时修改。可以在这种思路基础之上，再加一个改变。<br>在同级别的站点的密码不使用相同的， 但使用相同生成规则和salt, 再加上站点的二级域名.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">passwd=rule(domain, salt)</div><div class=\"line\">// 例如csdn.com, 二级域名=csdn，使用的salt=2017，rule=简单拼接，那么passwd=csdn2017</div></pre></td></tr></table></figure></p>\n<p>另一种思路是使用密码管理软件。这类软件还没使用过，不好评价。可能不是所有场景都能输入密码。<br>目前使用过的浏览器表单保存工具，使用体验也不是太好。</p>\n<h3 id=\"jvm垃圾回收占用cpu超过\"><a href=\"#jvm垃圾回收占用cpu超过\" class=\"headerlink\" title=\"jvm垃圾回收占用cpu超过\"></a>jvm垃圾回收占用cpu超过</h3><p>   有个job被反馈cpu超用，主要是gc线程在使用cpu。后来追加了参数”-XX:SurvivorRatio=5<br>-XX:ParallelGCThreads=4”后， 问题消除。   这里最主要的是ParallelGCThreads这个参数。<br>为了提高垃圾回收的性能，java在parallel回收的时候可以设置同时并行处理的线程数也就是ParallelGCThreads，<br>如果你没有设置该参数，当核数小于8时，该参数jvm会默认设置成online的cpu的核数但并不包括被shutdown的cpu的核数。<br>当核数大于8时，该参数按下述公式设置.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ParallelGCThreads＝8+( Processor - 8 ) ( 5/8 )</div></pre></td></tr></table></figure></p>\n<p>   问题出在没有设置这个参数，而程序又是跑在物理机(64核)上的。这样默认开启的线程数就太多了，<br>大量gc线程没事儿干，一直处于自旋锁状态，所以cpu才会超用。<br>   jvm参数的设置不能一招鲜吃遍天，有时还得考虑运行的具体环境。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"注册用的密码\"><a href=\"#注册用的密码\" class=\"headerlink\" title=\"注册用的密码\"></a>注册用的密码</h3><p>大量的网站要注册密码，使用相同的密码又不安全。一个垃圾站点泄露密码后，所有的账号都不安全了。   </p>\n<p>一种思路是对不同的网站分类，不同类别使用不同的密码。 这样可以一定程度缓解问题。 还是存在一定风险。<br>当同类的泄露之后，相同级别的站点密码也需要及时修改。可以在这种思路基础之上，再加一个改变。<br>在同级别的站点的密码不使用相同的， 但使用相同生成规则和salt, 再加上站点的二级域名.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">passwd=rule(domain, salt)</div><div class=\"line\">// 例如csdn.com, 二级域名=csdn，使用的salt=2017，rule=简单拼接，那么passwd=csdn2017</div></pre></td></tr></table></figure></p>\n<p>另一种思路是使用密码管理软件。这类软件还没使用过，不好评价。可能不是所有场景都能输入密码。<br>目前使用过的浏览器表单保存工具，使用体验也不是太好。</p>\n<h3 id=\"jvm垃圾回收占用cpu超过\"><a href=\"#jvm垃圾回收占用cpu超过\" class=\"headerlink\" title=\"jvm垃圾回收占用cpu超过\"></a>jvm垃圾回收占用cpu超过</h3><p>   有个job被反馈cpu超用，主要是gc线程在使用cpu。后来追加了参数”-XX:SurvivorRatio=5<br>-XX:ParallelGCThreads=4”后， 问题消除。   这里最主要的是ParallelGCThreads这个参数。<br>为了提高垃圾回收的性能，java在parallel回收的时候可以设置同时并行处理的线程数也就是ParallelGCThreads，<br>如果你没有设置该参数，当核数小于8时，该参数jvm会默认设置成online的cpu的核数但并不包括被shutdown的cpu的核数。<br>当核数大于8时，该参数按下述公式设置.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ParallelGCThreads＝8+( Processor - 8 ) ( 5/8 )</div></pre></td></tr></table></figure></p>\n<p>   问题出在没有设置这个参数，而程序又是跑在物理机(64核)上的。这样默认开启的线程数就太多了，<br>大量gc线程没事儿干，一直处于自旋锁状态，所以cpu才会超用。<br>   jvm参数的设置不能一招鲜吃遍天，有时还得考虑运行的具体环境。</p>\n"},{"title":"influx_write","date":"2017-10-19T06:02:11.000Z","_content":"\n## 1. 架构\n{% asset_img \"mip-20171019150351540.png\" \"架构\" %}\n\n* service是对外暴露各种读写数据的服务.\n* coordinator&influxql 读写数据的抽象接口\n* store是内部具体的存储服务执行者.\n\n## 2. 存储格式\ntsm文件包含4个部分: header, blocks, index和footer.\n\n### 2.1 header\n```\n┌────────┬────────────────────────────────────┬─────────────┬──────────────┐\n│ Header │               Blocks               │    Index    │    Footer    │\n│5 bytes │              N bytes               │   N bytes   │   4 bytes    │\n└────────┴────────────────────────────────────┴─────────────┴──────────────┘\n```\n 头部前4个字节是0x16D116D1标识是tsm文件, 后1个字节是版本号.\n\n```\n┌───────────────────┐\n│      Header       │\n├─────────┬─────────┤\n│  Magic  │ Version │\n│ 4 bytes │ 1 byte  │\n└─────────┴─────────┘\n```\n### 2.2 blocks\n#### 2.2.1 block结构  \n时序数据的基本单位是block，一个block是一个timeseries在一段时间内的数据集合。   \n```\n┌───────────────────────────────────────────────────────────┐\n│                          Blocks                           │\n├───────────────────┬───────────────────┬───────────────────┤\n│      Block 1      │      Block 2      │      Block N      │\n├─────────┬─────────┼─────────┬─────────┼─────────┬─────────┤\n│  CRC    │  Data   │  CRC    │  Data   │  CRC    │  Data   │\n│ 4 bytes │ N bytes │ 4 bytes │ N bytes │ 4 bytes │ N bytes │\n└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘\n```\n\nBlock是读取的最小单元.每个block包括crc和data两部分.\n+ crc用来校验block的数据完整性\n+ data是压缩后的时间戳和value. block格式有多种, 由类型和数据分布决定.\n\n\nblock格式:\n```\n {len timestamp bytes}, {ts bytes}, {value bytes}\n```\n\n#### 2.2.2 压缩\ninfluxdb其中一个最大的卖点是文件压缩率高。一方面可以节省成本，另一方面提升单机的存储能力。\n其中tsm数据文件是主要的数据存储地方。这个文件主要存储了时序数据及在当前文件中快速查找的索引。\n时序数据是最主要的数据，对其压缩方式的选择直接决定了最终数据文件的大小。\n\n##### timestamp:\n* delta相同: {type}, {first}, {delta}, {n} || RLE\n* delta不同且max_delta < (2**60-1): {type}, {first}, {packs}  || simple8\n* delta不同且delta>=(2**60-1) : {type}, {first}, {second} ... | raw\n> 选择压缩方式有点小问题, 应该用max_delta/div的值与2**60-1比较\n\n##### float:\n* 第一个不压缩\n* 与前个值XOR, head tail的0个数, 比之前大: {10},{有效位}\n与前个值XOR, head tail的0个数, 比之前小: {11},{head_5},{len_有效位_6},{有效位}\n* 如果第2个值的head,tail都比较小且后续都比第2个大, 那么会浪费不少空间\n\n\n##### integer\n*  先计算delta, 再用zigzag编码. 把负数转成包含有效1bit尽量少.\n*  delta相同: {type},{first}, {delta}, {n} || RLE\n*  simple8 or raw\n> zigzag: uint64(uint64(x<<1)^uint64((int64(x) >> 63)))\n\n##### boolean\n* 每个值占用1bit  \n* {type}, {len}, {value_bytes}\n\n##### string  \n* {type},{snappy_string}   \n\n\n### 2.3 index\nIndex 存放的是前面 Blocks 里内容的索引。索引条目的顺序是先按照 key 的字典序排序，再按照 time 排序。InfluxDB 在做查询操作时，可以根据 Index 的信息快速定位到 tsm file 中要查询的 block 的位置。\n参考这两个结构体,更容易理解\n```\ntype KeyIndex struct {\n    KeyLen      uint16  //下面一个字段 key 的长度。\n    Key         string  //seriesKey + 分隔符 + fieldName\n    Type        byte  // Block 中 Data 内的数据的类型\n    Count       uint32 //后面紧跟着的 Blocks 索引的个数\n    Blocks      []*BlockIndex\n}\n\ntype BlockIndex struct {\n    MinTime     int64  //block 中 value 的最小时间戳\n    MaxTime     int64  //block 中 value 的最大时间戳\n    Offset      int64  //block 在整个 tsm file 中的偏移量\n    Size        uint32  //block 的大小。根据 Offset + Size 字段就可以快速读取出一个 block 中的内容\n}\n\n┌────────────────────────────────────────────────────────────────────────────┐\n│                                   Index                                    │\n├─────────┬─────────┬──────┬───────┬─────────┬─────────┬────────┬────────┬───┤\n│ Key Len │   Key   │ Type │ Count │Min Time │Max Time │ Offset │  Size  │...│\n│ 2 bytes │ N bytes │1 byte│2 bytes│ 8 bytes │ 8 bytes │8 bytes │4 bytes │   │\n└─────────┴─────────┴──────┴───────┴─────────┴─────────┴────────┴────────┴───┘\n```\n## 2.4 footer\n\nfooter有8个字节, 存储index部分在当前tsm文件里偏移值.\n```\n┌─────────┐\n│ Footer  │\n├─────────┤\n│Index Ofs│\n│ 8 bytes │\n└─────────┘\n```\n\n## 3. 请求处理\n1. 写请求处理链路\n   + http服务接收请求再转给coordinator\n   + coordinator的pointwriter包含store的引用\n   + 根据写请求参数,选择合适的shard. 如没有则创建\n   + 先写入cache,再写wal文件.\n   + 同步的写请求处理完成\n```\n http.serveWrite -> co.pointwriter -> shard -> engine -> cache -> wal\n```\n2. 压缩数据到tsm\n  + 每秒检查是否需要执行compact. 超过cache_max_size和duration_max, 执行compact\n  + 创建cache的snapshot. cache这里用了一个交换机制, 交换snapshot的store和正在提供服务的cache的store.\n  + 创建cacheKeyIteator. 并发执行数据的encode\n  + 遍历iteator,写入到tsm文件.\n\n## 4. 索引合并\n### 4.1 索引日志合并\n在index发生变化(create or drop)时,会在最后一步调用CheckLogFile, 触发tsl合并成tsi文件.  \n\n\n### 4.2 索引文件合并\n在index文件打开时,会创建goroutine不断检查合并tis文件. 索引日志合并最后也会触发索引文件合并.\n","source":"_posts/2017-10-19-influxdb-write.md","raw":"---\ntitle: influx_write\ndate: 2017-10-19 14:02:11\ntags:\n---\n\n## 1. 架构\n{% asset_img \"mip-20171019150351540.png\" \"架构\" %}\n\n* service是对外暴露各种读写数据的服务.\n* coordinator&influxql 读写数据的抽象接口\n* store是内部具体的存储服务执行者.\n\n## 2. 存储格式\ntsm文件包含4个部分: header, blocks, index和footer.\n\n### 2.1 header\n```\n┌────────┬────────────────────────────────────┬─────────────┬──────────────┐\n│ Header │               Blocks               │    Index    │    Footer    │\n│5 bytes │              N bytes               │   N bytes   │   4 bytes    │\n└────────┴────────────────────────────────────┴─────────────┴──────────────┘\n```\n 头部前4个字节是0x16D116D1标识是tsm文件, 后1个字节是版本号.\n\n```\n┌───────────────────┐\n│      Header       │\n├─────────┬─────────┤\n│  Magic  │ Version │\n│ 4 bytes │ 1 byte  │\n└─────────┴─────────┘\n```\n### 2.2 blocks\n#### 2.2.1 block结构  \n时序数据的基本单位是block，一个block是一个timeseries在一段时间内的数据集合。   \n```\n┌───────────────────────────────────────────────────────────┐\n│                          Blocks                           │\n├───────────────────┬───────────────────┬───────────────────┤\n│      Block 1      │      Block 2      │      Block N      │\n├─────────┬─────────┼─────────┬─────────┼─────────┬─────────┤\n│  CRC    │  Data   │  CRC    │  Data   │  CRC    │  Data   │\n│ 4 bytes │ N bytes │ 4 bytes │ N bytes │ 4 bytes │ N bytes │\n└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘\n```\n\nBlock是读取的最小单元.每个block包括crc和data两部分.\n+ crc用来校验block的数据完整性\n+ data是压缩后的时间戳和value. block格式有多种, 由类型和数据分布决定.\n\n\nblock格式:\n```\n {len timestamp bytes}, {ts bytes}, {value bytes}\n```\n\n#### 2.2.2 压缩\ninfluxdb其中一个最大的卖点是文件压缩率高。一方面可以节省成本，另一方面提升单机的存储能力。\n其中tsm数据文件是主要的数据存储地方。这个文件主要存储了时序数据及在当前文件中快速查找的索引。\n时序数据是最主要的数据，对其压缩方式的选择直接决定了最终数据文件的大小。\n\n##### timestamp:\n* delta相同: {type}, {first}, {delta}, {n} || RLE\n* delta不同且max_delta < (2**60-1): {type}, {first}, {packs}  || simple8\n* delta不同且delta>=(2**60-1) : {type}, {first}, {second} ... | raw\n> 选择压缩方式有点小问题, 应该用max_delta/div的值与2**60-1比较\n\n##### float:\n* 第一个不压缩\n* 与前个值XOR, head tail的0个数, 比之前大: {10},{有效位}\n与前个值XOR, head tail的0个数, 比之前小: {11},{head_5},{len_有效位_6},{有效位}\n* 如果第2个值的head,tail都比较小且后续都比第2个大, 那么会浪费不少空间\n\n\n##### integer\n*  先计算delta, 再用zigzag编码. 把负数转成包含有效1bit尽量少.\n*  delta相同: {type},{first}, {delta}, {n} || RLE\n*  simple8 or raw\n> zigzag: uint64(uint64(x<<1)^uint64((int64(x) >> 63)))\n\n##### boolean\n* 每个值占用1bit  \n* {type}, {len}, {value_bytes}\n\n##### string  \n* {type},{snappy_string}   \n\n\n### 2.3 index\nIndex 存放的是前面 Blocks 里内容的索引。索引条目的顺序是先按照 key 的字典序排序，再按照 time 排序。InfluxDB 在做查询操作时，可以根据 Index 的信息快速定位到 tsm file 中要查询的 block 的位置。\n参考这两个结构体,更容易理解\n```\ntype KeyIndex struct {\n    KeyLen      uint16  //下面一个字段 key 的长度。\n    Key         string  //seriesKey + 分隔符 + fieldName\n    Type        byte  // Block 中 Data 内的数据的类型\n    Count       uint32 //后面紧跟着的 Blocks 索引的个数\n    Blocks      []*BlockIndex\n}\n\ntype BlockIndex struct {\n    MinTime     int64  //block 中 value 的最小时间戳\n    MaxTime     int64  //block 中 value 的最大时间戳\n    Offset      int64  //block 在整个 tsm file 中的偏移量\n    Size        uint32  //block 的大小。根据 Offset + Size 字段就可以快速读取出一个 block 中的内容\n}\n\n┌────────────────────────────────────────────────────────────────────────────┐\n│                                   Index                                    │\n├─────────┬─────────┬──────┬───────┬─────────┬─────────┬────────┬────────┬───┤\n│ Key Len │   Key   │ Type │ Count │Min Time │Max Time │ Offset │  Size  │...│\n│ 2 bytes │ N bytes │1 byte│2 bytes│ 8 bytes │ 8 bytes │8 bytes │4 bytes │   │\n└─────────┴─────────┴──────┴───────┴─────────┴─────────┴────────┴────────┴───┘\n```\n## 2.4 footer\n\nfooter有8个字节, 存储index部分在当前tsm文件里偏移值.\n```\n┌─────────┐\n│ Footer  │\n├─────────┤\n│Index Ofs│\n│ 8 bytes │\n└─────────┘\n```\n\n## 3. 请求处理\n1. 写请求处理链路\n   + http服务接收请求再转给coordinator\n   + coordinator的pointwriter包含store的引用\n   + 根据写请求参数,选择合适的shard. 如没有则创建\n   + 先写入cache,再写wal文件.\n   + 同步的写请求处理完成\n```\n http.serveWrite -> co.pointwriter -> shard -> engine -> cache -> wal\n```\n2. 压缩数据到tsm\n  + 每秒检查是否需要执行compact. 超过cache_max_size和duration_max, 执行compact\n  + 创建cache的snapshot. cache这里用了一个交换机制, 交换snapshot的store和正在提供服务的cache的store.\n  + 创建cacheKeyIteator. 并发执行数据的encode\n  + 遍历iteator,写入到tsm文件.\n\n## 4. 索引合并\n### 4.1 索引日志合并\n在index发生变化(create or drop)时,会在最后一步调用CheckLogFile, 触发tsl合并成tsi文件.  \n\n\n### 4.2 索引文件合并\n在index文件打开时,会创建goroutine不断检查合并tis文件. 索引日志合并最后也会触发索引文件合并.\n","slug":"influxdb-write","published":1,"updated":"2018-02-27T09:05:10.570Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0ze00053l65is3rc6kz","content":"<h2 id=\"1-架构\"><a href=\"#1-架构\" class=\"headerlink\" title=\"1. 架构\"></a>1. 架构</h2>\n<ul>\n<li>service是对外暴露各种读写数据的服务.</li>\n<li>coordinator&amp;influxql 读写数据的抽象接口</li>\n<li>store是内部具体的存储服务执行者.</li>\n</ul>\n<h2 id=\"2-存储格式\"><a href=\"#2-存储格式\" class=\"headerlink\" title=\"2. 存储格式\"></a>2. 存储格式</h2><p>tsm文件包含4个部分: header, blocks, index和footer.</p>\n<h3 id=\"2-1-header\"><a href=\"#2-1-header\" class=\"headerlink\" title=\"2.1 header\"></a>2.1 header</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌────────┬────────────────────────────────────┬─────────────┬──────────────┐</div><div class=\"line\">│ Header │               Blocks               │    Index    │    Footer    │</div><div class=\"line\">│5 bytes │              N bytes               │   N bytes   │   4 bytes    │</div><div class=\"line\">└────────┴────────────────────────────────────┴─────────────┴──────────────┘</div></pre></td></tr></table></figure>\n<p> 头部前4个字节是0x16D116D1标识是tsm文件, 后1个字节是版本号.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌───────────────────┐</div><div class=\"line\">│      Header       │</div><div class=\"line\">├─────────┬─────────┤</div><div class=\"line\">│  Magic  │ Version │</div><div class=\"line\">│ 4 bytes │ 1 byte  │</div><div class=\"line\">└─────────┴─────────┘</div></pre></td></tr></table></figure>\n<h3 id=\"2-2-blocks\"><a href=\"#2-2-blocks\" class=\"headerlink\" title=\"2.2 blocks\"></a>2.2 blocks</h3><h4 id=\"2-2-1-block结构\"><a href=\"#2-2-1-block结构\" class=\"headerlink\" title=\"2.2.1 block结构\"></a>2.2.1 block结构</h4><p>时序数据的基本单位是block，一个block是一个timeseries在一段时间内的数据集合。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌───────────────────────────────────────────────────────────┐</div><div class=\"line\">│                          Blocks                           │</div><div class=\"line\">├───────────────────┬───────────────────┬───────────────────┤</div><div class=\"line\">│      Block 1      │      Block 2      │      Block N      │</div><div class=\"line\">├─────────┬─────────┼─────────┬─────────┼─────────┬─────────┤</div><div class=\"line\">│  CRC    │  Data   │  CRC    │  Data   │  CRC    │  Data   │</div><div class=\"line\">│ 4 bytes │ N bytes │ 4 bytes │ N bytes │ 4 bytes │ N bytes │</div><div class=\"line\">└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘</div></pre></td></tr></table></figure></p>\n<p>Block是读取的最小单元.每个block包括crc和data两部分.</p>\n<ul>\n<li>crc用来校验block的数据完整性</li>\n<li>data是压缩后的时间戳和value. block格式有多种, 由类型和数据分布决定.</li>\n</ul>\n<p>block格式:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;len timestamp bytes&#125;, &#123;ts bytes&#125;, &#123;value bytes&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"2-2-2-压缩\"><a href=\"#2-2-2-压缩\" class=\"headerlink\" title=\"2.2.2 压缩\"></a>2.2.2 压缩</h4><p>influxdb其中一个最大的卖点是文件压缩率高。一方面可以节省成本，另一方面提升单机的存储能力。<br>其中tsm数据文件是主要的数据存储地方。这个文件主要存储了时序数据及在当前文件中快速查找的索引。<br>时序数据是最主要的数据，对其压缩方式的选择直接决定了最终数据文件的大小。</p>\n<h5 id=\"timestamp\"><a href=\"#timestamp\" class=\"headerlink\" title=\"timestamp:\"></a>timestamp:</h5><ul>\n<li>delta相同: {type}, {first}, {delta}, {n} || RLE</li>\n<li>delta不同且max_delta &lt; (2**60-1): {type}, {first}, {packs}  || simple8</li>\n<li>delta不同且delta&gt;=(2**60-1) : {type}, {first}, {second} … | raw<blockquote>\n<p>选择压缩方式有点小问题, 应该用max_delta/div的值与2**60-1比较</p>\n</blockquote>\n</li>\n</ul>\n<h5 id=\"float\"><a href=\"#float\" class=\"headerlink\" title=\"float:\"></a>float:</h5><ul>\n<li>第一个不压缩</li>\n<li>与前个值XOR, head tail的0个数, 比之前大: {10},{有效位}<br>与前个值XOR, head tail的0个数, 比之前小: {11},{head<em>5},{len</em>有效位_6},{有效位}</li>\n<li>如果第2个值的head,tail都比较小且后续都比第2个大, 那么会浪费不少空间</li>\n</ul>\n<h5 id=\"integer\"><a href=\"#integer\" class=\"headerlink\" title=\"integer\"></a>integer</h5><ul>\n<li>先计算delta, 再用zigzag编码. 把负数转成包含有效1bit尽量少.</li>\n<li>delta相同: {type},{first}, {delta}, {n} || RLE</li>\n<li>simple8 or raw<blockquote>\n<p>zigzag: uint64(uint64(x&lt;<1)^uint64((int64(x)>&gt; 63)))</1)^uint64((int64(x)></p>\n</blockquote>\n</li>\n</ul>\n<h5 id=\"boolean\"><a href=\"#boolean\" class=\"headerlink\" title=\"boolean\"></a>boolean</h5><ul>\n<li>每个值占用1bit  </li>\n<li>{type}, {len}, {value_bytes}</li>\n</ul>\n<h5 id=\"string\"><a href=\"#string\" class=\"headerlink\" title=\"string\"></a>string</h5><ul>\n<li>{type},{snappy_string}   </li>\n</ul>\n<h3 id=\"2-3-index\"><a href=\"#2-3-index\" class=\"headerlink\" title=\"2.3 index\"></a>2.3 index</h3><p>Index 存放的是前面 Blocks 里内容的索引。索引条目的顺序是先按照 key 的字典序排序，再按照 time 排序。InfluxDB 在做查询操作时，可以根据 Index 的信息快速定位到 tsm file 中要查询的 block 的位置。<br>参考这两个结构体,更容易理解<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">type KeyIndex struct &#123;</div><div class=\"line\">    KeyLen      uint16  //下面一个字段 key 的长度。</div><div class=\"line\">    Key         string  //seriesKey + 分隔符 + fieldName</div><div class=\"line\">    Type        byte  // Block 中 Data 内的数据的类型</div><div class=\"line\">    Count       uint32 //后面紧跟着的 Blocks 索引的个数</div><div class=\"line\">    Blocks      []*BlockIndex</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">type BlockIndex struct &#123;</div><div class=\"line\">    MinTime     int64  //block 中 value 的最小时间戳</div><div class=\"line\">    MaxTime     int64  //block 中 value 的最大时间戳</div><div class=\"line\">    Offset      int64  //block 在整个 tsm file 中的偏移量</div><div class=\"line\">    Size        uint32  //block 的大小。根据 Offset + Size 字段就可以快速读取出一个 block 中的内容</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">┌────────────────────────────────────────────────────────────────────────────┐</div><div class=\"line\">│                                   Index                                    │</div><div class=\"line\">├─────────┬─────────┬──────┬───────┬─────────┬─────────┬────────┬────────┬───┤</div><div class=\"line\">│ Key Len │   Key   │ Type │ Count │Min Time │Max Time │ Offset │  Size  │...│</div><div class=\"line\">│ 2 bytes │ N bytes │1 byte│2 bytes│ 8 bytes │ 8 bytes │8 bytes │4 bytes │   │</div><div class=\"line\">└─────────┴─────────┴──────┴───────┴─────────┴─────────┴────────┴────────┴───┘</div></pre></td></tr></table></figure></p>\n<h2 id=\"2-4-footer\"><a href=\"#2-4-footer\" class=\"headerlink\" title=\"2.4 footer\"></a>2.4 footer</h2><p>footer有8个字节, 存储index部分在当前tsm文件里偏移值.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌─────────┐</div><div class=\"line\">│ Footer  │</div><div class=\"line\">├─────────┤</div><div class=\"line\">│Index Ofs│</div><div class=\"line\">│ 8 bytes │</div><div class=\"line\">└─────────┘</div></pre></td></tr></table></figure></p>\n<h2 id=\"3-请求处理\"><a href=\"#3-请求处理\" class=\"headerlink\" title=\"3. 请求处理\"></a>3. 请求处理</h2><ol>\n<li><p>写请求处理链路</p>\n<ul>\n<li>http服务接收请求再转给coordinator</li>\n<li>coordinator的pointwriter包含store的引用</li>\n<li>根据写请求参数,选择合适的shard. 如没有则创建</li>\n<li>先写入cache,再写wal文件.</li>\n<li>同步的写请求处理完成<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">http.serveWrite -&gt; co.pointwriter -&gt; shard -&gt; engine -&gt; cache -&gt; wal</div></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>压缩数据到tsm</p>\n<ul>\n<li>每秒检查是否需要执行compact. 超过cache_max_size和duration_max, 执行compact</li>\n<li>创建cache的snapshot. cache这里用了一个交换机制, 交换snapshot的store和正在提供服务的cache的store.</li>\n<li>创建cacheKeyIteator. 并发执行数据的encode</li>\n<li>遍历iteator,写入到tsm文件.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"4-索引合并\"><a href=\"#4-索引合并\" class=\"headerlink\" title=\"4. 索引合并\"></a>4. 索引合并</h2><h3 id=\"4-1-索引日志合并\"><a href=\"#4-1-索引日志合并\" class=\"headerlink\" title=\"4.1 索引日志合并\"></a>4.1 索引日志合并</h3><p>在index发生变化(create or drop)时,会在最后一步调用CheckLogFile, 触发tsl合并成tsi文件.  </p>\n<h3 id=\"4-2-索引文件合并\"><a href=\"#4-2-索引文件合并\" class=\"headerlink\" title=\"4.2 索引文件合并\"></a>4.2 索引文件合并</h3><p>在index文件打开时,会创建goroutine不断检查合并tis文件. 索引日志合并最后也会触发索引文件合并.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-架构\"><a href=\"#1-架构\" class=\"headerlink\" title=\"1. 架构\"></a>1. 架构</h2>\n<ul>\n<li>service是对外暴露各种读写数据的服务.</li>\n<li>coordinator&amp;influxql 读写数据的抽象接口</li>\n<li>store是内部具体的存储服务执行者.</li>\n</ul>\n<h2 id=\"2-存储格式\"><a href=\"#2-存储格式\" class=\"headerlink\" title=\"2. 存储格式\"></a>2. 存储格式</h2><p>tsm文件包含4个部分: header, blocks, index和footer.</p>\n<h3 id=\"2-1-header\"><a href=\"#2-1-header\" class=\"headerlink\" title=\"2.1 header\"></a>2.1 header</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌────────┬────────────────────────────────────┬─────────────┬──────────────┐</div><div class=\"line\">│ Header │               Blocks               │    Index    │    Footer    │</div><div class=\"line\">│5 bytes │              N bytes               │   N bytes   │   4 bytes    │</div><div class=\"line\">└────────┴────────────────────────────────────┴─────────────┴──────────────┘</div></pre></td></tr></table></figure>\n<p> 头部前4个字节是0x16D116D1标识是tsm文件, 后1个字节是版本号.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌───────────────────┐</div><div class=\"line\">│      Header       │</div><div class=\"line\">├─────────┬─────────┤</div><div class=\"line\">│  Magic  │ Version │</div><div class=\"line\">│ 4 bytes │ 1 byte  │</div><div class=\"line\">└─────────┴─────────┘</div></pre></td></tr></table></figure>\n<h3 id=\"2-2-blocks\"><a href=\"#2-2-blocks\" class=\"headerlink\" title=\"2.2 blocks\"></a>2.2 blocks</h3><h4 id=\"2-2-1-block结构\"><a href=\"#2-2-1-block结构\" class=\"headerlink\" title=\"2.2.1 block结构\"></a>2.2.1 block结构</h4><p>时序数据的基本单位是block，一个block是一个timeseries在一段时间内的数据集合。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌───────────────────────────────────────────────────────────┐</div><div class=\"line\">│                          Blocks                           │</div><div class=\"line\">├───────────────────┬───────────────────┬───────────────────┤</div><div class=\"line\">│      Block 1      │      Block 2      │      Block N      │</div><div class=\"line\">├─────────┬─────────┼─────────┬─────────┼─────────┬─────────┤</div><div class=\"line\">│  CRC    │  Data   │  CRC    │  Data   │  CRC    │  Data   │</div><div class=\"line\">│ 4 bytes │ N bytes │ 4 bytes │ N bytes │ 4 bytes │ N bytes │</div><div class=\"line\">└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘</div></pre></td></tr></table></figure></p>\n<p>Block是读取的最小单元.每个block包括crc和data两部分.</p>\n<ul>\n<li>crc用来校验block的数据完整性</li>\n<li>data是压缩后的时间戳和value. block格式有多种, 由类型和数据分布决定.</li>\n</ul>\n<p>block格式:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;len timestamp bytes&#125;, &#123;ts bytes&#125;, &#123;value bytes&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"2-2-2-压缩\"><a href=\"#2-2-2-压缩\" class=\"headerlink\" title=\"2.2.2 压缩\"></a>2.2.2 压缩</h4><p>influxdb其中一个最大的卖点是文件压缩率高。一方面可以节省成本，另一方面提升单机的存储能力。<br>其中tsm数据文件是主要的数据存储地方。这个文件主要存储了时序数据及在当前文件中快速查找的索引。<br>时序数据是最主要的数据，对其压缩方式的选择直接决定了最终数据文件的大小。</p>\n<h5 id=\"timestamp\"><a href=\"#timestamp\" class=\"headerlink\" title=\"timestamp:\"></a>timestamp:</h5><ul>\n<li>delta相同: {type}, {first}, {delta}, {n} || RLE</li>\n<li>delta不同且max_delta &lt; (2**60-1): {type}, {first}, {packs}  || simple8</li>\n<li>delta不同且delta&gt;=(2**60-1) : {type}, {first}, {second} … | raw<blockquote>\n<p>选择压缩方式有点小问题, 应该用max_delta/div的值与2**60-1比较</p>\n</blockquote>\n</li>\n</ul>\n<h5 id=\"float\"><a href=\"#float\" class=\"headerlink\" title=\"float:\"></a>float:</h5><ul>\n<li>第一个不压缩</li>\n<li>与前个值XOR, head tail的0个数, 比之前大: {10},{有效位}<br>与前个值XOR, head tail的0个数, 比之前小: {11},{head<em>5},{len</em>有效位_6},{有效位}</li>\n<li>如果第2个值的head,tail都比较小且后续都比第2个大, 那么会浪费不少空间</li>\n</ul>\n<h5 id=\"integer\"><a href=\"#integer\" class=\"headerlink\" title=\"integer\"></a>integer</h5><ul>\n<li>先计算delta, 再用zigzag编码. 把负数转成包含有效1bit尽量少.</li>\n<li>delta相同: {type},{first}, {delta}, {n} || RLE</li>\n<li>simple8 or raw<blockquote>\n<p>zigzag: uint64(uint64(x&lt;<1)^uint64((int64(x)>&gt; 63)))</1)^uint64((int64(x)></p>\n</blockquote>\n</li>\n</ul>\n<h5 id=\"boolean\"><a href=\"#boolean\" class=\"headerlink\" title=\"boolean\"></a>boolean</h5><ul>\n<li>每个值占用1bit  </li>\n<li>{type}, {len}, {value_bytes}</li>\n</ul>\n<h5 id=\"string\"><a href=\"#string\" class=\"headerlink\" title=\"string\"></a>string</h5><ul>\n<li>{type},{snappy_string}   </li>\n</ul>\n<h3 id=\"2-3-index\"><a href=\"#2-3-index\" class=\"headerlink\" title=\"2.3 index\"></a>2.3 index</h3><p>Index 存放的是前面 Blocks 里内容的索引。索引条目的顺序是先按照 key 的字典序排序，再按照 time 排序。InfluxDB 在做查询操作时，可以根据 Index 的信息快速定位到 tsm file 中要查询的 block 的位置。<br>参考这两个结构体,更容易理解<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">type KeyIndex struct &#123;</div><div class=\"line\">    KeyLen      uint16  //下面一个字段 key 的长度。</div><div class=\"line\">    Key         string  //seriesKey + 分隔符 + fieldName</div><div class=\"line\">    Type        byte  // Block 中 Data 内的数据的类型</div><div class=\"line\">    Count       uint32 //后面紧跟着的 Blocks 索引的个数</div><div class=\"line\">    Blocks      []*BlockIndex</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">type BlockIndex struct &#123;</div><div class=\"line\">    MinTime     int64  //block 中 value 的最小时间戳</div><div class=\"line\">    MaxTime     int64  //block 中 value 的最大时间戳</div><div class=\"line\">    Offset      int64  //block 在整个 tsm file 中的偏移量</div><div class=\"line\">    Size        uint32  //block 的大小。根据 Offset + Size 字段就可以快速读取出一个 block 中的内容</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">┌────────────────────────────────────────────────────────────────────────────┐</div><div class=\"line\">│                                   Index                                    │</div><div class=\"line\">├─────────┬─────────┬──────┬───────┬─────────┬─────────┬────────┬────────┬───┤</div><div class=\"line\">│ Key Len │   Key   │ Type │ Count │Min Time │Max Time │ Offset │  Size  │...│</div><div class=\"line\">│ 2 bytes │ N bytes │1 byte│2 bytes│ 8 bytes │ 8 bytes │8 bytes │4 bytes │   │</div><div class=\"line\">└─────────┴─────────┴──────┴───────┴─────────┴─────────┴────────┴────────┴───┘</div></pre></td></tr></table></figure></p>\n<h2 id=\"2-4-footer\"><a href=\"#2-4-footer\" class=\"headerlink\" title=\"2.4 footer\"></a>2.4 footer</h2><p>footer有8个字节, 存储index部分在当前tsm文件里偏移值.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌─────────┐</div><div class=\"line\">│ Footer  │</div><div class=\"line\">├─────────┤</div><div class=\"line\">│Index Ofs│</div><div class=\"line\">│ 8 bytes │</div><div class=\"line\">└─────────┘</div></pre></td></tr></table></figure></p>\n<h2 id=\"3-请求处理\"><a href=\"#3-请求处理\" class=\"headerlink\" title=\"3. 请求处理\"></a>3. 请求处理</h2><ol>\n<li><p>写请求处理链路</p>\n<ul>\n<li>http服务接收请求再转给coordinator</li>\n<li>coordinator的pointwriter包含store的引用</li>\n<li>根据写请求参数,选择合适的shard. 如没有则创建</li>\n<li>先写入cache,再写wal文件.</li>\n<li>同步的写请求处理完成<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">http.serveWrite -&gt; co.pointwriter -&gt; shard -&gt; engine -&gt; cache -&gt; wal</div></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>压缩数据到tsm</p>\n<ul>\n<li>每秒检查是否需要执行compact. 超过cache_max_size和duration_max, 执行compact</li>\n<li>创建cache的snapshot. cache这里用了一个交换机制, 交换snapshot的store和正在提供服务的cache的store.</li>\n<li>创建cacheKeyIteator. 并发执行数据的encode</li>\n<li>遍历iteator,写入到tsm文件.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"4-索引合并\"><a href=\"#4-索引合并\" class=\"headerlink\" title=\"4. 索引合并\"></a>4. 索引合并</h2><h3 id=\"4-1-索引日志合并\"><a href=\"#4-1-索引日志合并\" class=\"headerlink\" title=\"4.1 索引日志合并\"></a>4.1 索引日志合并</h3><p>在index发生变化(create or drop)时,会在最后一步调用CheckLogFile, 触发tsl合并成tsi文件.  </p>\n<h3 id=\"4-2-索引文件合并\"><a href=\"#4-2-索引文件合并\" class=\"headerlink\" title=\"4.2 索引文件合并\"></a>4.2 索引文件合并</h3><p>在index文件打开时,会创建goroutine不断检查合并tis文件. 索引日志合并最后也会触发索引文件合并.</p>\n"},{"title":"influxdb-cluster","date":"2017-11-01T04:31:38.000Z","_content":"### 结构\n1. meta node：元数据的写，读。\n2. data node：数据的写，读\n```\n┌───────┐     ┌───────┐      \n│       │     │       │      \n│ Meta1 │◀───▶│ Meta2 │      \n│       │     │       │      \n└───────┘     └───────┘      \n    ▲             ▲          \n    │             │          \n    │  ┌───────┐  │          \n    │  │       │  │          \n    └─▶│ Meta3 │◀─┘          \n       │       │             \n       └───────┘             \n\n─────────────────────────────────\n      ╲│╱    ╲│╱             \n  ┌────┘      └──────┐       \n  │                  │       \n┌───────┐          ┌───────┐   \n│       │          │       │   \n│ Data1 │◀────────▶│ Data2 │   \n│       │          │       │   \n└───────┘          └───────┘   \n```\n\n### 写过程\n数据的分布。 有两级划分，先时间段划分成shardgroup，每个里面包含一段时间内的数据。\n时间段长度有创建的rp决定。再按照数据的measurement+tags进行hash后划分，分配到每个shard。\n每个shard落在具体的datanode机器上。\n\nshardgroup里shard个数由总机器数/复制因子算出来，取整数。每个shard根据配置的复制因子再确定出所属的\ndatanode机器。  \n\n因此写入数据时，由datanode接收写请求，根据写请求参数查询meta信息（本地缓存或者meta node）。\n结合meta信息，对于每个点，先根据timestamp路由到对应的shardgroup，再根据measurement+tags\n路由到shard，最后在把数据分别发送给对应的datanode，剩下的就是单机的写入流程。\n\n前述这些shardgorup，shard在创建shardgroup时创建好的。上述关联信息都保存在metanode中。\n\n### 读过程\n   读数据也是由datanode处理的， 请求可以落到任意一台datanode上，和Cassandra很类似。\n根据读请求查询meta信息（本地缓存或者meta node），根据时间的start，end确定shardgroup，\n然后再找到shardgroup下所有的shard，再从shard关联的datanode中选择其中一个放入请求列表，\n然后并行把请求发送给实际存储数据的datanode，最后合并分布式查询结果，并返回给客户端。\n\n## 如何提高查询能力\n按照场景进行划分\n+ 数据分析\n验证想法，频率低。可以支持功能，但是限制查询频率\n+ 数据应用\n查询参数基本一样，仅仅时间range不一样。预聚合进入tsdb。\n查询语句转换成预聚合查询结果的查询\n\n因此可以抽象出三个组件。\n+ store\nkv的查询模式。\n\n+ stream\n聚合流式计算\n\n+ proxy\n查询入口，采集分析查询语句的频率，生成预聚合规则。\n\n\n### 参考资料\n1. [first:google gorup](https://groups.google.com/forum/#!msg/influxdb/3jQQMXmXd6Q/cGcmFjM-f8YJ)\n2. [0.9.0]( https://www.influxdata.com/blog/clustering-tags-and-enhancements-to-come-in-0-9-0/#signup)\n","source":"_posts/2017-11-01-influxdb-cluster.md","raw":"---\ntitle: influxdb-cluster\ndate: 2017-11-01 12:31:38\ntags:\n---\n### 结构\n1. meta node：元数据的写，读。\n2. data node：数据的写，读\n```\n┌───────┐     ┌───────┐      \n│       │     │       │      \n│ Meta1 │◀───▶│ Meta2 │      \n│       │     │       │      \n└───────┘     └───────┘      \n    ▲             ▲          \n    │             │          \n    │  ┌───────┐  │          \n    │  │       │  │          \n    └─▶│ Meta3 │◀─┘          \n       │       │             \n       └───────┘             \n\n─────────────────────────────────\n      ╲│╱    ╲│╱             \n  ┌────┘      └──────┐       \n  │                  │       \n┌───────┐          ┌───────┐   \n│       │          │       │   \n│ Data1 │◀────────▶│ Data2 │   \n│       │          │       │   \n└───────┘          └───────┘   \n```\n\n### 写过程\n数据的分布。 有两级划分，先时间段划分成shardgroup，每个里面包含一段时间内的数据。\n时间段长度有创建的rp决定。再按照数据的measurement+tags进行hash后划分，分配到每个shard。\n每个shard落在具体的datanode机器上。\n\nshardgroup里shard个数由总机器数/复制因子算出来，取整数。每个shard根据配置的复制因子再确定出所属的\ndatanode机器。  \n\n因此写入数据时，由datanode接收写请求，根据写请求参数查询meta信息（本地缓存或者meta node）。\n结合meta信息，对于每个点，先根据timestamp路由到对应的shardgroup，再根据measurement+tags\n路由到shard，最后在把数据分别发送给对应的datanode，剩下的就是单机的写入流程。\n\n前述这些shardgorup，shard在创建shardgroup时创建好的。上述关联信息都保存在metanode中。\n\n### 读过程\n   读数据也是由datanode处理的， 请求可以落到任意一台datanode上，和Cassandra很类似。\n根据读请求查询meta信息（本地缓存或者meta node），根据时间的start，end确定shardgroup，\n然后再找到shardgroup下所有的shard，再从shard关联的datanode中选择其中一个放入请求列表，\n然后并行把请求发送给实际存储数据的datanode，最后合并分布式查询结果，并返回给客户端。\n\n## 如何提高查询能力\n按照场景进行划分\n+ 数据分析\n验证想法，频率低。可以支持功能，但是限制查询频率\n+ 数据应用\n查询参数基本一样，仅仅时间range不一样。预聚合进入tsdb。\n查询语句转换成预聚合查询结果的查询\n\n因此可以抽象出三个组件。\n+ store\nkv的查询模式。\n\n+ stream\n聚合流式计算\n\n+ proxy\n查询入口，采集分析查询语句的频率，生成预聚合规则。\n\n\n### 参考资料\n1. [first:google gorup](https://groups.google.com/forum/#!msg/influxdb/3jQQMXmXd6Q/cGcmFjM-f8YJ)\n2. [0.9.0]( https://www.influxdata.com/blog/clustering-tags-and-enhancements-to-come-in-0-9-0/#signup)\n","slug":"influxdb-cluster","published":1,"updated":"2018-04-17T04:00:01.777Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zf00073l65h2arprzl","content":"<h3 id=\"结构\"><a href=\"#结构\" class=\"headerlink\" title=\"结构\"></a>结构</h3><ol>\n<li>meta node：元数据的写，读。</li>\n<li>data node：数据的写，读<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌───────┐     ┌───────┐      </div><div class=\"line\">│       │     │       │      </div><div class=\"line\">│ Meta1 │◀───▶│ Meta2 │      </div><div class=\"line\">│       │     │       │      </div><div class=\"line\">└───────┘     └───────┘      </div><div class=\"line\">    ▲             ▲          </div><div class=\"line\">    │             │          </div><div class=\"line\">    │  ┌───────┐  │          </div><div class=\"line\">    │  │       │  │          </div><div class=\"line\">    └─▶│ Meta3 │◀─┘          </div><div class=\"line\">       │       │             </div><div class=\"line\">       └───────┘             </div><div class=\"line\"></div><div class=\"line\">─────────────────────────────────</div><div class=\"line\">      ╲│╱    ╲│╱             </div><div class=\"line\">  ┌────┘      └──────┐       </div><div class=\"line\">  │                  │       </div><div class=\"line\">┌───────┐          ┌───────┐   </div><div class=\"line\">│       │          │       │   </div><div class=\"line\">│ Data1 │◀────────▶│ Data2 │   </div><div class=\"line\">│       │          │       │   </div><div class=\"line\">└───────┘          └───────┘</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"写过程\"><a href=\"#写过程\" class=\"headerlink\" title=\"写过程\"></a>写过程</h3><p>数据的分布。 有两级划分，先时间段划分成shardgroup，每个里面包含一段时间内的数据。<br>时间段长度有创建的rp决定。再按照数据的measurement+tags进行hash后划分，分配到每个shard。<br>每个shard落在具体的datanode机器上。</p>\n<p>shardgroup里shard个数由总机器数/复制因子算出来，取整数。每个shard根据配置的复制因子再确定出所属的<br>datanode机器。  </p>\n<p>因此写入数据时，由datanode接收写请求，根据写请求参数查询meta信息（本地缓存或者meta node）。<br>结合meta信息，对于每个点，先根据timestamp路由到对应的shardgroup，再根据measurement+tags<br>路由到shard，最后在把数据分别发送给对应的datanode，剩下的就是单机的写入流程。</p>\n<p>前述这些shardgorup，shard在创建shardgroup时创建好的。上述关联信息都保存在metanode中。</p>\n<h3 id=\"读过程\"><a href=\"#读过程\" class=\"headerlink\" title=\"读过程\"></a>读过程</h3><p>   读数据也是由datanode处理的， 请求可以落到任意一台datanode上，和Cassandra很类似。<br>根据读请求查询meta信息（本地缓存或者meta node），根据时间的start，end确定shardgroup，<br>然后再找到shardgroup下所有的shard，再从shard关联的datanode中选择其中一个放入请求列表，<br>然后并行把请求发送给实际存储数据的datanode，最后合并分布式查询结果，并返回给客户端。</p>\n<h2 id=\"如何提高查询能力\"><a href=\"#如何提高查询能力\" class=\"headerlink\" title=\"如何提高查询能力\"></a>如何提高查询能力</h2><p>按照场景进行划分</p>\n<ul>\n<li>数据分析<br>验证想法，频率低。可以支持功能，但是限制查询频率</li>\n<li>数据应用<br>查询参数基本一样，仅仅时间range不一样。预聚合进入tsdb。<br>查询语句转换成预聚合查询结果的查询</li>\n</ul>\n<p>因此可以抽象出三个组件。</p>\n<ul>\n<li><p>store<br>kv的查询模式。</p>\n</li>\n<li><p>stream<br>聚合流式计算</p>\n</li>\n<li><p>proxy<br>查询入口，采集分析查询语句的频率，生成预聚合规则。</p>\n</li>\n</ul>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ol>\n<li><a href=\"https://groups.google.com/forum/#!msg/influxdb/3jQQMXmXd6Q/cGcmFjM-f8YJ\" target=\"_blank\" rel=\"noopener\">first:google gorup</a></li>\n<li><a href=\"https://www.influxdata.com/blog/clustering-tags-and-enhancements-to-come-in-0-9-0/#signup\" target=\"_blank\" rel=\"noopener\">0.9.0</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"结构\"><a href=\"#结构\" class=\"headerlink\" title=\"结构\"></a>结构</h3><ol>\n<li>meta node：元数据的写，读。</li>\n<li>data node：数据的写，读<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">┌───────┐     ┌───────┐      </div><div class=\"line\">│       │     │       │      </div><div class=\"line\">│ Meta1 │◀───▶│ Meta2 │      </div><div class=\"line\">│       │     │       │      </div><div class=\"line\">└───────┘     └───────┘      </div><div class=\"line\">    ▲             ▲          </div><div class=\"line\">    │             │          </div><div class=\"line\">    │  ┌───────┐  │          </div><div class=\"line\">    │  │       │  │          </div><div class=\"line\">    └─▶│ Meta3 │◀─┘          </div><div class=\"line\">       │       │             </div><div class=\"line\">       └───────┘             </div><div class=\"line\"></div><div class=\"line\">─────────────────────────────────</div><div class=\"line\">      ╲│╱    ╲│╱             </div><div class=\"line\">  ┌────┘      └──────┐       </div><div class=\"line\">  │                  │       </div><div class=\"line\">┌───────┐          ┌───────┐   </div><div class=\"line\">│       │          │       │   </div><div class=\"line\">│ Data1 │◀────────▶│ Data2 │   </div><div class=\"line\">│       │          │       │   </div><div class=\"line\">└───────┘          └───────┘</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"写过程\"><a href=\"#写过程\" class=\"headerlink\" title=\"写过程\"></a>写过程</h3><p>数据的分布。 有两级划分，先时间段划分成shardgroup，每个里面包含一段时间内的数据。<br>时间段长度有创建的rp决定。再按照数据的measurement+tags进行hash后划分，分配到每个shard。<br>每个shard落在具体的datanode机器上。</p>\n<p>shardgroup里shard个数由总机器数/复制因子算出来，取整数。每个shard根据配置的复制因子再确定出所属的<br>datanode机器。  </p>\n<p>因此写入数据时，由datanode接收写请求，根据写请求参数查询meta信息（本地缓存或者meta node）。<br>结合meta信息，对于每个点，先根据timestamp路由到对应的shardgroup，再根据measurement+tags<br>路由到shard，最后在把数据分别发送给对应的datanode，剩下的就是单机的写入流程。</p>\n<p>前述这些shardgorup，shard在创建shardgroup时创建好的。上述关联信息都保存在metanode中。</p>\n<h3 id=\"读过程\"><a href=\"#读过程\" class=\"headerlink\" title=\"读过程\"></a>读过程</h3><p>   读数据也是由datanode处理的， 请求可以落到任意一台datanode上，和Cassandra很类似。<br>根据读请求查询meta信息（本地缓存或者meta node），根据时间的start，end确定shardgroup，<br>然后再找到shardgroup下所有的shard，再从shard关联的datanode中选择其中一个放入请求列表，<br>然后并行把请求发送给实际存储数据的datanode，最后合并分布式查询结果，并返回给客户端。</p>\n<h2 id=\"如何提高查询能力\"><a href=\"#如何提高查询能力\" class=\"headerlink\" title=\"如何提高查询能力\"></a>如何提高查询能力</h2><p>按照场景进行划分</p>\n<ul>\n<li>数据分析<br>验证想法，频率低。可以支持功能，但是限制查询频率</li>\n<li>数据应用<br>查询参数基本一样，仅仅时间range不一样。预聚合进入tsdb。<br>查询语句转换成预聚合查询结果的查询</li>\n</ul>\n<p>因此可以抽象出三个组件。</p>\n<ul>\n<li><p>store<br>kv的查询模式。</p>\n</li>\n<li><p>stream<br>聚合流式计算</p>\n</li>\n<li><p>proxy<br>查询入口，采集分析查询语句的频率，生成预聚合规则。</p>\n</li>\n</ul>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ol>\n<li><a href=\"https://groups.google.com/forum/#!msg/influxdb/3jQQMXmXd6Q/cGcmFjM-f8YJ\" target=\"_blank\" rel=\"noopener\">first:google gorup</a></li>\n<li><a href=\"https://www.influxdata.com/blog/clustering-tags-and-enhancements-to-come-in-0-9-0/#signup\" target=\"_blank\" rel=\"noopener\">0.9.0</a></li>\n</ol>\n"},{"title":"20171113-misc","date":"2017-11-13T02:11:47.000Z","_content":"\n### goland下载失败解决办法\ngoland是个很好用的go语言ide，推荐使用。目前还是试用预览的EAP版本，直接在官方网站下载，\n在我的笔记本上，会报500错误。    \n```\n{\"errors\":[{\"code\":500,\"message\":\"Index: 0, Size: 0\"}]}\n```\n\n解决办法：\n1. 找到直接下载地址，见下面。\n2. 到官网下载页找到最新的版本号，比如73.3415.23。\n3. 替换下载地址里的版本为最新的，然后使用迅雷下载。\n4. 预览版一般只有1-2月的使用期限，到期后找到新版本号，重新下载即可。\n```\n不同平台的直接下载链接:\nhttp://download.jetbrains.com/go/gogland-163.10154.18.dmg\nhttp://download.jetbrains.com/go/gogland-163.10154.18.exe\nhttp://download.jetbrains.com/go/gogland-163.10154.18.tar.gz\n```\n### Atom的使用文档\n[atom飞行手册](https://wizardforcel.gitbooks.io/atom-flight-manual-zh-cn/content/1.2-Installing-Atom.html)\n","source":"_posts/2017-11-13-misc.md","raw":"---\ntitle: 20171113-misc\ndate: 2017-11-13 10:11:47\ntags:\n---\n\n### goland下载失败解决办法\ngoland是个很好用的go语言ide，推荐使用。目前还是试用预览的EAP版本，直接在官方网站下载，\n在我的笔记本上，会报500错误。    \n```\n{\"errors\":[{\"code\":500,\"message\":\"Index: 0, Size: 0\"}]}\n```\n\n解决办法：\n1. 找到直接下载地址，见下面。\n2. 到官网下载页找到最新的版本号，比如73.3415.23。\n3. 替换下载地址里的版本为最新的，然后使用迅雷下载。\n4. 预览版一般只有1-2月的使用期限，到期后找到新版本号，重新下载即可。\n```\n不同平台的直接下载链接:\nhttp://download.jetbrains.com/go/gogland-163.10154.18.dmg\nhttp://download.jetbrains.com/go/gogland-163.10154.18.exe\nhttp://download.jetbrains.com/go/gogland-163.10154.18.tar.gz\n```\n### Atom的使用文档\n[atom飞行手册](https://wizardforcel.gitbooks.io/atom-flight-manual-zh-cn/content/1.2-Installing-Atom.html)\n","slug":"misc","published":1,"updated":"2018-05-24T01:50:51.699Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zg00083l65wl4jj85s","content":"<h3 id=\"goland下载失败解决办法\"><a href=\"#goland下载失败解决办法\" class=\"headerlink\" title=\"goland下载失败解决办法\"></a>goland下载失败解决办法</h3><p>goland是个很好用的go语言ide，推荐使用。目前还是试用预览的EAP版本，直接在官方网站下载，<br>在我的笔记本上，会报500错误。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;&quot;errors&quot;:[&#123;&quot;code&quot;:500,&quot;message&quot;:&quot;Index: 0, Size: 0&quot;&#125;]&#125;</div></pre></td></tr></table></figure></p>\n<p>解决办法：</p>\n<ol>\n<li>找到直接下载地址，见下面。</li>\n<li>到官网下载页找到最新的版本号，比如73.3415.23。</li>\n<li>替换下载地址里的版本为最新的，然后使用迅雷下载。</li>\n<li>预览版一般只有1-2月的使用期限，到期后找到新版本号，重新下载即可。<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">不同平台的直接下载链接:</div><div class=\"line\">http://download.jetbrains.com/go/gogland-163.10154.18.dmg</div><div class=\"line\">http://download.jetbrains.com/go/gogland-163.10154.18.exe</div><div class=\"line\">http://download.jetbrains.com/go/gogland-163.10154.18.tar.gz</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"Atom的使用文档\"><a href=\"#Atom的使用文档\" class=\"headerlink\" title=\"Atom的使用文档\"></a>Atom的使用文档</h3><p><a href=\"https://wizardforcel.gitbooks.io/atom-flight-manual-zh-cn/content/1.2-Installing-Atom.html\" target=\"_blank\" rel=\"noopener\">atom飞行手册</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"goland下载失败解决办法\"><a href=\"#goland下载失败解决办法\" class=\"headerlink\" title=\"goland下载失败解决办法\"></a>goland下载失败解决办法</h3><p>goland是个很好用的go语言ide，推荐使用。目前还是试用预览的EAP版本，直接在官方网站下载，<br>在我的笔记本上，会报500错误。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;&quot;errors&quot;:[&#123;&quot;code&quot;:500,&quot;message&quot;:&quot;Index: 0, Size: 0&quot;&#125;]&#125;</div></pre></td></tr></table></figure></p>\n<p>解决办法：</p>\n<ol>\n<li>找到直接下载地址，见下面。</li>\n<li>到官网下载页找到最新的版本号，比如73.3415.23。</li>\n<li>替换下载地址里的版本为最新的，然后使用迅雷下载。</li>\n<li>预览版一般只有1-2月的使用期限，到期后找到新版本号，重新下载即可。<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">不同平台的直接下载链接:</div><div class=\"line\">http://download.jetbrains.com/go/gogland-163.10154.18.dmg</div><div class=\"line\">http://download.jetbrains.com/go/gogland-163.10154.18.exe</div><div class=\"line\">http://download.jetbrains.com/go/gogland-163.10154.18.tar.gz</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"Atom的使用文档\"><a href=\"#Atom的使用文档\" class=\"headerlink\" title=\"Atom的使用文档\"></a>Atom的使用文档</h3><p><a href=\"https://wizardforcel.gitbooks.io/atom-flight-manual-zh-cn/content/1.2-Installing-Atom.html\" target=\"_blank\" rel=\"noopener\">atom飞行手册</a></p>\n"},{"title":"tsdb_requirements","date":"2017-11-17T02:17:28.000Z","_content":"\n   以下内容主要翻译自Baron Schwartz的《Time-Series Database Requirements》\n\n## 1. 数据类型\n  时间序列可以定义成下面这样：\n+ 一个时间序列可以被source_name(source_id)和metric_name(metric_id)唯一标识。\n+ 一个时间序列由一系列{时间戳，值}组成，并按照时间戳排序。时间戳通常是高精度的Unix时间戳,\n值通常是浮点数。\n\n> 以opentsdb为代表的常见tsdb中的数据模型，都有tags的概念。\n从逻辑上看， tags也是时间序列唯一标识的组成部分。\n把tags提取出来，并进行kv切分，有利于执行时间线间的过滤和聚合操作。\n对tags添加一定的索引，可以提高数据的查询性能。\n\n## 2. 读写操作的特点\n   时间序列数据不是通用类型， 它们有自己的特点。一个时间序列数据库必须根据这些特点进行相应的优化。\n\n## 2.1 写\n+ 写是最常见的。通常95%-99%的操作都是写，有时更高\n+ 写入的数据通常是顺序追加的。写请求通常是按时间顺序到来的。对于TSDB这是很重要的一个限制。\n+ 很少遇到写入遥远过去的数据。最坏情况下，测量到的数据也需要在几秒或者几分钟内被写入。\n+ 更新也是很少见的。\n+ 删除是批量的，从过去某个时间开始往前所有连续的数据，例如当前时间7天以前的所有数据。删除独立的值\n或者删除随机时间范围内的值，也是罕见的。高效的批量删除很重要，尽量做到零成本。\n+ 综上所述，选择不可变的存储格式可能是好事情。使用不可变的存储格式的后果是，预定义或者固定数据范式\n在长期以后会出现问题。\n\n## 2.2 读\n+ 数据比内存大得多且很少被读取，所以缓存通常不能很好地工作。TSDB系统通常容易出现是IO制约。\n+ 读取的数据通常每个时间序列都是连续的且排序的， 按时间戳升序或者降序。\n+ 并发读或者一次读多个时间序列也是常见合理的。\n\n写入得数据按顺序到达， 一般是按{timestamp, series_id}排序，而读结果通常是按{series_id, timestamp}排序。\n读请求尽管很少，但是需要很快。通常有两种方式来处理读写。首先是写优先，数据在落盘时，没有按时间序列进行优化分布。\n读的时候使用大量的算力并行顺序地扫描所有数据。第二种是在写过程多做一些事情，把数据按时间序列分别打包到一起并且\n为顺序读做优化。\n\n## 3. 性能和容量的特点\n一个时间序列数据库应该有下面的特点：\n+ 为分布式设计-集群和分片。数据自动分布，查询自动分布。必须是容错和高可用的，通过内置数据复制和自动故障转移。\n有一些在这方面做得很好的数据库可以参考，天然分布式已经不是传说了。\n+ 把查询给数据，不要把数据给查询。 这是对查询自动分配的重申。查询可能涉及许多GB甚至TB的数据，所以\n跨网络移动是不可扩展的。\n+ 每个节点都是高效的，它可以运行大量的数据，这样就不必需要上千个节点了。\n+ 支持使用最新的高性能硬件。例如PCIe 闪存，大量内存，多核CPU.\n+ 快速和一致性。没有尖峰和停滞。执行检查点不会冻结，压缩数据不会锁住。\n\n## 4. 运维需求\n+ TSDB虽然不强调ACID, 但是当出现故障时，需要能快速把数据恢复到一致的状态。时间序列数据不像财务数据\n那样对持久性要求那么高\n+ 非阻塞的备份机制是必须的。增量备份也是个好东西\n+ 集群扩容或者缩容，不需要停机或者锁住。\n+ 压缩的存储。时间序列数据量很大，需要很高压缩率\n+ 需要很好的监控和展示运行时状态。\n\n## 5. 查询语言和API\n  我曾与许多为大公司建立大型时间序列数据库的人交谈。 他们中的大多数人告诉我，\n缺乏访问和查询数据库的高级方式是他们脖子上的长期磨刀石(负债)。\n\n我喜欢influxdb查询语言那样像sql的东西。最重要的是，要避免一些sql语言里传统限制。\nSQL表格是固定宽度的，并通过添加行向下增长。\n一个自然的结果是，SQL语句中的每一列都是事先已知的，并且是明确命名的，并且表达式自然地在一行内工作，\n或者在一组行中聚合，但是不能在没有JOIN的情况下跨越行工作\n\n但是，在时间序列数据库中，行是由“主键”标识的系列。随着新测量的添加，行增长横向，添加新系列时表向下增长，列是时间戳。\n因此，表格是稀疏矩阵。 表达式必须在稀疏矩阵的矩形部分进行聚合，而不仅仅是行或列，语言必须在两个方向上都允许有GROUP BY功能。\n你可以说，行和列都必须可以通过键而不是字面标识符来寻址，并且理想情况下除了严格的相等和范围之外，还可以通过模式匹配来寻址。\n\n理想情况下，查询语言和数据库应该至少支持以下服务器端处理工作，可能还有更多：\n+ 表达式，如算术和字符串操作\n+ 聚合函数\n+ 降精度，重新采样到不同的时间精度，不同的存储介质存放不同精度的数据\n+ 不同时间序列间的表达式和操作符，例如以将不同时间序列求和或相除\n+ 组合表达式，例如求和所有标识符与模式匹配的时间系列，然后将结果除以另一组时间系列的总和\n+ 支持order、rank、limit等操作\n\n另一种说法是，查询语言和数据库应该设计用于分析，而不仅仅是绘制带状图。许多开源时间序列数据库（如RRDTool）\n与他们的预期使用方式紧密耦合，这是一个严重的限制。\n\n应该有一个支持批量插入的高效的二进制协议。\n\n## 6. 非功能需求\n\n我想要一个能够很好地完成一件事情的数据库。 我不认为我需要以下任何一种，我认为他们是中立的，或者在某些情况下甚至是缺点：\n+ 访问控制 - 认证和授权。\n+ 能够可视化数据，绘制图形等\n+ 在同一时间戳支持多种测量。 测量的主键是系列，时间戳，并且允许具有相同时间戳的多个值没有意义。\n+ 多维性。 一系列的多维可以存储为多个系列，多个系列可以与我指定的查询语言组合在表达式中，因此“系列”的原子已经提供了多维度的用例。\n+ 使用额外的特定键值对来“标记”测量或系列。\n+ 时间序列数据关联关系数据。\n\n## 7. 其它需求\n从我的角度来看，前面的部分描述了一个很好的通用时间序列数据库。 不错的功能可能包括：\n+ 支持保留策略。\n+ 支持以多种时间精度存储数据并选择适当的时间精度以访问给定请求。\n+ 支持自动降精度\n+ 支持查询优先级或准入控制，以防止大型查询和DOS攻击影响到服务稳定性。\n\n对于我的特殊用途，我还需要支持：\n+ 集群中任一单台服务器可以存储很多时间序列, 远远超过文件目录中的文件数量.\n+ 虽然一些系列是长寿的，但很多系列并非如此. 很多都很稀少，很长一段时间只有一次测量.\n 系列是动态的，不是预定义的; 新时间序列可能随时出现。\n 由于这个要求，我需要高效的支持来发现在任何给定的时间范围内存在哪些时间序列。\n+ 物理层面的多租户。 这部分是由需求决定的; 有些客户希望知道他们的数据与其他客户的数据是分开的。\n这是部分实用的，以支持诸如每个客户的单独保留策略之类的功能。\n\n## 8. 结论\n“大数据”的未来主要是时间序列数据。 为这种用例创建一个好的时间序列数据库的人可能会做得很好。\n我确定我的要求并不是最通用或最完整的，但我希望分享是有用的。\n","source":"_posts/2017-11-17-tsdb-requirements.md","raw":"---\ntitle: tsdb_requirements\ndate: 2017-11-17 10:17:28\ntags: tsdb\n---\n\n   以下内容主要翻译自Baron Schwartz的《Time-Series Database Requirements》\n\n## 1. 数据类型\n  时间序列可以定义成下面这样：\n+ 一个时间序列可以被source_name(source_id)和metric_name(metric_id)唯一标识。\n+ 一个时间序列由一系列{时间戳，值}组成，并按照时间戳排序。时间戳通常是高精度的Unix时间戳,\n值通常是浮点数。\n\n> 以opentsdb为代表的常见tsdb中的数据模型，都有tags的概念。\n从逻辑上看， tags也是时间序列唯一标识的组成部分。\n把tags提取出来，并进行kv切分，有利于执行时间线间的过滤和聚合操作。\n对tags添加一定的索引，可以提高数据的查询性能。\n\n## 2. 读写操作的特点\n   时间序列数据不是通用类型， 它们有自己的特点。一个时间序列数据库必须根据这些特点进行相应的优化。\n\n## 2.1 写\n+ 写是最常见的。通常95%-99%的操作都是写，有时更高\n+ 写入的数据通常是顺序追加的。写请求通常是按时间顺序到来的。对于TSDB这是很重要的一个限制。\n+ 很少遇到写入遥远过去的数据。最坏情况下，测量到的数据也需要在几秒或者几分钟内被写入。\n+ 更新也是很少见的。\n+ 删除是批量的，从过去某个时间开始往前所有连续的数据，例如当前时间7天以前的所有数据。删除独立的值\n或者删除随机时间范围内的值，也是罕见的。高效的批量删除很重要，尽量做到零成本。\n+ 综上所述，选择不可变的存储格式可能是好事情。使用不可变的存储格式的后果是，预定义或者固定数据范式\n在长期以后会出现问题。\n\n## 2.2 读\n+ 数据比内存大得多且很少被读取，所以缓存通常不能很好地工作。TSDB系统通常容易出现是IO制约。\n+ 读取的数据通常每个时间序列都是连续的且排序的， 按时间戳升序或者降序。\n+ 并发读或者一次读多个时间序列也是常见合理的。\n\n写入得数据按顺序到达， 一般是按{timestamp, series_id}排序，而读结果通常是按{series_id, timestamp}排序。\n读请求尽管很少，但是需要很快。通常有两种方式来处理读写。首先是写优先，数据在落盘时，没有按时间序列进行优化分布。\n读的时候使用大量的算力并行顺序地扫描所有数据。第二种是在写过程多做一些事情，把数据按时间序列分别打包到一起并且\n为顺序读做优化。\n\n## 3. 性能和容量的特点\n一个时间序列数据库应该有下面的特点：\n+ 为分布式设计-集群和分片。数据自动分布，查询自动分布。必须是容错和高可用的，通过内置数据复制和自动故障转移。\n有一些在这方面做得很好的数据库可以参考，天然分布式已经不是传说了。\n+ 把查询给数据，不要把数据给查询。 这是对查询自动分配的重申。查询可能涉及许多GB甚至TB的数据，所以\n跨网络移动是不可扩展的。\n+ 每个节点都是高效的，它可以运行大量的数据，这样就不必需要上千个节点了。\n+ 支持使用最新的高性能硬件。例如PCIe 闪存，大量内存，多核CPU.\n+ 快速和一致性。没有尖峰和停滞。执行检查点不会冻结，压缩数据不会锁住。\n\n## 4. 运维需求\n+ TSDB虽然不强调ACID, 但是当出现故障时，需要能快速把数据恢复到一致的状态。时间序列数据不像财务数据\n那样对持久性要求那么高\n+ 非阻塞的备份机制是必须的。增量备份也是个好东西\n+ 集群扩容或者缩容，不需要停机或者锁住。\n+ 压缩的存储。时间序列数据量很大，需要很高压缩率\n+ 需要很好的监控和展示运行时状态。\n\n## 5. 查询语言和API\n  我曾与许多为大公司建立大型时间序列数据库的人交谈。 他们中的大多数人告诉我，\n缺乏访问和查询数据库的高级方式是他们脖子上的长期磨刀石(负债)。\n\n我喜欢influxdb查询语言那样像sql的东西。最重要的是，要避免一些sql语言里传统限制。\nSQL表格是固定宽度的，并通过添加行向下增长。\n一个自然的结果是，SQL语句中的每一列都是事先已知的，并且是明确命名的，并且表达式自然地在一行内工作，\n或者在一组行中聚合，但是不能在没有JOIN的情况下跨越行工作\n\n但是，在时间序列数据库中，行是由“主键”标识的系列。随着新测量的添加，行增长横向，添加新系列时表向下增长，列是时间戳。\n因此，表格是稀疏矩阵。 表达式必须在稀疏矩阵的矩形部分进行聚合，而不仅仅是行或列，语言必须在两个方向上都允许有GROUP BY功能。\n你可以说，行和列都必须可以通过键而不是字面标识符来寻址，并且理想情况下除了严格的相等和范围之外，还可以通过模式匹配来寻址。\n\n理想情况下，查询语言和数据库应该至少支持以下服务器端处理工作，可能还有更多：\n+ 表达式，如算术和字符串操作\n+ 聚合函数\n+ 降精度，重新采样到不同的时间精度，不同的存储介质存放不同精度的数据\n+ 不同时间序列间的表达式和操作符，例如以将不同时间序列求和或相除\n+ 组合表达式，例如求和所有标识符与模式匹配的时间系列，然后将结果除以另一组时间系列的总和\n+ 支持order、rank、limit等操作\n\n另一种说法是，查询语言和数据库应该设计用于分析，而不仅仅是绘制带状图。许多开源时间序列数据库（如RRDTool）\n与他们的预期使用方式紧密耦合，这是一个严重的限制。\n\n应该有一个支持批量插入的高效的二进制协议。\n\n## 6. 非功能需求\n\n我想要一个能够很好地完成一件事情的数据库。 我不认为我需要以下任何一种，我认为他们是中立的，或者在某些情况下甚至是缺点：\n+ 访问控制 - 认证和授权。\n+ 能够可视化数据，绘制图形等\n+ 在同一时间戳支持多种测量。 测量的主键是系列，时间戳，并且允许具有相同时间戳的多个值没有意义。\n+ 多维性。 一系列的多维可以存储为多个系列，多个系列可以与我指定的查询语言组合在表达式中，因此“系列”的原子已经提供了多维度的用例。\n+ 使用额外的特定键值对来“标记”测量或系列。\n+ 时间序列数据关联关系数据。\n\n## 7. 其它需求\n从我的角度来看，前面的部分描述了一个很好的通用时间序列数据库。 不错的功能可能包括：\n+ 支持保留策略。\n+ 支持以多种时间精度存储数据并选择适当的时间精度以访问给定请求。\n+ 支持自动降精度\n+ 支持查询优先级或准入控制，以防止大型查询和DOS攻击影响到服务稳定性。\n\n对于我的特殊用途，我还需要支持：\n+ 集群中任一单台服务器可以存储很多时间序列, 远远超过文件目录中的文件数量.\n+ 虽然一些系列是长寿的，但很多系列并非如此. 很多都很稀少，很长一段时间只有一次测量.\n 系列是动态的，不是预定义的; 新时间序列可能随时出现。\n 由于这个要求，我需要高效的支持来发现在任何给定的时间范围内存在哪些时间序列。\n+ 物理层面的多租户。 这部分是由需求决定的; 有些客户希望知道他们的数据与其他客户的数据是分开的。\n这是部分实用的，以支持诸如每个客户的单独保留策略之类的功能。\n\n## 8. 结论\n“大数据”的未来主要是时间序列数据。 为这种用例创建一个好的时间序列数据库的人可能会做得很好。\n我确定我的要求并不是最通用或最完整的，但我希望分享是有用的。\n","slug":"tsdb-requirements","published":1,"updated":"2018-06-19T10:06:16.993Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zi000a3l655ga5ednl","content":"<p>   以下内容主要翻译自Baron Schwartz的《Time-Series Database Requirements》</p>\n<h2 id=\"1-数据类型\"><a href=\"#1-数据类型\" class=\"headerlink\" title=\"1. 数据类型\"></a>1. 数据类型</h2><p>  时间序列可以定义成下面这样：</p>\n<ul>\n<li>一个时间序列可以被source_name(source_id)和metric_name(metric_id)唯一标识。</li>\n<li>一个时间序列由一系列{时间戳，值}组成，并按照时间戳排序。时间戳通常是高精度的Unix时间戳,<br>值通常是浮点数。</li>\n</ul>\n<blockquote>\n<p>以opentsdb为代表的常见tsdb中的数据模型，都有tags的概念。<br>从逻辑上看， tags也是时间序列唯一标识的组成部分。<br>把tags提取出来，并进行kv切分，有利于执行时间线间的过滤和聚合操作。<br>对tags添加一定的索引，可以提高数据的查询性能。</p>\n</blockquote>\n<h2 id=\"2-读写操作的特点\"><a href=\"#2-读写操作的特点\" class=\"headerlink\" title=\"2. 读写操作的特点\"></a>2. 读写操作的特点</h2><p>   时间序列数据不是通用类型， 它们有自己的特点。一个时间序列数据库必须根据这些特点进行相应的优化。</p>\n<h2 id=\"2-1-写\"><a href=\"#2-1-写\" class=\"headerlink\" title=\"2.1 写\"></a>2.1 写</h2><ul>\n<li>写是最常见的。通常95%-99%的操作都是写，有时更高</li>\n<li>写入的数据通常是顺序追加的。写请求通常是按时间顺序到来的。对于TSDB这是很重要的一个限制。</li>\n<li>很少遇到写入遥远过去的数据。最坏情况下，测量到的数据也需要在几秒或者几分钟内被写入。</li>\n<li>更新也是很少见的。</li>\n<li>删除是批量的，从过去某个时间开始往前所有连续的数据，例如当前时间7天以前的所有数据。删除独立的值<br>或者删除随机时间范围内的值，也是罕见的。高效的批量删除很重要，尽量做到零成本。</li>\n<li>综上所述，选择不可变的存储格式可能是好事情。使用不可变的存储格式的后果是，预定义或者固定数据范式<br>在长期以后会出现问题。</li>\n</ul>\n<h2 id=\"2-2-读\"><a href=\"#2-2-读\" class=\"headerlink\" title=\"2.2 读\"></a>2.2 读</h2><ul>\n<li>数据比内存大得多且很少被读取，所以缓存通常不能很好地工作。TSDB系统通常容易出现是IO制约。</li>\n<li>读取的数据通常每个时间序列都是连续的且排序的， 按时间戳升序或者降序。</li>\n<li>并发读或者一次读多个时间序列也是常见合理的。</li>\n</ul>\n<p>写入得数据按顺序到达， 一般是按{timestamp, series_id}排序，而读结果通常是按{series_id, timestamp}排序。<br>读请求尽管很少，但是需要很快。通常有两种方式来处理读写。首先是写优先，数据在落盘时，没有按时间序列进行优化分布。<br>读的时候使用大量的算力并行顺序地扫描所有数据。第二种是在写过程多做一些事情，把数据按时间序列分别打包到一起并且<br>为顺序读做优化。</p>\n<h2 id=\"3-性能和容量的特点\"><a href=\"#3-性能和容量的特点\" class=\"headerlink\" title=\"3. 性能和容量的特点\"></a>3. 性能和容量的特点</h2><p>一个时间序列数据库应该有下面的特点：</p>\n<ul>\n<li>为分布式设计-集群和分片。数据自动分布，查询自动分布。必须是容错和高可用的，通过内置数据复制和自动故障转移。<br>有一些在这方面做得很好的数据库可以参考，天然分布式已经不是传说了。</li>\n<li>把查询给数据，不要把数据给查询。 这是对查询自动分配的重申。查询可能涉及许多GB甚至TB的数据，所以<br>跨网络移动是不可扩展的。</li>\n<li>每个节点都是高效的，它可以运行大量的数据，这样就不必需要上千个节点了。</li>\n<li>支持使用最新的高性能硬件。例如PCIe 闪存，大量内存，多核CPU.</li>\n<li>快速和一致性。没有尖峰和停滞。执行检查点不会冻结，压缩数据不会锁住。</li>\n</ul>\n<h2 id=\"4-运维需求\"><a href=\"#4-运维需求\" class=\"headerlink\" title=\"4. 运维需求\"></a>4. 运维需求</h2><ul>\n<li>TSDB虽然不强调ACID, 但是当出现故障时，需要能快速把数据恢复到一致的状态。时间序列数据不像财务数据<br>那样对持久性要求那么高</li>\n<li>非阻塞的备份机制是必须的。增量备份也是个好东西</li>\n<li>集群扩容或者缩容，不需要停机或者锁住。</li>\n<li>压缩的存储。时间序列数据量很大，需要很高压缩率</li>\n<li>需要很好的监控和展示运行时状态。</li>\n</ul>\n<h2 id=\"5-查询语言和API\"><a href=\"#5-查询语言和API\" class=\"headerlink\" title=\"5. 查询语言和API\"></a>5. 查询语言和API</h2><p>  我曾与许多为大公司建立大型时间序列数据库的人交谈。 他们中的大多数人告诉我，<br>缺乏访问和查询数据库的高级方式是他们脖子上的长期磨刀石(负债)。</p>\n<p>我喜欢influxdb查询语言那样像sql的东西。最重要的是，要避免一些sql语言里传统限制。<br>SQL表格是固定宽度的，并通过添加行向下增长。<br>一个自然的结果是，SQL语句中的每一列都是事先已知的，并且是明确命名的，并且表达式自然地在一行内工作，<br>或者在一组行中聚合，但是不能在没有JOIN的情况下跨越行工作</p>\n<p>但是，在时间序列数据库中，行是由“主键”标识的系列。随着新测量的添加，行增长横向，添加新系列时表向下增长，列是时间戳。<br>因此，表格是稀疏矩阵。 表达式必须在稀疏矩阵的矩形部分进行聚合，而不仅仅是行或列，语言必须在两个方向上都允许有GROUP BY功能。<br>你可以说，行和列都必须可以通过键而不是字面标识符来寻址，并且理想情况下除了严格的相等和范围之外，还可以通过模式匹配来寻址。</p>\n<p>理想情况下，查询语言和数据库应该至少支持以下服务器端处理工作，可能还有更多：</p>\n<ul>\n<li>表达式，如算术和字符串操作</li>\n<li>聚合函数</li>\n<li>降精度，重新采样到不同的时间精度，不同的存储介质存放不同精度的数据</li>\n<li>不同时间序列间的表达式和操作符，例如以将不同时间序列求和或相除</li>\n<li>组合表达式，例如求和所有标识符与模式匹配的时间系列，然后将结果除以另一组时间系列的总和</li>\n<li>支持order、rank、limit等操作</li>\n</ul>\n<p>另一种说法是，查询语言和数据库应该设计用于分析，而不仅仅是绘制带状图。许多开源时间序列数据库（如RRDTool）<br>与他们的预期使用方式紧密耦合，这是一个严重的限制。</p>\n<p>应该有一个支持批量插入的高效的二进制协议。</p>\n<h2 id=\"6-非功能需求\"><a href=\"#6-非功能需求\" class=\"headerlink\" title=\"6. 非功能需求\"></a>6. 非功能需求</h2><p>我想要一个能够很好地完成一件事情的数据库。 我不认为我需要以下任何一种，我认为他们是中立的，或者在某些情况下甚至是缺点：</p>\n<ul>\n<li>访问控制 - 认证和授权。</li>\n<li>能够可视化数据，绘制图形等</li>\n<li>在同一时间戳支持多种测量。 测量的主键是系列，时间戳，并且允许具有相同时间戳的多个值没有意义。</li>\n<li>多维性。 一系列的多维可以存储为多个系列，多个系列可以与我指定的查询语言组合在表达式中，因此“系列”的原子已经提供了多维度的用例。</li>\n<li>使用额外的特定键值对来“标记”测量或系列。</li>\n<li>时间序列数据关联关系数据。</li>\n</ul>\n<h2 id=\"7-其它需求\"><a href=\"#7-其它需求\" class=\"headerlink\" title=\"7. 其它需求\"></a>7. 其它需求</h2><p>从我的角度来看，前面的部分描述了一个很好的通用时间序列数据库。 不错的功能可能包括：</p>\n<ul>\n<li>支持保留策略。</li>\n<li>支持以多种时间精度存储数据并选择适当的时间精度以访问给定请求。</li>\n<li>支持自动降精度</li>\n<li>支持查询优先级或准入控制，以防止大型查询和DOS攻击影响到服务稳定性。</li>\n</ul>\n<p>对于我的特殊用途，我还需要支持：</p>\n<ul>\n<li>集群中任一单台服务器可以存储很多时间序列, 远远超过文件目录中的文件数量.</li>\n<li>虽然一些系列是长寿的，但很多系列并非如此. 很多都很稀少，很长一段时间只有一次测量.<br>系列是动态的，不是预定义的; 新时间序列可能随时出现。<br>由于这个要求，我需要高效的支持来发现在任何给定的时间范围内存在哪些时间序列。</li>\n<li>物理层面的多租户。 这部分是由需求决定的; 有些客户希望知道他们的数据与其他客户的数据是分开的。<br>这是部分实用的，以支持诸如每个客户的单独保留策略之类的功能。</li>\n</ul>\n<h2 id=\"8-结论\"><a href=\"#8-结论\" class=\"headerlink\" title=\"8. 结论\"></a>8. 结论</h2><p>“大数据”的未来主要是时间序列数据。 为这种用例创建一个好的时间序列数据库的人可能会做得很好。<br>我确定我的要求并不是最通用或最完整的，但我希望分享是有用的。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>   以下内容主要翻译自Baron Schwartz的《Time-Series Database Requirements》</p>\n<h2 id=\"1-数据类型\"><a href=\"#1-数据类型\" class=\"headerlink\" title=\"1. 数据类型\"></a>1. 数据类型</h2><p>  时间序列可以定义成下面这样：</p>\n<ul>\n<li>一个时间序列可以被source_name(source_id)和metric_name(metric_id)唯一标识。</li>\n<li>一个时间序列由一系列{时间戳，值}组成，并按照时间戳排序。时间戳通常是高精度的Unix时间戳,<br>值通常是浮点数。</li>\n</ul>\n<blockquote>\n<p>以opentsdb为代表的常见tsdb中的数据模型，都有tags的概念。<br>从逻辑上看， tags也是时间序列唯一标识的组成部分。<br>把tags提取出来，并进行kv切分，有利于执行时间线间的过滤和聚合操作。<br>对tags添加一定的索引，可以提高数据的查询性能。</p>\n</blockquote>\n<h2 id=\"2-读写操作的特点\"><a href=\"#2-读写操作的特点\" class=\"headerlink\" title=\"2. 读写操作的特点\"></a>2. 读写操作的特点</h2><p>   时间序列数据不是通用类型， 它们有自己的特点。一个时间序列数据库必须根据这些特点进行相应的优化。</p>\n<h2 id=\"2-1-写\"><a href=\"#2-1-写\" class=\"headerlink\" title=\"2.1 写\"></a>2.1 写</h2><ul>\n<li>写是最常见的。通常95%-99%的操作都是写，有时更高</li>\n<li>写入的数据通常是顺序追加的。写请求通常是按时间顺序到来的。对于TSDB这是很重要的一个限制。</li>\n<li>很少遇到写入遥远过去的数据。最坏情况下，测量到的数据也需要在几秒或者几分钟内被写入。</li>\n<li>更新也是很少见的。</li>\n<li>删除是批量的，从过去某个时间开始往前所有连续的数据，例如当前时间7天以前的所有数据。删除独立的值<br>或者删除随机时间范围内的值，也是罕见的。高效的批量删除很重要，尽量做到零成本。</li>\n<li>综上所述，选择不可变的存储格式可能是好事情。使用不可变的存储格式的后果是，预定义或者固定数据范式<br>在长期以后会出现问题。</li>\n</ul>\n<h2 id=\"2-2-读\"><a href=\"#2-2-读\" class=\"headerlink\" title=\"2.2 读\"></a>2.2 读</h2><ul>\n<li>数据比内存大得多且很少被读取，所以缓存通常不能很好地工作。TSDB系统通常容易出现是IO制约。</li>\n<li>读取的数据通常每个时间序列都是连续的且排序的， 按时间戳升序或者降序。</li>\n<li>并发读或者一次读多个时间序列也是常见合理的。</li>\n</ul>\n<p>写入得数据按顺序到达， 一般是按{timestamp, series_id}排序，而读结果通常是按{series_id, timestamp}排序。<br>读请求尽管很少，但是需要很快。通常有两种方式来处理读写。首先是写优先，数据在落盘时，没有按时间序列进行优化分布。<br>读的时候使用大量的算力并行顺序地扫描所有数据。第二种是在写过程多做一些事情，把数据按时间序列分别打包到一起并且<br>为顺序读做优化。</p>\n<h2 id=\"3-性能和容量的特点\"><a href=\"#3-性能和容量的特点\" class=\"headerlink\" title=\"3. 性能和容量的特点\"></a>3. 性能和容量的特点</h2><p>一个时间序列数据库应该有下面的特点：</p>\n<ul>\n<li>为分布式设计-集群和分片。数据自动分布，查询自动分布。必须是容错和高可用的，通过内置数据复制和自动故障转移。<br>有一些在这方面做得很好的数据库可以参考，天然分布式已经不是传说了。</li>\n<li>把查询给数据，不要把数据给查询。 这是对查询自动分配的重申。查询可能涉及许多GB甚至TB的数据，所以<br>跨网络移动是不可扩展的。</li>\n<li>每个节点都是高效的，它可以运行大量的数据，这样就不必需要上千个节点了。</li>\n<li>支持使用最新的高性能硬件。例如PCIe 闪存，大量内存，多核CPU.</li>\n<li>快速和一致性。没有尖峰和停滞。执行检查点不会冻结，压缩数据不会锁住。</li>\n</ul>\n<h2 id=\"4-运维需求\"><a href=\"#4-运维需求\" class=\"headerlink\" title=\"4. 运维需求\"></a>4. 运维需求</h2><ul>\n<li>TSDB虽然不强调ACID, 但是当出现故障时，需要能快速把数据恢复到一致的状态。时间序列数据不像财务数据<br>那样对持久性要求那么高</li>\n<li>非阻塞的备份机制是必须的。增量备份也是个好东西</li>\n<li>集群扩容或者缩容，不需要停机或者锁住。</li>\n<li>压缩的存储。时间序列数据量很大，需要很高压缩率</li>\n<li>需要很好的监控和展示运行时状态。</li>\n</ul>\n<h2 id=\"5-查询语言和API\"><a href=\"#5-查询语言和API\" class=\"headerlink\" title=\"5. 查询语言和API\"></a>5. 查询语言和API</h2><p>  我曾与许多为大公司建立大型时间序列数据库的人交谈。 他们中的大多数人告诉我，<br>缺乏访问和查询数据库的高级方式是他们脖子上的长期磨刀石(负债)。</p>\n<p>我喜欢influxdb查询语言那样像sql的东西。最重要的是，要避免一些sql语言里传统限制。<br>SQL表格是固定宽度的，并通过添加行向下增长。<br>一个自然的结果是，SQL语句中的每一列都是事先已知的，并且是明确命名的，并且表达式自然地在一行内工作，<br>或者在一组行中聚合，但是不能在没有JOIN的情况下跨越行工作</p>\n<p>但是，在时间序列数据库中，行是由“主键”标识的系列。随着新测量的添加，行增长横向，添加新系列时表向下增长，列是时间戳。<br>因此，表格是稀疏矩阵。 表达式必须在稀疏矩阵的矩形部分进行聚合，而不仅仅是行或列，语言必须在两个方向上都允许有GROUP BY功能。<br>你可以说，行和列都必须可以通过键而不是字面标识符来寻址，并且理想情况下除了严格的相等和范围之外，还可以通过模式匹配来寻址。</p>\n<p>理想情况下，查询语言和数据库应该至少支持以下服务器端处理工作，可能还有更多：</p>\n<ul>\n<li>表达式，如算术和字符串操作</li>\n<li>聚合函数</li>\n<li>降精度，重新采样到不同的时间精度，不同的存储介质存放不同精度的数据</li>\n<li>不同时间序列间的表达式和操作符，例如以将不同时间序列求和或相除</li>\n<li>组合表达式，例如求和所有标识符与模式匹配的时间系列，然后将结果除以另一组时间系列的总和</li>\n<li>支持order、rank、limit等操作</li>\n</ul>\n<p>另一种说法是，查询语言和数据库应该设计用于分析，而不仅仅是绘制带状图。许多开源时间序列数据库（如RRDTool）<br>与他们的预期使用方式紧密耦合，这是一个严重的限制。</p>\n<p>应该有一个支持批量插入的高效的二进制协议。</p>\n<h2 id=\"6-非功能需求\"><a href=\"#6-非功能需求\" class=\"headerlink\" title=\"6. 非功能需求\"></a>6. 非功能需求</h2><p>我想要一个能够很好地完成一件事情的数据库。 我不认为我需要以下任何一种，我认为他们是中立的，或者在某些情况下甚至是缺点：</p>\n<ul>\n<li>访问控制 - 认证和授权。</li>\n<li>能够可视化数据，绘制图形等</li>\n<li>在同一时间戳支持多种测量。 测量的主键是系列，时间戳，并且允许具有相同时间戳的多个值没有意义。</li>\n<li>多维性。 一系列的多维可以存储为多个系列，多个系列可以与我指定的查询语言组合在表达式中，因此“系列”的原子已经提供了多维度的用例。</li>\n<li>使用额外的特定键值对来“标记”测量或系列。</li>\n<li>时间序列数据关联关系数据。</li>\n</ul>\n<h2 id=\"7-其它需求\"><a href=\"#7-其它需求\" class=\"headerlink\" title=\"7. 其它需求\"></a>7. 其它需求</h2><p>从我的角度来看，前面的部分描述了一个很好的通用时间序列数据库。 不错的功能可能包括：</p>\n<ul>\n<li>支持保留策略。</li>\n<li>支持以多种时间精度存储数据并选择适当的时间精度以访问给定请求。</li>\n<li>支持自动降精度</li>\n<li>支持查询优先级或准入控制，以防止大型查询和DOS攻击影响到服务稳定性。</li>\n</ul>\n<p>对于我的特殊用途，我还需要支持：</p>\n<ul>\n<li>集群中任一单台服务器可以存储很多时间序列, 远远超过文件目录中的文件数量.</li>\n<li>虽然一些系列是长寿的，但很多系列并非如此. 很多都很稀少，很长一段时间只有一次测量.<br>系列是动态的，不是预定义的; 新时间序列可能随时出现。<br>由于这个要求，我需要高效的支持来发现在任何给定的时间范围内存在哪些时间序列。</li>\n<li>物理层面的多租户。 这部分是由需求决定的; 有些客户希望知道他们的数据与其他客户的数据是分开的。<br>这是部分实用的，以支持诸如每个客户的单独保留策略之类的功能。</li>\n</ul>\n<h2 id=\"8-结论\"><a href=\"#8-结论\" class=\"headerlink\" title=\"8. 结论\"></a>8. 结论</h2><p>“大数据”的未来主要是时间序列数据。 为这种用例创建一个好的时间序列数据库的人可能会做得很好。<br>我确定我的要求并不是最通用或最完整的，但我希望分享是有用的。</p>\n"},{"title":"tips","date":"2018-02-28T08:17:03.000Z","_content":"\n## 命令行格式化json\n```\n1.\ncat some.json |python -m json.tool\n\n2.\njq some.json\n```\n\n## git clone后如何保持与原项目同步\n```\n把原来的项目添加到：\n\ngit remote add rp [主项目地址]\n然后：\n\ngit fetch rp && git merge rp/master\n```\n\n## git 修改已提交的日志\n未push到远端\n```\ngit reset --soft [commit_id] 就可以回滚到某一个commit，然后保留下修改的内容\n```\n\n## OM7\n```\n绘图\nName: Appked SN: MFWG-GHEB-HYTW-CGHT-CSXU-QCNC-SXU\n```\n\n## macos环境docker login失败\n```\nUsername: colin\nPassword:\nError saving credentials: error storing credentials - err: exit status 1, out: `The user name or passphrase you entered is not correct.`\n```\n参考链接：https://github.com/docker/docker-credential-helpers/issues/65   \n解决办法：rm /usr/local/bin/docker-credential-osxkeychain\n\n## 如何讲清楚一件事\n```\n看到的一个观点：其实讲一个东西，讲它是什么样是不足够的。如果能讲清楚它为什么会是这样子，则会举一反三\n```\n","source":"_posts/2018-02-28-tips.md","raw":"---\ntitle: tips\ndate: 2018-02-28 16:17:03\ntags:\n---\n\n## 命令行格式化json\n```\n1.\ncat some.json |python -m json.tool\n\n2.\njq some.json\n```\n\n## git clone后如何保持与原项目同步\n```\n把原来的项目添加到：\n\ngit remote add rp [主项目地址]\n然后：\n\ngit fetch rp && git merge rp/master\n```\n\n## git 修改已提交的日志\n未push到远端\n```\ngit reset --soft [commit_id] 就可以回滚到某一个commit，然后保留下修改的内容\n```\n\n## OM7\n```\n绘图\nName: Appked SN: MFWG-GHEB-HYTW-CGHT-CSXU-QCNC-SXU\n```\n\n## macos环境docker login失败\n```\nUsername: colin\nPassword:\nError saving credentials: error storing credentials - err: exit status 1, out: `The user name or passphrase you entered is not correct.`\n```\n参考链接：https://github.com/docker/docker-credential-helpers/issues/65   \n解决办法：rm /usr/local/bin/docker-credential-osxkeychain\n\n## 如何讲清楚一件事\n```\n看到的一个观点：其实讲一个东西，讲它是什么样是不足够的。如果能讲清楚它为什么会是这样子，则会举一反三\n```\n","slug":"tips","published":1,"updated":"2018-06-25T09:18:42.465Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zj000c3l65upaps1yn","content":"<h2 id=\"命令行格式化json\"><a href=\"#命令行格式化json\" class=\"headerlink\" title=\"命令行格式化json\"></a>命令行格式化json</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">1.</div><div class=\"line\">cat some.json |python -m json.tool</div><div class=\"line\"></div><div class=\"line\">2.</div><div class=\"line\">jq some.json</div></pre></td></tr></table></figure>\n<h2 id=\"git-clone后如何保持与原项目同步\"><a href=\"#git-clone后如何保持与原项目同步\" class=\"headerlink\" title=\"git clone后如何保持与原项目同步\"></a>git clone后如何保持与原项目同步</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">把原来的项目添加到：</div><div class=\"line\"></div><div class=\"line\">git remote add rp [主项目地址]</div><div class=\"line\">然后：</div><div class=\"line\"></div><div class=\"line\">git fetch rp &amp;&amp; git merge rp/master</div></pre></td></tr></table></figure>\n<h2 id=\"git-修改已提交的日志\"><a href=\"#git-修改已提交的日志\" class=\"headerlink\" title=\"git 修改已提交的日志\"></a>git 修改已提交的日志</h2><p>未push到远端<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">git reset --soft [commit_id] 就可以回滚到某一个commit，然后保留下修改的内容</div></pre></td></tr></table></figure></p>\n<h2 id=\"OM7\"><a href=\"#OM7\" class=\"headerlink\" title=\"OM7\"></a>OM7</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">绘图</div><div class=\"line\">Name: Appked SN: MFWG-GHEB-HYTW-CGHT-CSXU-QCNC-SXU</div></pre></td></tr></table></figure>\n<h2 id=\"macos环境docker-login失败\"><a href=\"#macos环境docker-login失败\" class=\"headerlink\" title=\"macos环境docker login失败\"></a>macos环境docker login失败</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">Username: colin</div><div class=\"line\">Password:</div><div class=\"line\">Error saving credentials: error storing credentials - err: exit status 1, out: `The user name or passphrase you entered is not correct.`</div></pre></td></tr></table></figure>\n<p>参考链接：<a href=\"https://github.com/docker/docker-credential-helpers/issues/65\" target=\"_blank\" rel=\"noopener\">https://github.com/docker/docker-credential-helpers/issues/65</a><br>解决办法：rm /usr/local/bin/docker-credential-osxkeychain</p>\n<h2 id=\"如何讲清楚一件事\"><a href=\"#如何讲清楚一件事\" class=\"headerlink\" title=\"如何讲清楚一件事\"></a>如何讲清楚一件事</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">看到的一个观点：其实讲一个东西，讲它是什么样是不足够的。如果能讲清楚它为什么会是这样子，则会举一反三</div></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"命令行格式化json\"><a href=\"#命令行格式化json\" class=\"headerlink\" title=\"命令行格式化json\"></a>命令行格式化json</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">1.</div><div class=\"line\">cat some.json |python -m json.tool</div><div class=\"line\"></div><div class=\"line\">2.</div><div class=\"line\">jq some.json</div></pre></td></tr></table></figure>\n<h2 id=\"git-clone后如何保持与原项目同步\"><a href=\"#git-clone后如何保持与原项目同步\" class=\"headerlink\" title=\"git clone后如何保持与原项目同步\"></a>git clone后如何保持与原项目同步</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">把原来的项目添加到：</div><div class=\"line\"></div><div class=\"line\">git remote add rp [主项目地址]</div><div class=\"line\">然后：</div><div class=\"line\"></div><div class=\"line\">git fetch rp &amp;&amp; git merge rp/master</div></pre></td></tr></table></figure>\n<h2 id=\"git-修改已提交的日志\"><a href=\"#git-修改已提交的日志\" class=\"headerlink\" title=\"git 修改已提交的日志\"></a>git 修改已提交的日志</h2><p>未push到远端<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">git reset --soft [commit_id] 就可以回滚到某一个commit，然后保留下修改的内容</div></pre></td></tr></table></figure></p>\n<h2 id=\"OM7\"><a href=\"#OM7\" class=\"headerlink\" title=\"OM7\"></a>OM7</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">绘图</div><div class=\"line\">Name: Appked SN: MFWG-GHEB-HYTW-CGHT-CSXU-QCNC-SXU</div></pre></td></tr></table></figure>\n<h2 id=\"macos环境docker-login失败\"><a href=\"#macos环境docker-login失败\" class=\"headerlink\" title=\"macos环境docker login失败\"></a>macos环境docker login失败</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">Username: colin</div><div class=\"line\">Password:</div><div class=\"line\">Error saving credentials: error storing credentials - err: exit status 1, out: `The user name or passphrase you entered is not correct.`</div></pre></td></tr></table></figure>\n<p>参考链接：<a href=\"https://github.com/docker/docker-credential-helpers/issues/65\" target=\"_blank\" rel=\"noopener\">https://github.com/docker/docker-credential-helpers/issues/65</a><br>解决办法：rm /usr/local/bin/docker-credential-osxkeychain</p>\n<h2 id=\"如何讲清楚一件事\"><a href=\"#如何讲清楚一件事\" class=\"headerlink\" title=\"如何讲清楚一件事\"></a>如何讲清楚一件事</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">看到的一个观点：其实讲一个东西，讲它是什么样是不足够的。如果能讲清楚它为什么会是这样子，则会举一反三</div></pre></td></tr></table></figure>\n"},{"title":"raft源码解读","date":"2017-11-27T06:07:13.000Z","_content":"以下是 hashicorp/raft 1.0 第一次源码阅读后的整理。根据经验，最开始往往有理解不正确的地方，后续加深理解后再整理修正，并与当前对比\n\n## 1. Apply过程\n### 1.1 leader\n- api.Apply 写logfuture到r.applyCh\n- raft.leaderLoop 读applyCh然后调用 dispatchLogs\n- raft.dispatchLogs 先写入到leaderStare的inflight,再持久化到logStore，然后通知commit(commitCh)，最后通知复制log(triggerCh)\n- 先说commit链路。raft.leaderLoop处理commit，循环从leaderState中读出每个待提交的LogFuture,然后调用r.processLogs\n- raft.processLogs循环调用processLog，里面向fsmMutateCh写入构造的commitTuple消息\n- fsm.runFSM读fsmMutateCh，执行commit函数，这个函数里面调用fsm对象的Apply方法，这个方法需要由用户自定义实现。\n- 再回到复制链路。启动时，每个follower都创建1个goroutine，运行r.replicate函数\n- 获得lastIndex，构造tranReq，r.setupAppendEntries从logstore读出需复制的log\n- r.trans.AppendEntries 执行RPC\n- commit补充。leader被通知commitCh，是当大多数follower复制成功消息后才被通知提交的。\n- 复制链路有个commitTimeout(默认50ms), 定期把当前的commitIndex等信息通过RPC传递到Follower。Command类型还是AppendEntriesRequest\n\n### 1.2 Follower\n- raft.runFollower 读r.rpcCh，然后调用processRPC处理\n- 检查rpc的类型，处理AppendEntriesRequest\n- 检查一大堆，然后先持久化到logStore，再commit。\n- commit过程与leader类似，调用processLogs进行处理。\n\n## 2. Term变化过程\n- 先进入到 Candidate 状态\n- 选举自己。发送投票请求给其它节点，请求包括currentTerm，lastTerm,lastIndex.\n- 优先投票给currentTerm，lastTerm，lastIndex最大的node\n\n## 3. Node变化过程\n- 添加节点。api.AddVoter必须在leader执行. 先更新configurations，接着调用dispatchLogs;\n调用startStopReplication 启动新节点的复制goroutine。\n- 删除节点。api.RemoveServer也必须在leader执行。流程和添加节点类似，commandType 变成RemoveServer。\n删除leader节点，触发重新选举。处理完log提交后，修改状态 stepdown 为true，然后关闭或者变成Follower。\n- 节点故障。 Follower的心跳超时，改变状态为 Candidate 重新选举。\n\n## 4. snapshot 过程\n- r.runSnapshots 默认每隔120s 检查一次上次snapshot的index和当前最新的index，二者差值超过8192，执行snapshot\n- 先创建snapshot的sink，然后持久化，再接着compactLog(删除已经snapshot的log)\n- 无论leader还是Follower都启动snapshot的goroutine\n\n## 5. restore 过程\n- 新加入的节点，状态为Fllower\n- leader主动同步log到新节点\n- 构造复制请求时，发现需要同步很久以前的log，且当前logstore不存在该log\n- 此时发起installSnapshot的请求给Follower，取消同步log的请求\n- follwer接收snapshot并应用到本地\n- leader的周期同步commit的机制逐步把最近的log同步给Follower\n","source":"_posts/2017-11-27-raft.md","raw":"---\ntitle: raft源码解读\ndate: 2017-11-27 14:07:13\ntags:\n---\n以下是 hashicorp/raft 1.0 第一次源码阅读后的整理。根据经验，最开始往往有理解不正确的地方，后续加深理解后再整理修正，并与当前对比\n\n## 1. Apply过程\n### 1.1 leader\n- api.Apply 写logfuture到r.applyCh\n- raft.leaderLoop 读applyCh然后调用 dispatchLogs\n- raft.dispatchLogs 先写入到leaderStare的inflight,再持久化到logStore，然后通知commit(commitCh)，最后通知复制log(triggerCh)\n- 先说commit链路。raft.leaderLoop处理commit，循环从leaderState中读出每个待提交的LogFuture,然后调用r.processLogs\n- raft.processLogs循环调用processLog，里面向fsmMutateCh写入构造的commitTuple消息\n- fsm.runFSM读fsmMutateCh，执行commit函数，这个函数里面调用fsm对象的Apply方法，这个方法需要由用户自定义实现。\n- 再回到复制链路。启动时，每个follower都创建1个goroutine，运行r.replicate函数\n- 获得lastIndex，构造tranReq，r.setupAppendEntries从logstore读出需复制的log\n- r.trans.AppendEntries 执行RPC\n- commit补充。leader被通知commitCh，是当大多数follower复制成功消息后才被通知提交的。\n- 复制链路有个commitTimeout(默认50ms), 定期把当前的commitIndex等信息通过RPC传递到Follower。Command类型还是AppendEntriesRequest\n\n### 1.2 Follower\n- raft.runFollower 读r.rpcCh，然后调用processRPC处理\n- 检查rpc的类型，处理AppendEntriesRequest\n- 检查一大堆，然后先持久化到logStore，再commit。\n- commit过程与leader类似，调用processLogs进行处理。\n\n## 2. Term变化过程\n- 先进入到 Candidate 状态\n- 选举自己。发送投票请求给其它节点，请求包括currentTerm，lastTerm,lastIndex.\n- 优先投票给currentTerm，lastTerm，lastIndex最大的node\n\n## 3. Node变化过程\n- 添加节点。api.AddVoter必须在leader执行. 先更新configurations，接着调用dispatchLogs;\n调用startStopReplication 启动新节点的复制goroutine。\n- 删除节点。api.RemoveServer也必须在leader执行。流程和添加节点类似，commandType 变成RemoveServer。\n删除leader节点，触发重新选举。处理完log提交后，修改状态 stepdown 为true，然后关闭或者变成Follower。\n- 节点故障。 Follower的心跳超时，改变状态为 Candidate 重新选举。\n\n## 4. snapshot 过程\n- r.runSnapshots 默认每隔120s 检查一次上次snapshot的index和当前最新的index，二者差值超过8192，执行snapshot\n- 先创建snapshot的sink，然后持久化，再接着compactLog(删除已经snapshot的log)\n- 无论leader还是Follower都启动snapshot的goroutine\n\n## 5. restore 过程\n- 新加入的节点，状态为Fllower\n- leader主动同步log到新节点\n- 构造复制请求时，发现需要同步很久以前的log，且当前logstore不存在该log\n- 此时发起installSnapshot的请求给Follower，取消同步log的请求\n- follwer接收snapshot并应用到本地\n- leader的周期同步commit的机制逐步把最近的log同步给Follower\n","slug":"raft","published":1,"updated":"2018-02-27T09:05:10.573Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zk000f3l65xdsvqbo9","content":"<p>以下是 hashicorp/raft 1.0 第一次源码阅读后的整理。根据经验，最开始往往有理解不正确的地方，后续加深理解后再整理修正，并与当前对比</p>\n<h2 id=\"1-Apply过程\"><a href=\"#1-Apply过程\" class=\"headerlink\" title=\"1. Apply过程\"></a>1. Apply过程</h2><h3 id=\"1-1-leader\"><a href=\"#1-1-leader\" class=\"headerlink\" title=\"1.1 leader\"></a>1.1 leader</h3><ul>\n<li>api.Apply 写logfuture到r.applyCh</li>\n<li>raft.leaderLoop 读applyCh然后调用 dispatchLogs</li>\n<li>raft.dispatchLogs 先写入到leaderStare的inflight,再持久化到logStore，然后通知commit(commitCh)，最后通知复制log(triggerCh)</li>\n<li>先说commit链路。raft.leaderLoop处理commit，循环从leaderState中读出每个待提交的LogFuture,然后调用r.processLogs</li>\n<li>raft.processLogs循环调用processLog，里面向fsmMutateCh写入构造的commitTuple消息</li>\n<li>fsm.runFSM读fsmMutateCh，执行commit函数，这个函数里面调用fsm对象的Apply方法，这个方法需要由用户自定义实现。</li>\n<li>再回到复制链路。启动时，每个follower都创建1个goroutine，运行r.replicate函数</li>\n<li>获得lastIndex，构造tranReq，r.setupAppendEntries从logstore读出需复制的log</li>\n<li>r.trans.AppendEntries 执行RPC</li>\n<li>commit补充。leader被通知commitCh，是当大多数follower复制成功消息后才被通知提交的。</li>\n<li>复制链路有个commitTimeout(默认50ms), 定期把当前的commitIndex等信息通过RPC传递到Follower。Command类型还是AppendEntriesRequest</li>\n</ul>\n<h3 id=\"1-2-Follower\"><a href=\"#1-2-Follower\" class=\"headerlink\" title=\"1.2 Follower\"></a>1.2 Follower</h3><ul>\n<li>raft.runFollower 读r.rpcCh，然后调用processRPC处理</li>\n<li>检查rpc的类型，处理AppendEntriesRequest</li>\n<li>检查一大堆，然后先持久化到logStore，再commit。</li>\n<li>commit过程与leader类似，调用processLogs进行处理。</li>\n</ul>\n<h2 id=\"2-Term变化过程\"><a href=\"#2-Term变化过程\" class=\"headerlink\" title=\"2. Term变化过程\"></a>2. Term变化过程</h2><ul>\n<li>先进入到 Candidate 状态</li>\n<li>选举自己。发送投票请求给其它节点，请求包括currentTerm，lastTerm,lastIndex.</li>\n<li>优先投票给currentTerm，lastTerm，lastIndex最大的node</li>\n</ul>\n<h2 id=\"3-Node变化过程\"><a href=\"#3-Node变化过程\" class=\"headerlink\" title=\"3. Node变化过程\"></a>3. Node变化过程</h2><ul>\n<li>添加节点。api.AddVoter必须在leader执行. 先更新configurations，接着调用dispatchLogs;<br>调用startStopReplication 启动新节点的复制goroutine。</li>\n<li>删除节点。api.RemoveServer也必须在leader执行。流程和添加节点类似，commandType 变成RemoveServer。<br>删除leader节点，触发重新选举。处理完log提交后，修改状态 stepdown 为true，然后关闭或者变成Follower。</li>\n<li>节点故障。 Follower的心跳超时，改变状态为 Candidate 重新选举。</li>\n</ul>\n<h2 id=\"4-snapshot-过程\"><a href=\"#4-snapshot-过程\" class=\"headerlink\" title=\"4. snapshot 过程\"></a>4. snapshot 过程</h2><ul>\n<li>r.runSnapshots 默认每隔120s 检查一次上次snapshot的index和当前最新的index，二者差值超过8192，执行snapshot</li>\n<li>先创建snapshot的sink，然后持久化，再接着compactLog(删除已经snapshot的log)</li>\n<li>无论leader还是Follower都启动snapshot的goroutine</li>\n</ul>\n<h2 id=\"5-restore-过程\"><a href=\"#5-restore-过程\" class=\"headerlink\" title=\"5. restore 过程\"></a>5. restore 过程</h2><ul>\n<li>新加入的节点，状态为Fllower</li>\n<li>leader主动同步log到新节点</li>\n<li>构造复制请求时，发现需要同步很久以前的log，且当前logstore不存在该log</li>\n<li>此时发起installSnapshot的请求给Follower，取消同步log的请求</li>\n<li>follwer接收snapshot并应用到本地</li>\n<li>leader的周期同步commit的机制逐步把最近的log同步给Follower</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>以下是 hashicorp/raft 1.0 第一次源码阅读后的整理。根据经验，最开始往往有理解不正确的地方，后续加深理解后再整理修正，并与当前对比</p>\n<h2 id=\"1-Apply过程\"><a href=\"#1-Apply过程\" class=\"headerlink\" title=\"1. Apply过程\"></a>1. Apply过程</h2><h3 id=\"1-1-leader\"><a href=\"#1-1-leader\" class=\"headerlink\" title=\"1.1 leader\"></a>1.1 leader</h3><ul>\n<li>api.Apply 写logfuture到r.applyCh</li>\n<li>raft.leaderLoop 读applyCh然后调用 dispatchLogs</li>\n<li>raft.dispatchLogs 先写入到leaderStare的inflight,再持久化到logStore，然后通知commit(commitCh)，最后通知复制log(triggerCh)</li>\n<li>先说commit链路。raft.leaderLoop处理commit，循环从leaderState中读出每个待提交的LogFuture,然后调用r.processLogs</li>\n<li>raft.processLogs循环调用processLog，里面向fsmMutateCh写入构造的commitTuple消息</li>\n<li>fsm.runFSM读fsmMutateCh，执行commit函数，这个函数里面调用fsm对象的Apply方法，这个方法需要由用户自定义实现。</li>\n<li>再回到复制链路。启动时，每个follower都创建1个goroutine，运行r.replicate函数</li>\n<li>获得lastIndex，构造tranReq，r.setupAppendEntries从logstore读出需复制的log</li>\n<li>r.trans.AppendEntries 执行RPC</li>\n<li>commit补充。leader被通知commitCh，是当大多数follower复制成功消息后才被通知提交的。</li>\n<li>复制链路有个commitTimeout(默认50ms), 定期把当前的commitIndex等信息通过RPC传递到Follower。Command类型还是AppendEntriesRequest</li>\n</ul>\n<h3 id=\"1-2-Follower\"><a href=\"#1-2-Follower\" class=\"headerlink\" title=\"1.2 Follower\"></a>1.2 Follower</h3><ul>\n<li>raft.runFollower 读r.rpcCh，然后调用processRPC处理</li>\n<li>检查rpc的类型，处理AppendEntriesRequest</li>\n<li>检查一大堆，然后先持久化到logStore，再commit。</li>\n<li>commit过程与leader类似，调用processLogs进行处理。</li>\n</ul>\n<h2 id=\"2-Term变化过程\"><a href=\"#2-Term变化过程\" class=\"headerlink\" title=\"2. Term变化过程\"></a>2. Term变化过程</h2><ul>\n<li>先进入到 Candidate 状态</li>\n<li>选举自己。发送投票请求给其它节点，请求包括currentTerm，lastTerm,lastIndex.</li>\n<li>优先投票给currentTerm，lastTerm，lastIndex最大的node</li>\n</ul>\n<h2 id=\"3-Node变化过程\"><a href=\"#3-Node变化过程\" class=\"headerlink\" title=\"3. Node变化过程\"></a>3. Node变化过程</h2><ul>\n<li>添加节点。api.AddVoter必须在leader执行. 先更新configurations，接着调用dispatchLogs;<br>调用startStopReplication 启动新节点的复制goroutine。</li>\n<li>删除节点。api.RemoveServer也必须在leader执行。流程和添加节点类似，commandType 变成RemoveServer。<br>删除leader节点，触发重新选举。处理完log提交后，修改状态 stepdown 为true，然后关闭或者变成Follower。</li>\n<li>节点故障。 Follower的心跳超时，改变状态为 Candidate 重新选举。</li>\n</ul>\n<h2 id=\"4-snapshot-过程\"><a href=\"#4-snapshot-过程\" class=\"headerlink\" title=\"4. snapshot 过程\"></a>4. snapshot 过程</h2><ul>\n<li>r.runSnapshots 默认每隔120s 检查一次上次snapshot的index和当前最新的index，二者差值超过8192，执行snapshot</li>\n<li>先创建snapshot的sink，然后持久化，再接着compactLog(删除已经snapshot的log)</li>\n<li>无论leader还是Follower都启动snapshot的goroutine</li>\n</ul>\n<h2 id=\"5-restore-过程\"><a href=\"#5-restore-过程\" class=\"headerlink\" title=\"5. restore 过程\"></a>5. restore 过程</h2><ul>\n<li>新加入的节点，状态为Fllower</li>\n<li>leader主动同步log到新节点</li>\n<li>构造复制请求时，发现需要同步很久以前的log，且当前logstore不存在该log</li>\n<li>此时发起installSnapshot的请求给Follower，取消同步log的请求</li>\n<li>follwer接收snapshot并应用到本地</li>\n<li>leader的周期同步commit的机制逐步把最近的log同步给Follower</li>\n</ul>\n"},{"title":"influx_http_service","date":"2017-12-04T03:03:14.000Z","_content":"  支持的不同handler\n## serveOptions\n直接返回204状态码\n\n## servePing\n先记录ping的次数，再返回204状态码\n\n## serveStatus\n已过期，用servePing代替\n\n## serveWrite\n+ 先解析请求，构造points对象\n+ 调用PointsWriter的WritePoints\n+ PointsWriter是个接口，默认赋值的是coordinator.PointsWriter\n+ 0.11. 先创建shardgroup，接着mapShards得到ShardMapping ，\n然后再每个shardinfo的owner创建1个goroutine调用rpc执行写操作。\n+ 0.11. 目的节点的cluster模块监听连接，接收请求，并调用本地的TSDBStore写本地的tsdb。\n+ 1.3.  也是先mapShards， 再writeToShard。少了多data_node的rpc\n","source":"_posts/2017-12-04-influxdb-http.md","raw":"---\ntitle: influx_http_service\ndate: 2017-12-04 11:03:14\ntags:\n---\n  支持的不同handler\n## serveOptions\n直接返回204状态码\n\n## servePing\n先记录ping的次数，再返回204状态码\n\n## serveStatus\n已过期，用servePing代替\n\n## serveWrite\n+ 先解析请求，构造points对象\n+ 调用PointsWriter的WritePoints\n+ PointsWriter是个接口，默认赋值的是coordinator.PointsWriter\n+ 0.11. 先创建shardgroup，接着mapShards得到ShardMapping ，\n然后再每个shardinfo的owner创建1个goroutine调用rpc执行写操作。\n+ 0.11. 目的节点的cluster模块监听连接，接收请求，并调用本地的TSDBStore写本地的tsdb。\n+ 1.3.  也是先mapShards， 再writeToShard。少了多data_node的rpc\n","slug":"influxdb-http","published":1,"updated":"2018-02-27T09:05:10.573Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zn000h3l651gbwwf6k","content":"<p>  支持的不同handler</p>\n<h2 id=\"serveOptions\"><a href=\"#serveOptions\" class=\"headerlink\" title=\"serveOptions\"></a>serveOptions</h2><p>直接返回204状态码</p>\n<h2 id=\"servePing\"><a href=\"#servePing\" class=\"headerlink\" title=\"servePing\"></a>servePing</h2><p>先记录ping的次数，再返回204状态码</p>\n<h2 id=\"serveStatus\"><a href=\"#serveStatus\" class=\"headerlink\" title=\"serveStatus\"></a>serveStatus</h2><p>已过期，用servePing代替</p>\n<h2 id=\"serveWrite\"><a href=\"#serveWrite\" class=\"headerlink\" title=\"serveWrite\"></a>serveWrite</h2><ul>\n<li>先解析请求，构造points对象</li>\n<li>调用PointsWriter的WritePoints</li>\n<li>PointsWriter是个接口，默认赋值的是coordinator.PointsWriter</li>\n<li>0.11. 先创建shardgroup，接着mapShards得到ShardMapping ，<br>然后再每个shardinfo的owner创建1个goroutine调用rpc执行写操作。</li>\n<li>0.11. 目的节点的cluster模块监听连接，接收请求，并调用本地的TSDBStore写本地的tsdb。</li>\n<li>1.3.  也是先mapShards， 再writeToShard。少了多data_node的rpc</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>  支持的不同handler</p>\n<h2 id=\"serveOptions\"><a href=\"#serveOptions\" class=\"headerlink\" title=\"serveOptions\"></a>serveOptions</h2><p>直接返回204状态码</p>\n<h2 id=\"servePing\"><a href=\"#servePing\" class=\"headerlink\" title=\"servePing\"></a>servePing</h2><p>先记录ping的次数，再返回204状态码</p>\n<h2 id=\"serveStatus\"><a href=\"#serveStatus\" class=\"headerlink\" title=\"serveStatus\"></a>serveStatus</h2><p>已过期，用servePing代替</p>\n<h2 id=\"serveWrite\"><a href=\"#serveWrite\" class=\"headerlink\" title=\"serveWrite\"></a>serveWrite</h2><ul>\n<li>先解析请求，构造points对象</li>\n<li>调用PointsWriter的WritePoints</li>\n<li>PointsWriter是个接口，默认赋值的是coordinator.PointsWriter</li>\n<li>0.11. 先创建shardgroup，接着mapShards得到ShardMapping ，<br>然后再每个shardinfo的owner创建1个goroutine调用rpc执行写操作。</li>\n<li>0.11. 目的节点的cluster模块监听连接，接收请求，并调用本地的TSDBStore写本地的tsdb。</li>\n<li>1.3.  也是先mapShards， 再writeToShard。少了多data_node的rpc</li>\n</ul>\n"},{"title":"influxdb_monitor","date":"2018-02-27T11:49:45.000Z","_content":"## 1. 前言\n  无论是开发还是运维，对于influxd(InfluxDb服务端)的运行状态信息的获取都是至关重要的。\n在influxd内部把监控信息分成了两大类: Diagnostics 和 Statistics 。 这些信息默认是持久化到\ninfluxdb内的，对应得database是 `_internal` ， 每隔10s写入一次。\n\n\n## 2. Statistics\n  Statistics信息是可以计数的数字，需要定期存储起来以便事后分析。例如写入点的个数，查询请求数等。  \n\n### 2.1 查询statistics\n1. 在console执行命令。 SHOW STATS\n2. 读http服务。 curl http://localhost:8086/debug/vars\n\n### 2.2 添加statistics\n对于新创建的服务，添加Statistics信息。参考以下步骤:\n1. 定义Statistics结构，并作为的服务的Field之一。\n```\ntype ShardWriteStatistics struct {\n\tDirectWriteReq      int64\n\tFlushWriteReq int64\n\tFlushCount  int64\n}\n```\n2. 在服务相关的地方执行原子计数增加。  \n```\natomic.AddInt64(&w.stats.FlushCount, 1)\n```\n3. 实现接口 monitor.Reporter。\n```\nfunc (w *ShardWriter) Statistics(tags map[string]string) []models.Statistic {\n\treturn []models.Statistic{{\n\t\tName: \"shard_write\",\n\t\tTags: tags,\n\t\tValues: map[string]interface{}{\n\t\t\tdirectWriteReq:    atomic.LoadInt64(&w.stats.DirectWriteReq),\n\t\t\tflushWriteReq:     atomic.LoadInt64(&w.stats.FlushWriteReq),\n\t\t\tflushCount:        atomic.LoadInt64(&w.stats.FlushCount),\n\t\t},\n\t}}\n}\n```\n4. 透出statistics信息。如果新服务实现了service接口，默认会注册到server的;其他情况可以在Server的Statistics方法中调用，并append到\n最终结果中。\n```\nstatistics = append(statistics, s.ShardWriter.Statistics(tags)...)\n```\n\n## 3. Diagnostics\n  Diagnostics信息可以不是数字，也不需要存储，一般在内存中。例如influxd版本信息，各个service\n的配置信息等。\n\n### 3.1 查询diagnostics\n1. 在console执行命令。 SHOW DIAGNOSTICS\n\n### 3.2 添加diagnostics\n  对于新创建的服务的配置信息或者运行时参数，可以作为diagnostics信息透出。可按下面步骤添加\n1. 对新服务的config结构，实现接口 diagnostics.Client\n```\nfunc (c Config) Diagnostics() (*diagnostics.Diagnostics, error) {\n\treturn diagnostics.RowFromMap(map[string]interface{}{\n\t\t\"write-timeout\":          c.WriteTimeout,\n\t\t\"max-concurrent-queries\": c.MaxConcurrentQueries,\n\t\t\"query-timeout\":          c.QueryTimeout,\n\t\t\"log-queries-after\":      c.LogQueriesAfter,\n\t\t\"max-select-point\":       c.MaxSelectPointN,\n\t\t\"max-select-series\":      c.MaxSelectSeriesN,\n\t\t\"max-select-buckets\":     c.MaxSelectBucketsN,\n\t}), nil\n}\n```\n2. 在run包的config.go中的diagnosticsClients添加\n```\nfunc (c *Config) diagnosticsClients() map[string]diagnostics.Client {\n \tm := map[string]diagnostics.Client{\n\t\t\"config\": c,\n\t\t\"config-data\":        c.Data,\n\n\t\t\"config-dataext\":        c.DataExt,  // added config\n\n\t\t\"config-meta\":        c.Meta,\n\t\t\"config-retention\":   c.Retention,\n\t\t\"config-precreator\":  c.Precreator,\n\t\t\"config-monitor\":    c.Monitor,\n\t\t\"config-httpd\":      c.HTTPD,\n\t\t}\n\treturn m\n}\n```\n\n\n## 4. References\n[Server monitoring](https://docs.influxdata.com/influxdb/v1.4/troubleshooting/statistics/)\n[System Monitoring](https://github.com/influxdata/influxdb/blob/master/monitor/README.md)\n[How to use the SHOW STATS command and the \\_internal database to monitor InfluxDB](https://www.influxdata.com/blog/how-to-use-the-show-stats-command-and-the-_internal-database-to-monitor-influxdb/)\n","source":"_posts/2018-02-27-influxdb-monitor.md","raw":"---\ntitle: influxdb_monitor\ndate: 2018-02-27 19:49:45\ntags:\n---\n## 1. 前言\n  无论是开发还是运维，对于influxd(InfluxDb服务端)的运行状态信息的获取都是至关重要的。\n在influxd内部把监控信息分成了两大类: Diagnostics 和 Statistics 。 这些信息默认是持久化到\ninfluxdb内的，对应得database是 `_internal` ， 每隔10s写入一次。\n\n\n## 2. Statistics\n  Statistics信息是可以计数的数字，需要定期存储起来以便事后分析。例如写入点的个数，查询请求数等。  \n\n### 2.1 查询statistics\n1. 在console执行命令。 SHOW STATS\n2. 读http服务。 curl http://localhost:8086/debug/vars\n\n### 2.2 添加statistics\n对于新创建的服务，添加Statistics信息。参考以下步骤:\n1. 定义Statistics结构，并作为的服务的Field之一。\n```\ntype ShardWriteStatistics struct {\n\tDirectWriteReq      int64\n\tFlushWriteReq int64\n\tFlushCount  int64\n}\n```\n2. 在服务相关的地方执行原子计数增加。  \n```\natomic.AddInt64(&w.stats.FlushCount, 1)\n```\n3. 实现接口 monitor.Reporter。\n```\nfunc (w *ShardWriter) Statistics(tags map[string]string) []models.Statistic {\n\treturn []models.Statistic{{\n\t\tName: \"shard_write\",\n\t\tTags: tags,\n\t\tValues: map[string]interface{}{\n\t\t\tdirectWriteReq:    atomic.LoadInt64(&w.stats.DirectWriteReq),\n\t\t\tflushWriteReq:     atomic.LoadInt64(&w.stats.FlushWriteReq),\n\t\t\tflushCount:        atomic.LoadInt64(&w.stats.FlushCount),\n\t\t},\n\t}}\n}\n```\n4. 透出statistics信息。如果新服务实现了service接口，默认会注册到server的;其他情况可以在Server的Statistics方法中调用，并append到\n最终结果中。\n```\nstatistics = append(statistics, s.ShardWriter.Statistics(tags)...)\n```\n\n## 3. Diagnostics\n  Diagnostics信息可以不是数字，也不需要存储，一般在内存中。例如influxd版本信息，各个service\n的配置信息等。\n\n### 3.1 查询diagnostics\n1. 在console执行命令。 SHOW DIAGNOSTICS\n\n### 3.2 添加diagnostics\n  对于新创建的服务的配置信息或者运行时参数，可以作为diagnostics信息透出。可按下面步骤添加\n1. 对新服务的config结构，实现接口 diagnostics.Client\n```\nfunc (c Config) Diagnostics() (*diagnostics.Diagnostics, error) {\n\treturn diagnostics.RowFromMap(map[string]interface{}{\n\t\t\"write-timeout\":          c.WriteTimeout,\n\t\t\"max-concurrent-queries\": c.MaxConcurrentQueries,\n\t\t\"query-timeout\":          c.QueryTimeout,\n\t\t\"log-queries-after\":      c.LogQueriesAfter,\n\t\t\"max-select-point\":       c.MaxSelectPointN,\n\t\t\"max-select-series\":      c.MaxSelectSeriesN,\n\t\t\"max-select-buckets\":     c.MaxSelectBucketsN,\n\t}), nil\n}\n```\n2. 在run包的config.go中的diagnosticsClients添加\n```\nfunc (c *Config) diagnosticsClients() map[string]diagnostics.Client {\n \tm := map[string]diagnostics.Client{\n\t\t\"config\": c,\n\t\t\"config-data\":        c.Data,\n\n\t\t\"config-dataext\":        c.DataExt,  // added config\n\n\t\t\"config-meta\":        c.Meta,\n\t\t\"config-retention\":   c.Retention,\n\t\t\"config-precreator\":  c.Precreator,\n\t\t\"config-monitor\":    c.Monitor,\n\t\t\"config-httpd\":      c.HTTPD,\n\t\t}\n\treturn m\n}\n```\n\n\n## 4. References\n[Server monitoring](https://docs.influxdata.com/influxdb/v1.4/troubleshooting/statistics/)\n[System Monitoring](https://github.com/influxdata/influxdb/blob/master/monitor/README.md)\n[How to use the SHOW STATS command and the \\_internal database to monitor InfluxDB](https://www.influxdata.com/blog/how-to-use-the-show-stats-command-and-the-_internal-database-to-monitor-influxdb/)\n","slug":"influxdb-monitor","published":1,"updated":"2018-03-06T08:49:02.068Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zo000i3l65m038e39s","content":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>  无论是开发还是运维，对于influxd(InfluxDb服务端)的运行状态信息的获取都是至关重要的。<br>在influxd内部把监控信息分成了两大类: Diagnostics 和 Statistics 。 这些信息默认是持久化到<br>influxdb内的，对应得database是 <code>_internal</code> ， 每隔10s写入一次。</p>\n<h2 id=\"2-Statistics\"><a href=\"#2-Statistics\" class=\"headerlink\" title=\"2. Statistics\"></a>2. Statistics</h2><p>  Statistics信息是可以计数的数字，需要定期存储起来以便事后分析。例如写入点的个数，查询请求数等。  </p>\n<h3 id=\"2-1-查询statistics\"><a href=\"#2-1-查询statistics\" class=\"headerlink\" title=\"2.1 查询statistics\"></a>2.1 查询statistics</h3><ol>\n<li>在console执行命令。 SHOW STATS</li>\n<li>读http服务。 curl <a href=\"http://localhost:8086/debug/vars\" target=\"_blank\" rel=\"noopener\">http://localhost:8086/debug/vars</a></li>\n</ol>\n<h3 id=\"2-2-添加statistics\"><a href=\"#2-2-添加statistics\" class=\"headerlink\" title=\"2.2 添加statistics\"></a>2.2 添加statistics</h3><p>对于新创建的服务，添加Statistics信息。参考以下步骤:</p>\n<ol>\n<li><p>定义Statistics结构，并作为的服务的Field之一。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">type ShardWriteStatistics struct &#123;</div><div class=\"line\">\tDirectWriteReq      int64</div><div class=\"line\">\tFlushWriteReq int64</div><div class=\"line\">\tFlushCount  int64</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>在服务相关的地方执行原子计数增加。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">atomic.AddInt64(&amp;w.stats.FlushCount, 1)</div></pre></td></tr></table></figure>\n</li>\n<li><p>实现接口 monitor.Reporter。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">func (w *ShardWriter) Statistics(tags map[string]string) []models.Statistic &#123;</div><div class=\"line\">\treturn []models.Statistic&#123;&#123;</div><div class=\"line\">\t\tName: &quot;shard_write&quot;,</div><div class=\"line\">\t\tTags: tags,</div><div class=\"line\">\t\tValues: map[string]interface&#123;&#125;&#123;</div><div class=\"line\">\t\t\tdirectWriteReq:    atomic.LoadInt64(&amp;w.stats.DirectWriteReq),</div><div class=\"line\">\t\t\tflushWriteReq:     atomic.LoadInt64(&amp;w.stats.FlushWriteReq),</div><div class=\"line\">\t\t\tflushCount:        atomic.LoadInt64(&amp;w.stats.FlushCount),</div><div class=\"line\">\t\t&#125;,</div><div class=\"line\">\t&#125;&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>透出statistics信息。如果新服务实现了service接口，默认会注册到server的;其他情况可以在Server的Statistics方法中调用，并append到<br>最终结果中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">statistics = append(statistics, s.ShardWriter.Statistics(tags)...)</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"3-Diagnostics\"><a href=\"#3-Diagnostics\" class=\"headerlink\" title=\"3. Diagnostics\"></a>3. Diagnostics</h2><p>  Diagnostics信息可以不是数字，也不需要存储，一般在内存中。例如influxd版本信息，各个service<br>的配置信息等。</p>\n<h3 id=\"3-1-查询diagnostics\"><a href=\"#3-1-查询diagnostics\" class=\"headerlink\" title=\"3.1 查询diagnostics\"></a>3.1 查询diagnostics</h3><ol>\n<li>在console执行命令。 SHOW DIAGNOSTICS</li>\n</ol>\n<h3 id=\"3-2-添加diagnostics\"><a href=\"#3-2-添加diagnostics\" class=\"headerlink\" title=\"3.2 添加diagnostics\"></a>3.2 添加diagnostics</h3><p>  对于新创建的服务的配置信息或者运行时参数，可以作为diagnostics信息透出。可按下面步骤添加</p>\n<ol>\n<li><p>对新服务的config结构，实现接口 diagnostics.Client</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">func (c Config) Diagnostics() (*diagnostics.Diagnostics, error) &#123;</div><div class=\"line\">\treturn diagnostics.RowFromMap(map[string]interface&#123;&#125;&#123;</div><div class=\"line\">\t\t&quot;write-timeout&quot;:          c.WriteTimeout,</div><div class=\"line\">\t\t&quot;max-concurrent-queries&quot;: c.MaxConcurrentQueries,</div><div class=\"line\">\t\t&quot;query-timeout&quot;:          c.QueryTimeout,</div><div class=\"line\">\t\t&quot;log-queries-after&quot;:      c.LogQueriesAfter,</div><div class=\"line\">\t\t&quot;max-select-point&quot;:       c.MaxSelectPointN,</div><div class=\"line\">\t\t&quot;max-select-series&quot;:      c.MaxSelectSeriesN,</div><div class=\"line\">\t\t&quot;max-select-buckets&quot;:     c.MaxSelectBucketsN,</div><div class=\"line\">\t&#125;), nil</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>在run包的config.go中的diagnosticsClients添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">func (c *Config) diagnosticsClients() map[string]diagnostics.Client &#123;</div><div class=\"line\"> \tm := map[string]diagnostics.Client&#123;</div><div class=\"line\">\t\t&quot;config&quot;: c,</div><div class=\"line\">\t\t&quot;config-data&quot;:        c.Data,</div><div class=\"line\"></div><div class=\"line\">\t\t&quot;config-dataext&quot;:        c.DataExt,  // added config</div><div class=\"line\"></div><div class=\"line\">\t\t&quot;config-meta&quot;:        c.Meta,</div><div class=\"line\">\t\t&quot;config-retention&quot;:   c.Retention,</div><div class=\"line\">\t\t&quot;config-precreator&quot;:  c.Precreator,</div><div class=\"line\">\t\t&quot;config-monitor&quot;:    c.Monitor,</div><div class=\"line\">\t\t&quot;config-httpd&quot;:      c.HTTPD,</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\treturn m</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"4-References\"><a href=\"#4-References\" class=\"headerlink\" title=\"4. References\"></a>4. References</h2><p><a href=\"https://docs.influxdata.com/influxdb/v1.4/troubleshooting/statistics/\" target=\"_blank\" rel=\"noopener\">Server monitoring</a><br><a href=\"https://github.com/influxdata/influxdb/blob/master/monitor/README.md\" target=\"_blank\" rel=\"noopener\">System Monitoring</a><br><a href=\"https://www.influxdata.com/blog/how-to-use-the-show-stats-command-and-the-_internal-database-to-monitor-influxdb/\" target=\"_blank\" rel=\"noopener\">How to use the SHOW STATS command and the _internal database to monitor InfluxDB</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>  无论是开发还是运维，对于influxd(InfluxDb服务端)的运行状态信息的获取都是至关重要的。<br>在influxd内部把监控信息分成了两大类: Diagnostics 和 Statistics 。 这些信息默认是持久化到<br>influxdb内的，对应得database是 <code>_internal</code> ， 每隔10s写入一次。</p>\n<h2 id=\"2-Statistics\"><a href=\"#2-Statistics\" class=\"headerlink\" title=\"2. Statistics\"></a>2. Statistics</h2><p>  Statistics信息是可以计数的数字，需要定期存储起来以便事后分析。例如写入点的个数，查询请求数等。  </p>\n<h3 id=\"2-1-查询statistics\"><a href=\"#2-1-查询statistics\" class=\"headerlink\" title=\"2.1 查询statistics\"></a>2.1 查询statistics</h3><ol>\n<li>在console执行命令。 SHOW STATS</li>\n<li>读http服务。 curl <a href=\"http://localhost:8086/debug/vars\" target=\"_blank\" rel=\"noopener\">http://localhost:8086/debug/vars</a></li>\n</ol>\n<h3 id=\"2-2-添加statistics\"><a href=\"#2-2-添加statistics\" class=\"headerlink\" title=\"2.2 添加statistics\"></a>2.2 添加statistics</h3><p>对于新创建的服务，添加Statistics信息。参考以下步骤:</p>\n<ol>\n<li><p>定义Statistics结构，并作为的服务的Field之一。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">type ShardWriteStatistics struct &#123;</div><div class=\"line\">\tDirectWriteReq      int64</div><div class=\"line\">\tFlushWriteReq int64</div><div class=\"line\">\tFlushCount  int64</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>在服务相关的地方执行原子计数增加。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">atomic.AddInt64(&amp;w.stats.FlushCount, 1)</div></pre></td></tr></table></figure>\n</li>\n<li><p>实现接口 monitor.Reporter。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">func (w *ShardWriter) Statistics(tags map[string]string) []models.Statistic &#123;</div><div class=\"line\">\treturn []models.Statistic&#123;&#123;</div><div class=\"line\">\t\tName: &quot;shard_write&quot;,</div><div class=\"line\">\t\tTags: tags,</div><div class=\"line\">\t\tValues: map[string]interface&#123;&#125;&#123;</div><div class=\"line\">\t\t\tdirectWriteReq:    atomic.LoadInt64(&amp;w.stats.DirectWriteReq),</div><div class=\"line\">\t\t\tflushWriteReq:     atomic.LoadInt64(&amp;w.stats.FlushWriteReq),</div><div class=\"line\">\t\t\tflushCount:        atomic.LoadInt64(&amp;w.stats.FlushCount),</div><div class=\"line\">\t\t&#125;,</div><div class=\"line\">\t&#125;&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>透出statistics信息。如果新服务实现了service接口，默认会注册到server的;其他情况可以在Server的Statistics方法中调用，并append到<br>最终结果中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">statistics = append(statistics, s.ShardWriter.Statistics(tags)...)</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"3-Diagnostics\"><a href=\"#3-Diagnostics\" class=\"headerlink\" title=\"3. Diagnostics\"></a>3. Diagnostics</h2><p>  Diagnostics信息可以不是数字，也不需要存储，一般在内存中。例如influxd版本信息，各个service<br>的配置信息等。</p>\n<h3 id=\"3-1-查询diagnostics\"><a href=\"#3-1-查询diagnostics\" class=\"headerlink\" title=\"3.1 查询diagnostics\"></a>3.1 查询diagnostics</h3><ol>\n<li>在console执行命令。 SHOW DIAGNOSTICS</li>\n</ol>\n<h3 id=\"3-2-添加diagnostics\"><a href=\"#3-2-添加diagnostics\" class=\"headerlink\" title=\"3.2 添加diagnostics\"></a>3.2 添加diagnostics</h3><p>  对于新创建的服务的配置信息或者运行时参数，可以作为diagnostics信息透出。可按下面步骤添加</p>\n<ol>\n<li><p>对新服务的config结构，实现接口 diagnostics.Client</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">func (c Config) Diagnostics() (*diagnostics.Diagnostics, error) &#123;</div><div class=\"line\">\treturn diagnostics.RowFromMap(map[string]interface&#123;&#125;&#123;</div><div class=\"line\">\t\t&quot;write-timeout&quot;:          c.WriteTimeout,</div><div class=\"line\">\t\t&quot;max-concurrent-queries&quot;: c.MaxConcurrentQueries,</div><div class=\"line\">\t\t&quot;query-timeout&quot;:          c.QueryTimeout,</div><div class=\"line\">\t\t&quot;log-queries-after&quot;:      c.LogQueriesAfter,</div><div class=\"line\">\t\t&quot;max-select-point&quot;:       c.MaxSelectPointN,</div><div class=\"line\">\t\t&quot;max-select-series&quot;:      c.MaxSelectSeriesN,</div><div class=\"line\">\t\t&quot;max-select-buckets&quot;:     c.MaxSelectBucketsN,</div><div class=\"line\">\t&#125;), nil</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>在run包的config.go中的diagnosticsClients添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">func (c *Config) diagnosticsClients() map[string]diagnostics.Client &#123;</div><div class=\"line\"> \tm := map[string]diagnostics.Client&#123;</div><div class=\"line\">\t\t&quot;config&quot;: c,</div><div class=\"line\">\t\t&quot;config-data&quot;:        c.Data,</div><div class=\"line\"></div><div class=\"line\">\t\t&quot;config-dataext&quot;:        c.DataExt,  // added config</div><div class=\"line\"></div><div class=\"line\">\t\t&quot;config-meta&quot;:        c.Meta,</div><div class=\"line\">\t\t&quot;config-retention&quot;:   c.Retention,</div><div class=\"line\">\t\t&quot;config-precreator&quot;:  c.Precreator,</div><div class=\"line\">\t\t&quot;config-monitor&quot;:    c.Monitor,</div><div class=\"line\">\t\t&quot;config-httpd&quot;:      c.HTTPD,</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\treturn m</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"4-References\"><a href=\"#4-References\" class=\"headerlink\" title=\"4. References\"></a>4. References</h2><p><a href=\"https://docs.influxdata.com/influxdb/v1.4/troubleshooting/statistics/\" target=\"_blank\" rel=\"noopener\">Server monitoring</a><br><a href=\"https://github.com/influxdata/influxdb/blob/master/monitor/README.md\" target=\"_blank\" rel=\"noopener\">System Monitoring</a><br><a href=\"https://www.influxdata.com/blog/how-to-use-the-show-stats-command-and-the-_internal-database-to-monitor-influxdb/\" target=\"_blank\" rel=\"noopener\">How to use the SHOW STATS command and the _internal database to monitor InfluxDB</a></p>\n"},{"title":"tsdb_references","date":"2018-02-28T03:10:14.000Z","_content":"## 需求\n[Designing apps for Time Series data](http://crispanalytics.com/blog/tag/tsdb/)\n[Time-Series Database Requirements](https://www.xaprb.com/blog/2014/06/08/time-series-database-requirements)\n[Measure Anything, Measure Everything](https://codeascraft.com/2011/02/15/measure-anything-measure-everything/)\n[Thoughts on Time-series Databases](http://jmoiron.net/blog/thoughts-on-timeseries-databases)\n[DB-engines rank categories](https://db-engines.com/en/ranking_categories)\n\n## 设计\n[Writing a Time Series Database from Scratch](https://fabxc.org/tsdb/)\n[TODO](Graphite)\n[TODO](RRDTool)\n[TODO](Promethues)\n\n## Golang\n[The Go Programming Language](http://gopl-zh.b0.upaiyun.com/)\n[The Golang Standard Library by Example](https://books.studygolang.com/The-Golang-Standard-Library-by-Example/)\n\n## 时间序列分析\n[通过机器学习和时间序列数据理解软件系统行为](http://www.infoq.com/cn/articles/system-behaviour-time-series-ml)\n","source":"_posts/2018-02-28-tsdb-references.md","raw":"---\ntitle: tsdb_references\ndate: 2018-02-28 11:10:14\ntags:\n---\n## 需求\n[Designing apps for Time Series data](http://crispanalytics.com/blog/tag/tsdb/)\n[Time-Series Database Requirements](https://www.xaprb.com/blog/2014/06/08/time-series-database-requirements)\n[Measure Anything, Measure Everything](https://codeascraft.com/2011/02/15/measure-anything-measure-everything/)\n[Thoughts on Time-series Databases](http://jmoiron.net/blog/thoughts-on-timeseries-databases)\n[DB-engines rank categories](https://db-engines.com/en/ranking_categories)\n\n## 设计\n[Writing a Time Series Database from Scratch](https://fabxc.org/tsdb/)\n[TODO](Graphite)\n[TODO](RRDTool)\n[TODO](Promethues)\n\n## Golang\n[The Go Programming Language](http://gopl-zh.b0.upaiyun.com/)\n[The Golang Standard Library by Example](https://books.studygolang.com/The-Golang-Standard-Library-by-Example/)\n\n## 时间序列分析\n[通过机器学习和时间序列数据理解软件系统行为](http://www.infoq.com/cn/articles/system-behaviour-time-series-ml)\n","slug":"tsdb-references","published":1,"updated":"2018-08-10T11:02:07.018Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zp000k3l65na1e1ljs","content":"<h2 id=\"需求\"><a href=\"#需求\" class=\"headerlink\" title=\"需求\"></a>需求</h2><p><a href=\"http://crispanalytics.com/blog/tag/tsdb/\" target=\"_blank\" rel=\"noopener\">Designing apps for Time Series data</a><br><a href=\"https://www.xaprb.com/blog/2014/06/08/time-series-database-requirements\" target=\"_blank\" rel=\"noopener\">Time-Series Database Requirements</a><br><a href=\"https://codeascraft.com/2011/02/15/measure-anything-measure-everything/\" target=\"_blank\" rel=\"noopener\">Measure Anything, Measure Everything</a><br><a href=\"http://jmoiron.net/blog/thoughts-on-timeseries-databases\" target=\"_blank\" rel=\"noopener\">Thoughts on Time-series Databases</a><br><a href=\"https://db-engines.com/en/ranking_categories\" target=\"_blank\" rel=\"noopener\">DB-engines rank categories</a></p>\n<h2 id=\"设计\"><a href=\"#设计\" class=\"headerlink\" title=\"设计\"></a>设计</h2><p><a href=\"https://fabxc.org/tsdb/\" target=\"_blank\" rel=\"noopener\">Writing a Time Series Database from Scratch</a><br><a href=\"Graphite\">TODO</a><br><a href=\"RRDTool\">TODO</a><br><a href=\"Promethues\">TODO</a></p>\n<h2 id=\"Golang\"><a href=\"#Golang\" class=\"headerlink\" title=\"Golang\"></a>Golang</h2><p><a href=\"http://gopl-zh.b0.upaiyun.com/\" target=\"_blank\" rel=\"noopener\">The Go Programming Language</a><br><a href=\"https://books.studygolang.com/The-Golang-Standard-Library-by-Example/\" target=\"_blank\" rel=\"noopener\">The Golang Standard Library by Example</a></p>\n<h2 id=\"时间序列分析\"><a href=\"#时间序列分析\" class=\"headerlink\" title=\"时间序列分析\"></a>时间序列分析</h2><p><a href=\"http://www.infoq.com/cn/articles/system-behaviour-time-series-ml\" target=\"_blank\" rel=\"noopener\">通过机器学习和时间序列数据理解软件系统行为</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"需求\"><a href=\"#需求\" class=\"headerlink\" title=\"需求\"></a>需求</h2><p><a href=\"http://crispanalytics.com/blog/tag/tsdb/\" target=\"_blank\" rel=\"noopener\">Designing apps for Time Series data</a><br><a href=\"https://www.xaprb.com/blog/2014/06/08/time-series-database-requirements\" target=\"_blank\" rel=\"noopener\">Time-Series Database Requirements</a><br><a href=\"https://codeascraft.com/2011/02/15/measure-anything-measure-everything/\" target=\"_blank\" rel=\"noopener\">Measure Anything, Measure Everything</a><br><a href=\"http://jmoiron.net/blog/thoughts-on-timeseries-databases\" target=\"_blank\" rel=\"noopener\">Thoughts on Time-series Databases</a><br><a href=\"https://db-engines.com/en/ranking_categories\" target=\"_blank\" rel=\"noopener\">DB-engines rank categories</a></p>\n<h2 id=\"设计\"><a href=\"#设计\" class=\"headerlink\" title=\"设计\"></a>设计</h2><p><a href=\"https://fabxc.org/tsdb/\" target=\"_blank\" rel=\"noopener\">Writing a Time Series Database from Scratch</a><br><a href=\"Graphite\">TODO</a><br><a href=\"RRDTool\">TODO</a><br><a href=\"Promethues\">TODO</a></p>\n<h2 id=\"Golang\"><a href=\"#Golang\" class=\"headerlink\" title=\"Golang\"></a>Golang</h2><p><a href=\"http://gopl-zh.b0.upaiyun.com/\" target=\"_blank\" rel=\"noopener\">The Go Programming Language</a><br><a href=\"https://books.studygolang.com/The-Golang-Standard-Library-by-Example/\" target=\"_blank\" rel=\"noopener\">The Golang Standard Library by Example</a></p>\n<h2 id=\"时间序列分析\"><a href=\"#时间序列分析\" class=\"headerlink\" title=\"时间序列分析\"></a>时间序列分析</h2><p><a href=\"http://www.infoq.com/cn/articles/system-behaviour-time-series-ml\" target=\"_blank\" rel=\"noopener\">通过机器学习和时间序列数据理解软件系统行为</a></p>\n"},{"title":"grpc-go","date":"2018-03-20T06:00:48.000Z","_content":"   grpc-go是一个功能相对完备的rpc框架，支持unary, client streaming, server streaming,\nbidirectional streaming四种模式。由于使用了http2作为传输层，实际上都是stream模式。\n\n## 传输-HTTP2\n+ 二进制\n+ 十种类型的基本帧\n  其中HEADERS DATA对应HTTP1.0/1.1\n+ 多路复用的流\n+ 优先级和依赖性 PRIORITY\n+ 头压缩\n+ 重置 RST_STREAM\n+ 服务器推送 [pool or websocket]\n+ 流量控制\n+ 扩展 [ALTSVC, ]\n\n\n## Wire protocol\n  主要代码google.golang.org/grpc/rpc_util.go的encode方法。返回header和data两部分，\n这两个分布封装成独立的dataFrame发送出去。\n\n在应用层上包含两种类型的帧，分布是Request和Response\n\n```\nRequest → Request-Headers *Length-Prefixed-Message EOS\nResponse → (Response-Headers *Length-Prefixed-Message Trailers) / Trailers-Only\n```\n\n例子：Request\n```\nHEADERS (flags = END_HEADERS)\n:method = POST\n:scheme = http\n:path = /google.pubsub.v2.PublisherService/CreateTopic\n:authority = pubsub.googleapis.com\ngrpc-timeout = 1S\ncontent-type = application/grpc+proto\ngrpc-encoding = gzip\nauthorization = Bearer y235.wef315yfh138vh31hv93hv8h3v\n\nDATA (flags = END_STREAM)\n<Length-Prefixed Message>\n```\n\n例子：Response\n```\nHEADERS (flags = END_HEADERS)\n:status = 200\ngrpc-encoding = gzip\ncontent-type = application/grpc+proto\n\nDATA\n<Length-Prefixed Message>\n\nHEADERS (flags = END_STREAM, END_HEADERS)\ngrpc-status = 0 # OK\ntrace-proto-bin = jher831yy13JHy3hc\n```\n\n## Reliablity\n   gRPC官方并未直接提供服务注册与发现的功能实现，但其设计文档已提供实现的思路，\n并在不同语言的gRPC代码API中已提供了命名解析和负载均衡接口供扩展。   \n\n   服务提供方启动时，首先将服务地址注册到服务注册表，同时定期报心跳到服务注册表以表明服务的存活状态，\n相当于健康检查.服务消费方要访问某个服务时，它通过内置的LB组件向服务注册表查询，同时缓存并定期刷新目标服务地址列表，\n然后以某种负载均衡策略选择一个目标服务地址，最后向目标服务发起请求\n\n优点：不需要额外的负载均衡设备，没有单点故障\n缺点：相关策略机制都在客户端，需支持多语言，开发成本高。升级客户端，需要服务调用方配合一起升级\n\n## 易用性\n    主要体现在API和文档等方面。文档在多语言支持方面比较全面，但是在内容深度方面远远不够。\n    API在使用上没有问题，但是在client端封装不够，conn，client等暴露出来还需要自己创建和维护。\n需要有个Factory可以根据参数获取到client，在Factory内部维护conn和client的实例化。\n\n## 经验与收获\n+ go语言context在大型开源项目里的使用\n+ 生态建设，与其它开源项目的合作。\n\n## server\n+ 关键方法\nNewServer\nServe\nhandleRawConn\nnewHTTP2Transport\n\n+ 主要流程\ngrpcServer.Serve里面是个死循环，不断accept新conn，\n然后创建一个goroutine处理conn\nHandleStreams 里面是个死循环，从conn读数据并解析成Frame\n遇到业务方法相关的Frame，会新创建个goroutine进行处理。\n\n## Client\nDialContext 创建clientconn\ninvoke 创建clientstream\n\n## References\n[http2讲解](https://ye11ow.gitbooks.io/http2-explained/content/)\n[HPACK 完全解析](https://www.jianshu.com/p/f44b930cfcac)\n[深入了解 gRPC：协议](https://zhuanlan.zhihu.com/p/27961684)\n[gRPC-rs：从 C 到 Rust](https://zhuanlan.zhihu.com/p/27995238)\n[如何设计一个通讯协议](http://mrpeak.cn/blog/tcp-rpc-protocol/)\n[体系化认识RPC](http://www.infoq.com/cn/articles/get-to-know-rpc)\n[TiDB与gRPC的那点事](http://www.infoq.com/cn/articles/tidb-and-grpc)\n[gRPC over HTTP2](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md)\n[based pollset implementation in gRPC](https://github.com/grpc/grpc/blob/master/doc/epoll-polling-engine.md)\n[gRPC服务发现&负载均衡](http://www.open-open.com/lib/view/open1489473315209.html)\n[谈谈 HTTP/2 的协议协商机制](https://imququ.com/post/protocol-negotiation-in-http2.html)\n","source":"_posts/2018-03-20-grpc-go.md","raw":"---\ntitle: grpc-go\ndate: 2018-03-20 14:00:48\ntags:\n---\n   grpc-go是一个功能相对完备的rpc框架，支持unary, client streaming, server streaming,\nbidirectional streaming四种模式。由于使用了http2作为传输层，实际上都是stream模式。\n\n## 传输-HTTP2\n+ 二进制\n+ 十种类型的基本帧\n  其中HEADERS DATA对应HTTP1.0/1.1\n+ 多路复用的流\n+ 优先级和依赖性 PRIORITY\n+ 头压缩\n+ 重置 RST_STREAM\n+ 服务器推送 [pool or websocket]\n+ 流量控制\n+ 扩展 [ALTSVC, ]\n\n\n## Wire protocol\n  主要代码google.golang.org/grpc/rpc_util.go的encode方法。返回header和data两部分，\n这两个分布封装成独立的dataFrame发送出去。\n\n在应用层上包含两种类型的帧，分布是Request和Response\n\n```\nRequest → Request-Headers *Length-Prefixed-Message EOS\nResponse → (Response-Headers *Length-Prefixed-Message Trailers) / Trailers-Only\n```\n\n例子：Request\n```\nHEADERS (flags = END_HEADERS)\n:method = POST\n:scheme = http\n:path = /google.pubsub.v2.PublisherService/CreateTopic\n:authority = pubsub.googleapis.com\ngrpc-timeout = 1S\ncontent-type = application/grpc+proto\ngrpc-encoding = gzip\nauthorization = Bearer y235.wef315yfh138vh31hv93hv8h3v\n\nDATA (flags = END_STREAM)\n<Length-Prefixed Message>\n```\n\n例子：Response\n```\nHEADERS (flags = END_HEADERS)\n:status = 200\ngrpc-encoding = gzip\ncontent-type = application/grpc+proto\n\nDATA\n<Length-Prefixed Message>\n\nHEADERS (flags = END_STREAM, END_HEADERS)\ngrpc-status = 0 # OK\ntrace-proto-bin = jher831yy13JHy3hc\n```\n\n## Reliablity\n   gRPC官方并未直接提供服务注册与发现的功能实现，但其设计文档已提供实现的思路，\n并在不同语言的gRPC代码API中已提供了命名解析和负载均衡接口供扩展。   \n\n   服务提供方启动时，首先将服务地址注册到服务注册表，同时定期报心跳到服务注册表以表明服务的存活状态，\n相当于健康检查.服务消费方要访问某个服务时，它通过内置的LB组件向服务注册表查询，同时缓存并定期刷新目标服务地址列表，\n然后以某种负载均衡策略选择一个目标服务地址，最后向目标服务发起请求\n\n优点：不需要额外的负载均衡设备，没有单点故障\n缺点：相关策略机制都在客户端，需支持多语言，开发成本高。升级客户端，需要服务调用方配合一起升级\n\n## 易用性\n    主要体现在API和文档等方面。文档在多语言支持方面比较全面，但是在内容深度方面远远不够。\n    API在使用上没有问题，但是在client端封装不够，conn，client等暴露出来还需要自己创建和维护。\n需要有个Factory可以根据参数获取到client，在Factory内部维护conn和client的实例化。\n\n## 经验与收获\n+ go语言context在大型开源项目里的使用\n+ 生态建设，与其它开源项目的合作。\n\n## server\n+ 关键方法\nNewServer\nServe\nhandleRawConn\nnewHTTP2Transport\n\n+ 主要流程\ngrpcServer.Serve里面是个死循环，不断accept新conn，\n然后创建一个goroutine处理conn\nHandleStreams 里面是个死循环，从conn读数据并解析成Frame\n遇到业务方法相关的Frame，会新创建个goroutine进行处理。\n\n## Client\nDialContext 创建clientconn\ninvoke 创建clientstream\n\n## References\n[http2讲解](https://ye11ow.gitbooks.io/http2-explained/content/)\n[HPACK 完全解析](https://www.jianshu.com/p/f44b930cfcac)\n[深入了解 gRPC：协议](https://zhuanlan.zhihu.com/p/27961684)\n[gRPC-rs：从 C 到 Rust](https://zhuanlan.zhihu.com/p/27995238)\n[如何设计一个通讯协议](http://mrpeak.cn/blog/tcp-rpc-protocol/)\n[体系化认识RPC](http://www.infoq.com/cn/articles/get-to-know-rpc)\n[TiDB与gRPC的那点事](http://www.infoq.com/cn/articles/tidb-and-grpc)\n[gRPC over HTTP2](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md)\n[based pollset implementation in gRPC](https://github.com/grpc/grpc/blob/master/doc/epoll-polling-engine.md)\n[gRPC服务发现&负载均衡](http://www.open-open.com/lib/view/open1489473315209.html)\n[谈谈 HTTP/2 的协议协商机制](https://imququ.com/post/protocol-negotiation-in-http2.html)\n","slug":"grpc-go","published":1,"updated":"2018-05-23T08:35:23.211Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zq000m3l65yk94vwwk","content":"<p>   grpc-go是一个功能相对完备的rpc框架，支持unary, client streaming, server streaming,<br>bidirectional streaming四种模式。由于使用了http2作为传输层，实际上都是stream模式。</p>\n<h2 id=\"传输-HTTP2\"><a href=\"#传输-HTTP2\" class=\"headerlink\" title=\"传输-HTTP2\"></a>传输-HTTP2</h2><ul>\n<li>二进制</li>\n<li>十种类型的基本帧<br>其中HEADERS DATA对应HTTP1.0/1.1</li>\n<li>多路复用的流</li>\n<li>优先级和依赖性 PRIORITY</li>\n<li>头压缩</li>\n<li>重置 RST_STREAM</li>\n<li>服务器推送 [pool or websocket]</li>\n<li>流量控制</li>\n<li>扩展 [ALTSVC, ]</li>\n</ul>\n<h2 id=\"Wire-protocol\"><a href=\"#Wire-protocol\" class=\"headerlink\" title=\"Wire protocol\"></a>Wire protocol</h2><p>  主要代码google.golang.org/grpc/rpc_util.go的encode方法。返回header和data两部分，<br>这两个分布封装成独立的dataFrame发送出去。</p>\n<p>在应用层上包含两种类型的帧，分布是Request和Response</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Request → Request-Headers *Length-Prefixed-Message EOS</div><div class=\"line\">Response → (Response-Headers *Length-Prefixed-Message Trailers) / Trailers-Only</div></pre></td></tr></table></figure>\n<p>例子：Request<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">HEADERS (flags = END_HEADERS)</div><div class=\"line\">:method = POST</div><div class=\"line\">:scheme = http</div><div class=\"line\">:path = /google.pubsub.v2.PublisherService/CreateTopic</div><div class=\"line\">:authority = pubsub.googleapis.com</div><div class=\"line\">grpc-timeout = 1S</div><div class=\"line\">content-type = application/grpc+proto</div><div class=\"line\">grpc-encoding = gzip</div><div class=\"line\">authorization = Bearer y235.wef315yfh138vh31hv93hv8h3v</div><div class=\"line\"></div><div class=\"line\">DATA (flags = END_STREAM)</div><div class=\"line\">&lt;Length-Prefixed Message&gt;</div></pre></td></tr></table></figure></p>\n<p>例子：Response<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">HEADERS (flags = END_HEADERS)</div><div class=\"line\">:status = 200</div><div class=\"line\">grpc-encoding = gzip</div><div class=\"line\">content-type = application/grpc+proto</div><div class=\"line\"></div><div class=\"line\">DATA</div><div class=\"line\">&lt;Length-Prefixed Message&gt;</div><div class=\"line\"></div><div class=\"line\">HEADERS (flags = END_STREAM, END_HEADERS)</div><div class=\"line\">grpc-status = 0 # OK</div><div class=\"line\">trace-proto-bin = jher831yy13JHy3hc</div></pre></td></tr></table></figure></p>\n<h2 id=\"Reliablity\"><a href=\"#Reliablity\" class=\"headerlink\" title=\"Reliablity\"></a>Reliablity</h2><p>   gRPC官方并未直接提供服务注册与发现的功能实现，但其设计文档已提供实现的思路，<br>并在不同语言的gRPC代码API中已提供了命名解析和负载均衡接口供扩展。   </p>\n<p>   服务提供方启动时，首先将服务地址注册到服务注册表，同时定期报心跳到服务注册表以表明服务的存活状态，<br>相当于健康检查.服务消费方要访问某个服务时，它通过内置的LB组件向服务注册表查询，同时缓存并定期刷新目标服务地址列表，<br>然后以某种负载均衡策略选择一个目标服务地址，最后向目标服务发起请求</p>\n<p>优点：不需要额外的负载均衡设备，没有单点故障<br>缺点：相关策略机制都在客户端，需支持多语言，开发成本高。升级客户端，需要服务调用方配合一起升级</p>\n<h2 id=\"易用性\"><a href=\"#易用性\" class=\"headerlink\" title=\"易用性\"></a>易用性</h2><pre><code>主要体现在API和文档等方面。文档在多语言支持方面比较全面，但是在内容深度方面远远不够。\nAPI在使用上没有问题，但是在client端封装不够，conn，client等暴露出来还需要自己创建和维护。\n</code></pre><p>需要有个Factory可以根据参数获取到client，在Factory内部维护conn和client的实例化。</p>\n<h2 id=\"经验与收获\"><a href=\"#经验与收获\" class=\"headerlink\" title=\"经验与收获\"></a>经验与收获</h2><ul>\n<li>go语言context在大型开源项目里的使用</li>\n<li>生态建设，与其它开源项目的合作。</li>\n</ul>\n<h2 id=\"server\"><a href=\"#server\" class=\"headerlink\" title=\"server\"></a>server</h2><ul>\n<li><p>关键方法<br>NewServer<br>Serve<br>handleRawConn<br>newHTTP2Transport</p>\n</li>\n<li><p>主要流程<br>grpcServer.Serve里面是个死循环，不断accept新conn，<br>然后创建一个goroutine处理conn<br>HandleStreams 里面是个死循环，从conn读数据并解析成Frame<br>遇到业务方法相关的Frame，会新创建个goroutine进行处理。</p>\n</li>\n</ul>\n<h2 id=\"Client\"><a href=\"#Client\" class=\"headerlink\" title=\"Client\"></a>Client</h2><p>DialContext 创建clientconn<br>invoke 创建clientstream</p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p><a href=\"https://ye11ow.gitbooks.io/http2-explained/content/\" target=\"_blank\" rel=\"noopener\">http2讲解</a><br><a href=\"https://www.jianshu.com/p/f44b930cfcac\" target=\"_blank\" rel=\"noopener\">HPACK 完全解析</a><br><a href=\"https://zhuanlan.zhihu.com/p/27961684\" target=\"_blank\" rel=\"noopener\">深入了解 gRPC：协议</a><br><a href=\"https://zhuanlan.zhihu.com/p/27995238\" target=\"_blank\" rel=\"noopener\">gRPC-rs：从 C 到 Rust</a><br><a href=\"http://mrpeak.cn/blog/tcp-rpc-protocol/\" target=\"_blank\" rel=\"noopener\">如何设计一个通讯协议</a><br><a href=\"http://www.infoq.com/cn/articles/get-to-know-rpc\" target=\"_blank\" rel=\"noopener\">体系化认识RPC</a><br><a href=\"http://www.infoq.com/cn/articles/tidb-and-grpc\" target=\"_blank\" rel=\"noopener\">TiDB与gRPC的那点事</a><br><a href=\"https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md\" target=\"_blank\" rel=\"noopener\">gRPC over HTTP2</a><br><a href=\"https://github.com/grpc/grpc/blob/master/doc/epoll-polling-engine.md\" target=\"_blank\" rel=\"noopener\">based pollset implementation in gRPC</a><br><a href=\"http://www.open-open.com/lib/view/open1489473315209.html\" target=\"_blank\" rel=\"noopener\">gRPC服务发现&amp;负载均衡</a><br><a href=\"https://imququ.com/post/protocol-negotiation-in-http2.html\" target=\"_blank\" rel=\"noopener\">谈谈 HTTP/2 的协议协商机制</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>   grpc-go是一个功能相对完备的rpc框架，支持unary, client streaming, server streaming,<br>bidirectional streaming四种模式。由于使用了http2作为传输层，实际上都是stream模式。</p>\n<h2 id=\"传输-HTTP2\"><a href=\"#传输-HTTP2\" class=\"headerlink\" title=\"传输-HTTP2\"></a>传输-HTTP2</h2><ul>\n<li>二进制</li>\n<li>十种类型的基本帧<br>其中HEADERS DATA对应HTTP1.0/1.1</li>\n<li>多路复用的流</li>\n<li>优先级和依赖性 PRIORITY</li>\n<li>头压缩</li>\n<li>重置 RST_STREAM</li>\n<li>服务器推送 [pool or websocket]</li>\n<li>流量控制</li>\n<li>扩展 [ALTSVC, ]</li>\n</ul>\n<h2 id=\"Wire-protocol\"><a href=\"#Wire-protocol\" class=\"headerlink\" title=\"Wire protocol\"></a>Wire protocol</h2><p>  主要代码google.golang.org/grpc/rpc_util.go的encode方法。返回header和data两部分，<br>这两个分布封装成独立的dataFrame发送出去。</p>\n<p>在应用层上包含两种类型的帧，分布是Request和Response</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Request → Request-Headers *Length-Prefixed-Message EOS</div><div class=\"line\">Response → (Response-Headers *Length-Prefixed-Message Trailers) / Trailers-Only</div></pre></td></tr></table></figure>\n<p>例子：Request<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">HEADERS (flags = END_HEADERS)</div><div class=\"line\">:method = POST</div><div class=\"line\">:scheme = http</div><div class=\"line\">:path = /google.pubsub.v2.PublisherService/CreateTopic</div><div class=\"line\">:authority = pubsub.googleapis.com</div><div class=\"line\">grpc-timeout = 1S</div><div class=\"line\">content-type = application/grpc+proto</div><div class=\"line\">grpc-encoding = gzip</div><div class=\"line\">authorization = Bearer y235.wef315yfh138vh31hv93hv8h3v</div><div class=\"line\"></div><div class=\"line\">DATA (flags = END_STREAM)</div><div class=\"line\">&lt;Length-Prefixed Message&gt;</div></pre></td></tr></table></figure></p>\n<p>例子：Response<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">HEADERS (flags = END_HEADERS)</div><div class=\"line\">:status = 200</div><div class=\"line\">grpc-encoding = gzip</div><div class=\"line\">content-type = application/grpc+proto</div><div class=\"line\"></div><div class=\"line\">DATA</div><div class=\"line\">&lt;Length-Prefixed Message&gt;</div><div class=\"line\"></div><div class=\"line\">HEADERS (flags = END_STREAM, END_HEADERS)</div><div class=\"line\">grpc-status = 0 # OK</div><div class=\"line\">trace-proto-bin = jher831yy13JHy3hc</div></pre></td></tr></table></figure></p>\n<h2 id=\"Reliablity\"><a href=\"#Reliablity\" class=\"headerlink\" title=\"Reliablity\"></a>Reliablity</h2><p>   gRPC官方并未直接提供服务注册与发现的功能实现，但其设计文档已提供实现的思路，<br>并在不同语言的gRPC代码API中已提供了命名解析和负载均衡接口供扩展。   </p>\n<p>   服务提供方启动时，首先将服务地址注册到服务注册表，同时定期报心跳到服务注册表以表明服务的存活状态，<br>相当于健康检查.服务消费方要访问某个服务时，它通过内置的LB组件向服务注册表查询，同时缓存并定期刷新目标服务地址列表，<br>然后以某种负载均衡策略选择一个目标服务地址，最后向目标服务发起请求</p>\n<p>优点：不需要额外的负载均衡设备，没有单点故障<br>缺点：相关策略机制都在客户端，需支持多语言，开发成本高。升级客户端，需要服务调用方配合一起升级</p>\n<h2 id=\"易用性\"><a href=\"#易用性\" class=\"headerlink\" title=\"易用性\"></a>易用性</h2><pre><code>主要体现在API和文档等方面。文档在多语言支持方面比较全面，但是在内容深度方面远远不够。\nAPI在使用上没有问题，但是在client端封装不够，conn，client等暴露出来还需要自己创建和维护。\n</code></pre><p>需要有个Factory可以根据参数获取到client，在Factory内部维护conn和client的实例化。</p>\n<h2 id=\"经验与收获\"><a href=\"#经验与收获\" class=\"headerlink\" title=\"经验与收获\"></a>经验与收获</h2><ul>\n<li>go语言context在大型开源项目里的使用</li>\n<li>生态建设，与其它开源项目的合作。</li>\n</ul>\n<h2 id=\"server\"><a href=\"#server\" class=\"headerlink\" title=\"server\"></a>server</h2><ul>\n<li><p>关键方法<br>NewServer<br>Serve<br>handleRawConn<br>newHTTP2Transport</p>\n</li>\n<li><p>主要流程<br>grpcServer.Serve里面是个死循环，不断accept新conn，<br>然后创建一个goroutine处理conn<br>HandleStreams 里面是个死循环，从conn读数据并解析成Frame<br>遇到业务方法相关的Frame，会新创建个goroutine进行处理。</p>\n</li>\n</ul>\n<h2 id=\"Client\"><a href=\"#Client\" class=\"headerlink\" title=\"Client\"></a>Client</h2><p>DialContext 创建clientconn<br>invoke 创建clientstream</p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p><a href=\"https://ye11ow.gitbooks.io/http2-explained/content/\" target=\"_blank\" rel=\"noopener\">http2讲解</a><br><a href=\"https://www.jianshu.com/p/f44b930cfcac\" target=\"_blank\" rel=\"noopener\">HPACK 完全解析</a><br><a href=\"https://zhuanlan.zhihu.com/p/27961684\" target=\"_blank\" rel=\"noopener\">深入了解 gRPC：协议</a><br><a href=\"https://zhuanlan.zhihu.com/p/27995238\" target=\"_blank\" rel=\"noopener\">gRPC-rs：从 C 到 Rust</a><br><a href=\"http://mrpeak.cn/blog/tcp-rpc-protocol/\" target=\"_blank\" rel=\"noopener\">如何设计一个通讯协议</a><br><a href=\"http://www.infoq.com/cn/articles/get-to-know-rpc\" target=\"_blank\" rel=\"noopener\">体系化认识RPC</a><br><a href=\"http://www.infoq.com/cn/articles/tidb-and-grpc\" target=\"_blank\" rel=\"noopener\">TiDB与gRPC的那点事</a><br><a href=\"https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md\" target=\"_blank\" rel=\"noopener\">gRPC over HTTP2</a><br><a href=\"https://github.com/grpc/grpc/blob/master/doc/epoll-polling-engine.md\" target=\"_blank\" rel=\"noopener\">based pollset implementation in gRPC</a><br><a href=\"http://www.open-open.com/lib/view/open1489473315209.html\" target=\"_blank\" rel=\"noopener\">gRPC服务发现&amp;负载均衡</a><br><a href=\"https://imququ.com/post/protocol-negotiation-in-http2.html\" target=\"_blank\" rel=\"noopener\">谈谈 HTTP/2 的协议协商机制</a></p>\n"},{"title":"influxdb","date":"2018-05-22T03:39:28.000Z","_content":"大纲\n## 背景\n开发背景和版本变迁\n\n## 功能\n启动与配置\n数据写入\n数据读取\n元数据管理\n\n## 架构\n功能组件\n代码结构\n\n## 实现\n### 模型与元数据\n\n### 写流程\n\n\n### 读流程\n\n\n### 重要services\n\n## 集群\n\n\n## 运维\n","source":"_posts/2018-05-22-influxdb.md","raw":"---\ntitle: influxdb\ndate: 2018-05-22 11:39:28\ntags:\n---\n大纲\n## 背景\n开发背景和版本变迁\n\n## 功能\n启动与配置\n数据写入\n数据读取\n元数据管理\n\n## 架构\n功能组件\n代码结构\n\n## 实现\n### 模型与元数据\n\n### 写流程\n\n\n### 读流程\n\n\n### 重要services\n\n## 集群\n\n\n## 运维\n","slug":"influxdb","published":1,"updated":"2018-05-22T03:44:45.861Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zq000n3l65z04pvl4o","content":"<p>大纲</p>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>开发背景和版本变迁</p>\n<h2 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h2><p>启动与配置<br>数据写入<br>数据读取<br>元数据管理</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p>功能组件<br>代码结构</p>\n<h2 id=\"实现\"><a href=\"#实现\" class=\"headerlink\" title=\"实现\"></a>实现</h2><h3 id=\"模型与元数据\"><a href=\"#模型与元数据\" class=\"headerlink\" title=\"模型与元数据\"></a>模型与元数据</h3><h3 id=\"写流程\"><a href=\"#写流程\" class=\"headerlink\" title=\"写流程\"></a>写流程</h3><h3 id=\"读流程\"><a href=\"#读流程\" class=\"headerlink\" title=\"读流程\"></a>读流程</h3><h3 id=\"重要services\"><a href=\"#重要services\" class=\"headerlink\" title=\"重要services\"></a>重要services</h3><h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><h2 id=\"运维\"><a href=\"#运维\" class=\"headerlink\" title=\"运维\"></a>运维</h2>","site":{"data":{}},"excerpt":"","more":"<p>大纲</p>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>开发背景和版本变迁</p>\n<h2 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h2><p>启动与配置<br>数据写入<br>数据读取<br>元数据管理</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p>功能组件<br>代码结构</p>\n<h2 id=\"实现\"><a href=\"#实现\" class=\"headerlink\" title=\"实现\"></a>实现</h2><h3 id=\"模型与元数据\"><a href=\"#模型与元数据\" class=\"headerlink\" title=\"模型与元数据\"></a>模型与元数据</h3><h3 id=\"写流程\"><a href=\"#写流程\" class=\"headerlink\" title=\"写流程\"></a>写流程</h3><h3 id=\"读流程\"><a href=\"#读流程\" class=\"headerlink\" title=\"读流程\"></a>读流程</h3><h3 id=\"重要services\"><a href=\"#重要services\" class=\"headerlink\" title=\"重要services\"></a>重要services</h3><h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><h2 id=\"运维\"><a href=\"#运维\" class=\"headerlink\" title=\"运维\"></a>运维</h2>"},{"title":"influxdb-compress","date":"2018-05-28T08:22:29.000Z","_content":"\n## 前言\ninfluxdb里持续化数据的文件是tsm格式，上篇有说明，这篇重点说说这个文件里涉及的压缩算法。\n其中压缩的部分是data block部分。influxdb数据模型里的field_value支持float, int， uint, bool,\nstring等类型，针对每种类型都有对应的压缩方式。时间戳没有像beringei那样和value混合起来一起压缩，\n而且单独进行压缩存储。因此一共有6种场景的压缩方式。\n每个block都是包含三部分时间戳压缩后的字节数组长度，时间戳压缩后的字节数组，field_value压缩后的字节数组。\n\n## 时间戳的压缩\nberingei的时间戳压缩主要思路是计算出delta-of-delta的值D, 然后不同值预范围的值用对应的bit前缀+最少的bit的\nD。具体要点如下：\n1. Header存储起始时间戳T0\n2. 第1个时间戳用14bit存储delta值:T1-T0\n3. 从第2个到最后一个存储delta-of-delta值D: (Tn - Tn-1) - (Tn-1 - Tn-2)\n4. 如果D==0， 用1个bit 0 来存储表示\n5. 如果D∈[-63,64], 用'10' + 7bit的D来存储\n6. 如果D∈[-255,256], 用'110' + 9bit的D来存储\n7. 如果D∈[-2047,2048], 用'1110' + 12bit的D来存储\n8. 如果是其它值，用用'1111' + 32bit的D来存储\n\ninfluxdb里的时间戳压缩，思路是先对一组时间戳进行统计分析，然后根据统计结果进行相应的编码。\n统计结果包括4个部分，时间戳的delta值数组，delta的最大值，delta间的最大公约数，是否全相等。\n### RLE (run-length encode)\n如果delta全相等，则进行RLE压缩。具体压缩方式如下:\n  + 第1个字节前4bit，置为'0010',表示压缩类型\n  + 第1个字节后4bit，表示最大公约数以10为底的对数\n  + 接着8个字节，表示第一个时间戳\n  + 接着1-8个字节，表示第1个delta值与公约数的除结果\n  + 接着1-8字节，表示重复的delta个数\n如果有1000个时间戳，delta为1000000000且全相等（单位ns，此处delta为1s），最大公约数1000000000，则\n一共需要1+8+4+2=14个字节，112bit。  如果是beringei，一共需要64+14+999=1077bit。这种场景下，\ninfluxdb的RLE压缩方式更优。\n\n### Raw Pack\n如果delta的最大值大于1152921504606846975，则不进行压缩，直接打包原始值。具体方式如下：\n  + 第1个字节前4bit，置为'0000',表示当前压缩类型。\n  + 后面每个8个字节保存1个时间戳\n\n### Simple8b Pack\n其它情况，对delta数组再使用simple8b压缩后存储，具体方式如下:\n  + 第1个字节前4bit，置为'0001',表示当前压缩类型。\n  + 第1个字节后4bit，表示最大公约数以10为底的对数\n  + 接着8个字节，表示第一个时间戳\n  + 接着对delta数据使用simple8b压缩后的字节数组。如果最大公约数大于1，可以把delta数组里的\n  每个数除以最大公约数后再压缩，这样使用的bit位会更少一些。\n\nsimple8b的思路是，把多个整数打包存在64bit里。\n+ 支持16种打包类型，\n+ 64bit的前4bit表示打包类型\n+ 后面60bit用来存放对应类型可放入的整数。\n例如[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 25] 这个整数数组一共12数，最大的数是25，需要至少用\n5bit来表示。 60/5=12 刚好可以保持12个整数。 具体编码如下：\n```\n0110，高4bit， 对应第6个打包类型。\n11001，倒数第1个数，十进制25。使用逆序存放数据。\n01011，倒数第2个数\n01010，倒数第3个数\n01001，倒数第4个数\n01000，倒数第5个数\n00111，倒数第6个数\n00110，倒数第7个数\n00101，倒数第8个数\n00100，倒数第9个数\n00011，倒数第10个数\n00010，倒数第11个数\n00001，倒数第12个数\n\n最终的整数10进制为7830995874016792000，16进制为6cad4941cc520c00\n```\n从上面可以，simple8b对于值比较小且波动不大的整数压缩较好。如果波动比较大会浪费比较多的bit位。\n\n如果有1000个时间戳，其中998个delta为1000000000，中间两个连续点出现波动两个分别是\n1500000000,500000000.最大公约数是500000000，一共需要1+8+4*8+8+8=57字节, 457bit。\n使用beringei需要64+997+36*2=1133bit\n\n### 小结\n1. influxdb支持的时间戳精度到纳秒，实际中很少用到这么高的精度。如果最低精度到s，可以把时间戳对齐\n到秒，秒之后的值清零，以提高压缩率。\n2. 当时间戳的delta大部分相同的情况下，influxdb的压缩效果要优于beringei\n\n## Int的压缩\n由于metric的value部分，可以是正数，也可以是负数。而负数高位bit是1，不便于压缩。使用ZigZag编码\n可以把负数转成正数。对正数，将它乘以2；对负数，将它的数值乘2减1\n```\n64位整数的zigzag编码公式是： uint64(uint64(x<<1)^uint64((int64(x) >> 63)))\n\n```\n编码后的整数压缩与时间戳压缩类似，分别使用了RLE, RawPack, Simple8b Pack. 不再赘述\n\n无符号整数与整数压缩方式完全相同，只是存储的block类型不同。\n\n## Float压缩\n对于浮点数的压缩，beringei里使用了XOR编码， influxdb使用了一样的方式。具体要点如下：\n+ 第1个数不压缩，使用64bit\n+ 第二个数开始，与前一个数进行异或，然后统计结果数，非0位前面是0bit的个数（LZ)，非零bit后面0bit的个数(TZ)，\n中间非0bit的个数(MB)。\n+ 如果异或后的结果为0，则存储'0'，占用1个bit\n+ 如果异或后的结果不为0，按下面结果存储\n  - 如果LZ和TZ与前一个值的完全一样，存储 '10'+ 中间非0bit\n  - 如果LZ和TZ与前一个值不一样，存储'11',接着5个bit存储LZ，6个bit存储MB，最后存储中间非0bit。\n\n```\n假设有3个浮点数，二进制形式如下：\n01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)\n01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)\n01000000 00101100 01100110 01100110 01100110 01100110 01100110 01100110  (14.2)\n\n中间结果\n00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000\n00000000 00000100 01100110 01100110 01100110 01100110 01100110 01100110\n\n压缩结果\n01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000\n0\n11 01101 110010 100 01100110 01100110 01100110 01100110 01100110 0110011\n```\n对于有大量0bit的浮点数，这种方式可以有效减少存储位。\n\n## Boolean压缩\ninfluxdb支持boolean类型的value值，它的压缩思路就是用每个bit表示1个boolean值。\n+ 每8个bit，即1个字节作为一个单元。\n+ 每编码一个boolean值，先把当前字节往左移1位，后面补0\n+ 如果被编码的boolean为true，再把最后1bit置为1\n\n```\n原始值: true, false, false, false, true, true, true, false\n编码后结果: 10001110\n```\n\n## String 压缩\n对于string类型的value，编码过程如下：\n+ 对于每个值，先在编码器的buf里保存value的长度(UvarInt)\n+ 保存原始的字符串\n+ 遍历完成后，对所有buf里是数据，使用snappy的方式压缩\n\n### Snappy压缩\n  snappy在LZ77基础上发展而来的。lz77的压缩思路是，建立一个滑动窗口，分成两个部分，搜索缓冲区\n和待编码区。编码器遍历待编码区，从搜索缓冲区找到最大匹配字符串，然后输出(offset, length).\noffset是当前位置距离匹配字符串的偏移量，length是匹配字符串的长度。 zlib在LZ77基础上，\n再对LZ77的结果进行huffman编码，以此来提高压缩率。\n\n   snappy改进了查找匹配字符串的方式。它设计了一个map，key是4字节整数的hash值，value是待压缩字节数组\n对应整数的index。压缩编码没有了滑动窗口，但是还是要从之前的数据中找到匹配字符串。先计算当位置4个\n字节整数的hash值，使用这个hash值到map里可以找到相同的hash值的值位置。然后比较两个位置的原始值是否相等\n如果相等，说明找到开头匹配的字符串，然后继续匹配后续字符串，直到找到最大匹配。如果不相等，index往后\n移1位，继续计算4字节整数的hash。\n\n   从上面可以看出，snappy在查找匹配字符串上结合hash表快了不少。并且总是与最近相同字符串的匹配，\n有可能匹配的不是最大匹配。 snappy有自己的结果编码方式，没有huffman编码。因此snappy相比zlib，\n压缩更快,但是压缩率要稍低一点。\n\n## 小结\n   对于时序数据的压缩，针对每种数据类型无论是压缩率还是计算量肯定还有更有更好的方式。\n这需要对现有数据进行统计分析，找出隐藏的规律。压缩算法的选择上也不能只追求压缩率，\n数据在不同的位置应该有不同的压缩策略，在压缩率和性能上取一个合适的平衡。\n在内存的数据，更高吞吐的压缩算法可能更合适；在落盘的历史数据，更高的压缩率可能更合适。\n\n## references\n[ZIP压缩算法详细分析及解压实例解释](http://www.cnblogs.com/esingchan/p/3958962.html)\n","source":"_posts/2018-05-28-influxdb-compress.md","raw":"---\ntitle: influxdb-compress\ndate: 2018-05-28 16:22:29\ntags:\n---\n\n## 前言\ninfluxdb里持续化数据的文件是tsm格式，上篇有说明，这篇重点说说这个文件里涉及的压缩算法。\n其中压缩的部分是data block部分。influxdb数据模型里的field_value支持float, int， uint, bool,\nstring等类型，针对每种类型都有对应的压缩方式。时间戳没有像beringei那样和value混合起来一起压缩，\n而且单独进行压缩存储。因此一共有6种场景的压缩方式。\n每个block都是包含三部分时间戳压缩后的字节数组长度，时间戳压缩后的字节数组，field_value压缩后的字节数组。\n\n## 时间戳的压缩\nberingei的时间戳压缩主要思路是计算出delta-of-delta的值D, 然后不同值预范围的值用对应的bit前缀+最少的bit的\nD。具体要点如下：\n1. Header存储起始时间戳T0\n2. 第1个时间戳用14bit存储delta值:T1-T0\n3. 从第2个到最后一个存储delta-of-delta值D: (Tn - Tn-1) - (Tn-1 - Tn-2)\n4. 如果D==0， 用1个bit 0 来存储表示\n5. 如果D∈[-63,64], 用'10' + 7bit的D来存储\n6. 如果D∈[-255,256], 用'110' + 9bit的D来存储\n7. 如果D∈[-2047,2048], 用'1110' + 12bit的D来存储\n8. 如果是其它值，用用'1111' + 32bit的D来存储\n\ninfluxdb里的时间戳压缩，思路是先对一组时间戳进行统计分析，然后根据统计结果进行相应的编码。\n统计结果包括4个部分，时间戳的delta值数组，delta的最大值，delta间的最大公约数，是否全相等。\n### RLE (run-length encode)\n如果delta全相等，则进行RLE压缩。具体压缩方式如下:\n  + 第1个字节前4bit，置为'0010',表示压缩类型\n  + 第1个字节后4bit，表示最大公约数以10为底的对数\n  + 接着8个字节，表示第一个时间戳\n  + 接着1-8个字节，表示第1个delta值与公约数的除结果\n  + 接着1-8字节，表示重复的delta个数\n如果有1000个时间戳，delta为1000000000且全相等（单位ns，此处delta为1s），最大公约数1000000000，则\n一共需要1+8+4+2=14个字节，112bit。  如果是beringei，一共需要64+14+999=1077bit。这种场景下，\ninfluxdb的RLE压缩方式更优。\n\n### Raw Pack\n如果delta的最大值大于1152921504606846975，则不进行压缩，直接打包原始值。具体方式如下：\n  + 第1个字节前4bit，置为'0000',表示当前压缩类型。\n  + 后面每个8个字节保存1个时间戳\n\n### Simple8b Pack\n其它情况，对delta数组再使用simple8b压缩后存储，具体方式如下:\n  + 第1个字节前4bit，置为'0001',表示当前压缩类型。\n  + 第1个字节后4bit，表示最大公约数以10为底的对数\n  + 接着8个字节，表示第一个时间戳\n  + 接着对delta数据使用simple8b压缩后的字节数组。如果最大公约数大于1，可以把delta数组里的\n  每个数除以最大公约数后再压缩，这样使用的bit位会更少一些。\n\nsimple8b的思路是，把多个整数打包存在64bit里。\n+ 支持16种打包类型，\n+ 64bit的前4bit表示打包类型\n+ 后面60bit用来存放对应类型可放入的整数。\n例如[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 25] 这个整数数组一共12数，最大的数是25，需要至少用\n5bit来表示。 60/5=12 刚好可以保持12个整数。 具体编码如下：\n```\n0110，高4bit， 对应第6个打包类型。\n11001，倒数第1个数，十进制25。使用逆序存放数据。\n01011，倒数第2个数\n01010，倒数第3个数\n01001，倒数第4个数\n01000，倒数第5个数\n00111，倒数第6个数\n00110，倒数第7个数\n00101，倒数第8个数\n00100，倒数第9个数\n00011，倒数第10个数\n00010，倒数第11个数\n00001，倒数第12个数\n\n最终的整数10进制为7830995874016792000，16进制为6cad4941cc520c00\n```\n从上面可以，simple8b对于值比较小且波动不大的整数压缩较好。如果波动比较大会浪费比较多的bit位。\n\n如果有1000个时间戳，其中998个delta为1000000000，中间两个连续点出现波动两个分别是\n1500000000,500000000.最大公约数是500000000，一共需要1+8+4*8+8+8=57字节, 457bit。\n使用beringei需要64+997+36*2=1133bit\n\n### 小结\n1. influxdb支持的时间戳精度到纳秒，实际中很少用到这么高的精度。如果最低精度到s，可以把时间戳对齐\n到秒，秒之后的值清零，以提高压缩率。\n2. 当时间戳的delta大部分相同的情况下，influxdb的压缩效果要优于beringei\n\n## Int的压缩\n由于metric的value部分，可以是正数，也可以是负数。而负数高位bit是1，不便于压缩。使用ZigZag编码\n可以把负数转成正数。对正数，将它乘以2；对负数，将它的数值乘2减1\n```\n64位整数的zigzag编码公式是： uint64(uint64(x<<1)^uint64((int64(x) >> 63)))\n\n```\n编码后的整数压缩与时间戳压缩类似，分别使用了RLE, RawPack, Simple8b Pack. 不再赘述\n\n无符号整数与整数压缩方式完全相同，只是存储的block类型不同。\n\n## Float压缩\n对于浮点数的压缩，beringei里使用了XOR编码， influxdb使用了一样的方式。具体要点如下：\n+ 第1个数不压缩，使用64bit\n+ 第二个数开始，与前一个数进行异或，然后统计结果数，非0位前面是0bit的个数（LZ)，非零bit后面0bit的个数(TZ)，\n中间非0bit的个数(MB)。\n+ 如果异或后的结果为0，则存储'0'，占用1个bit\n+ 如果异或后的结果不为0，按下面结果存储\n  - 如果LZ和TZ与前一个值的完全一样，存储 '10'+ 中间非0bit\n  - 如果LZ和TZ与前一个值不一样，存储'11',接着5个bit存储LZ，6个bit存储MB，最后存储中间非0bit。\n\n```\n假设有3个浮点数，二进制形式如下：\n01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)\n01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)\n01000000 00101100 01100110 01100110 01100110 01100110 01100110 01100110  (14.2)\n\n中间结果\n00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000\n00000000 00000100 01100110 01100110 01100110 01100110 01100110 01100110\n\n压缩结果\n01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000\n0\n11 01101 110010 100 01100110 01100110 01100110 01100110 01100110 0110011\n```\n对于有大量0bit的浮点数，这种方式可以有效减少存储位。\n\n## Boolean压缩\ninfluxdb支持boolean类型的value值，它的压缩思路就是用每个bit表示1个boolean值。\n+ 每8个bit，即1个字节作为一个单元。\n+ 每编码一个boolean值，先把当前字节往左移1位，后面补0\n+ 如果被编码的boolean为true，再把最后1bit置为1\n\n```\n原始值: true, false, false, false, true, true, true, false\n编码后结果: 10001110\n```\n\n## String 压缩\n对于string类型的value，编码过程如下：\n+ 对于每个值，先在编码器的buf里保存value的长度(UvarInt)\n+ 保存原始的字符串\n+ 遍历完成后，对所有buf里是数据，使用snappy的方式压缩\n\n### Snappy压缩\n  snappy在LZ77基础上发展而来的。lz77的压缩思路是，建立一个滑动窗口，分成两个部分，搜索缓冲区\n和待编码区。编码器遍历待编码区，从搜索缓冲区找到最大匹配字符串，然后输出(offset, length).\noffset是当前位置距离匹配字符串的偏移量，length是匹配字符串的长度。 zlib在LZ77基础上，\n再对LZ77的结果进行huffman编码，以此来提高压缩率。\n\n   snappy改进了查找匹配字符串的方式。它设计了一个map，key是4字节整数的hash值，value是待压缩字节数组\n对应整数的index。压缩编码没有了滑动窗口，但是还是要从之前的数据中找到匹配字符串。先计算当位置4个\n字节整数的hash值，使用这个hash值到map里可以找到相同的hash值的值位置。然后比较两个位置的原始值是否相等\n如果相等，说明找到开头匹配的字符串，然后继续匹配后续字符串，直到找到最大匹配。如果不相等，index往后\n移1位，继续计算4字节整数的hash。\n\n   从上面可以看出，snappy在查找匹配字符串上结合hash表快了不少。并且总是与最近相同字符串的匹配，\n有可能匹配的不是最大匹配。 snappy有自己的结果编码方式，没有huffman编码。因此snappy相比zlib，\n压缩更快,但是压缩率要稍低一点。\n\n## 小结\n   对于时序数据的压缩，针对每种数据类型无论是压缩率还是计算量肯定还有更有更好的方式。\n这需要对现有数据进行统计分析，找出隐藏的规律。压缩算法的选择上也不能只追求压缩率，\n数据在不同的位置应该有不同的压缩策略，在压缩率和性能上取一个合适的平衡。\n在内存的数据，更高吞吐的压缩算法可能更合适；在落盘的历史数据，更高的压缩率可能更合适。\n\n## references\n[ZIP压缩算法详细分析及解压实例解释](http://www.cnblogs.com/esingchan/p/3958962.html)\n","slug":"influxdb-compress","published":1,"updated":"2018-07-09T10:22:07.260Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zr000o3l65jbw3vgvs","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>influxdb里持续化数据的文件是tsm格式，上篇有说明，这篇重点说说这个文件里涉及的压缩算法。<br>其中压缩的部分是data block部分。influxdb数据模型里的field_value支持float, int， uint, bool,<br>string等类型，针对每种类型都有对应的压缩方式。时间戳没有像beringei那样和value混合起来一起压缩，<br>而且单独进行压缩存储。因此一共有6种场景的压缩方式。<br>每个block都是包含三部分时间戳压缩后的字节数组长度，时间戳压缩后的字节数组，field_value压缩后的字节数组。</p>\n<h2 id=\"时间戳的压缩\"><a href=\"#时间戳的压缩\" class=\"headerlink\" title=\"时间戳的压缩\"></a>时间戳的压缩</h2><p>beringei的时间戳压缩主要思路是计算出delta-of-delta的值D, 然后不同值预范围的值用对应的bit前缀+最少的bit的<br>D。具体要点如下：</p>\n<ol>\n<li>Header存储起始时间戳T0</li>\n<li>第1个时间戳用14bit存储delta值:T1-T0</li>\n<li>从第2个到最后一个存储delta-of-delta值D: (Tn - Tn-1) - (Tn-1 - Tn-2)</li>\n<li>如果D==0， 用1个bit 0 来存储表示</li>\n<li>如果D∈[-63,64], 用’10’ + 7bit的D来存储</li>\n<li>如果D∈[-255,256], 用’110’ + 9bit的D来存储</li>\n<li>如果D∈[-2047,2048], 用’1110’ + 12bit的D来存储</li>\n<li>如果是其它值，用用’1111’ + 32bit的D来存储</li>\n</ol>\n<p>influxdb里的时间戳压缩，思路是先对一组时间戳进行统计分析，然后根据统计结果进行相应的编码。<br>统计结果包括4个部分，时间戳的delta值数组，delta的最大值，delta间的最大公约数，是否全相等。</p>\n<h3 id=\"RLE-run-length-encode\"><a href=\"#RLE-run-length-encode\" class=\"headerlink\" title=\"RLE (run-length encode)\"></a>RLE (run-length encode)</h3><p>如果delta全相等，则进行RLE压缩。具体压缩方式如下:</p>\n<ul>\n<li>第1个字节前4bit，置为’0010’,表示压缩类型</li>\n<li>第1个字节后4bit，表示最大公约数以10为底的对数</li>\n<li>接着8个字节，表示第一个时间戳</li>\n<li>接着1-8个字节，表示第1个delta值与公约数的除结果</li>\n<li>接着1-8字节，表示重复的delta个数<br>如果有1000个时间戳，delta为1000000000且全相等（单位ns，此处delta为1s），最大公约数1000000000，则<br>一共需要1+8+4+2=14个字节，112bit。  如果是beringei，一共需要64+14+999=1077bit。这种场景下，<br>influxdb的RLE压缩方式更优。</li>\n</ul>\n<h3 id=\"Raw-Pack\"><a href=\"#Raw-Pack\" class=\"headerlink\" title=\"Raw Pack\"></a>Raw Pack</h3><p>如果delta的最大值大于1152921504606846975，则不进行压缩，直接打包原始值。具体方式如下：</p>\n<ul>\n<li>第1个字节前4bit，置为’0000’,表示当前压缩类型。</li>\n<li>后面每个8个字节保存1个时间戳</li>\n</ul>\n<h3 id=\"Simple8b-Pack\"><a href=\"#Simple8b-Pack\" class=\"headerlink\" title=\"Simple8b Pack\"></a>Simple8b Pack</h3><p>其它情况，对delta数组再使用simple8b压缩后存储，具体方式如下:</p>\n<ul>\n<li>第1个字节前4bit，置为’0001’,表示当前压缩类型。</li>\n<li>第1个字节后4bit，表示最大公约数以10为底的对数</li>\n<li>接着8个字节，表示第一个时间戳</li>\n<li>接着对delta数据使用simple8b压缩后的字节数组。如果最大公约数大于1，可以把delta数组里的<br>每个数除以最大公约数后再压缩，这样使用的bit位会更少一些。</li>\n</ul>\n<p>simple8b的思路是，把多个整数打包存在64bit里。</p>\n<ul>\n<li>支持16种打包类型，</li>\n<li>64bit的前4bit表示打包类型</li>\n<li>后面60bit用来存放对应类型可放入的整数。<br>例如[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 25] 这个整数数组一共12数，最大的数是25，需要至少用<br>5bit来表示。 60/5=12 刚好可以保持12个整数。 具体编码如下：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">0110，高4bit， 对应第6个打包类型。</div><div class=\"line\">11001，倒数第1个数，十进制25。使用逆序存放数据。</div><div class=\"line\">01011，倒数第2个数</div><div class=\"line\">01010，倒数第3个数</div><div class=\"line\">01001，倒数第4个数</div><div class=\"line\">01000，倒数第5个数</div><div class=\"line\">00111，倒数第6个数</div><div class=\"line\">00110，倒数第7个数</div><div class=\"line\">00101，倒数第8个数</div><div class=\"line\">00100，倒数第9个数</div><div class=\"line\">00011，倒数第10个数</div><div class=\"line\">00010，倒数第11个数</div><div class=\"line\">00001，倒数第12个数</div><div class=\"line\"></div><div class=\"line\">最终的整数10进制为7830995874016792000，16进制为6cad4941cc520c00</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>从上面可以，simple8b对于值比较小且波动不大的整数压缩较好。如果波动比较大会浪费比较多的bit位。</p>\n<p>如果有1000个时间戳，其中998个delta为1000000000，中间两个连续点出现波动两个分别是<br>1500000000,500000000.最大公约数是500000000，一共需要1+8+4<em>8+8+8=57字节, 457bit。<br>使用beringei需要64+997+36</em>2=1133bit</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><ol>\n<li>influxdb支持的时间戳精度到纳秒，实际中很少用到这么高的精度。如果最低精度到s，可以把时间戳对齐<br>到秒，秒之后的值清零，以提高压缩率。</li>\n<li>当时间戳的delta大部分相同的情况下，influxdb的压缩效果要优于beringei</li>\n</ol>\n<h2 id=\"Int的压缩\"><a href=\"#Int的压缩\" class=\"headerlink\" title=\"Int的压缩\"></a>Int的压缩</h2><p>由于metric的value部分，可以是正数，也可以是负数。而负数高位bit是1，不便于压缩。使用ZigZag编码<br>可以把负数转成正数。对正数，将它乘以2；对负数，将它的数值乘2减1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">64位整数的zigzag编码公式是： uint64(uint64(x&lt;&lt;1)^uint64((int64(x) &gt;&gt; 63)))</div></pre></td></tr></table></figure></p>\n<p>编码后的整数压缩与时间戳压缩类似，分别使用了RLE, RawPack, Simple8b Pack. 不再赘述</p>\n<p>无符号整数与整数压缩方式完全相同，只是存储的block类型不同。</p>\n<h2 id=\"Float压缩\"><a href=\"#Float压缩\" class=\"headerlink\" title=\"Float压缩\"></a>Float压缩</h2><p>对于浮点数的压缩，beringei里使用了XOR编码， influxdb使用了一样的方式。具体要点如下：</p>\n<ul>\n<li>第1个数不压缩，使用64bit</li>\n<li>第二个数开始，与前一个数进行异或，然后统计结果数，非0位前面是0bit的个数（LZ)，非零bit后面0bit的个数(TZ)，<br>中间非0bit的个数(MB)。</li>\n<li>如果异或后的结果为0，则存储’0’，占用1个bit</li>\n<li>如果异或后的结果不为0，按下面结果存储<ul>\n<li>如果LZ和TZ与前一个值的完全一样，存储 ‘10’+ 中间非0bit</li>\n<li>如果LZ和TZ与前一个值不一样，存储’11’,接着5个bit存储LZ，6个bit存储MB，最后存储中间非0bit。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">假设有3个浮点数，二进制形式如下：</div><div class=\"line\">01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)</div><div class=\"line\">01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)</div><div class=\"line\">01000000 00101100 01100110 01100110 01100110 01100110 01100110 01100110  (14.2)</div><div class=\"line\"></div><div class=\"line\">中间结果</div><div class=\"line\">00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</div><div class=\"line\">00000000 00000100 01100110 01100110 01100110 01100110 01100110 01100110</div><div class=\"line\"></div><div class=\"line\">压缩结果</div><div class=\"line\">01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000</div><div class=\"line\">0</div><div class=\"line\">11 01101 110010 100 01100110 01100110 01100110 01100110 01100110 0110011</div></pre></td></tr></table></figure>\n<p>对于有大量0bit的浮点数，这种方式可以有效减少存储位。</p>\n<h2 id=\"Boolean压缩\"><a href=\"#Boolean压缩\" class=\"headerlink\" title=\"Boolean压缩\"></a>Boolean压缩</h2><p>influxdb支持boolean类型的value值，它的压缩思路就是用每个bit表示1个boolean值。</p>\n<ul>\n<li>每8个bit，即1个字节作为一个单元。</li>\n<li>每编码一个boolean值，先把当前字节往左移1位，后面补0</li>\n<li>如果被编码的boolean为true，再把最后1bit置为1</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">原始值: true, false, false, false, true, true, true, false</div><div class=\"line\">编码后结果: 10001110</div></pre></td></tr></table></figure>\n<h2 id=\"String-压缩\"><a href=\"#String-压缩\" class=\"headerlink\" title=\"String 压缩\"></a>String 压缩</h2><p>对于string类型的value，编码过程如下：</p>\n<ul>\n<li>对于每个值，先在编码器的buf里保存value的长度(UvarInt)</li>\n<li>保存原始的字符串</li>\n<li>遍历完成后，对所有buf里是数据，使用snappy的方式压缩</li>\n</ul>\n<h3 id=\"Snappy压缩\"><a href=\"#Snappy压缩\" class=\"headerlink\" title=\"Snappy压缩\"></a>Snappy压缩</h3><p>  snappy在LZ77基础上发展而来的。lz77的压缩思路是，建立一个滑动窗口，分成两个部分，搜索缓冲区<br>和待编码区。编码器遍历待编码区，从搜索缓冲区找到最大匹配字符串，然后输出(offset, length).<br>offset是当前位置距离匹配字符串的偏移量，length是匹配字符串的长度。 zlib在LZ77基础上，<br>再对LZ77的结果进行huffman编码，以此来提高压缩率。</p>\n<p>   snappy改进了查找匹配字符串的方式。它设计了一个map，key是4字节整数的hash值，value是待压缩字节数组<br>对应整数的index。压缩编码没有了滑动窗口，但是还是要从之前的数据中找到匹配字符串。先计算当位置4个<br>字节整数的hash值，使用这个hash值到map里可以找到相同的hash值的值位置。然后比较两个位置的原始值是否相等<br>如果相等，说明找到开头匹配的字符串，然后继续匹配后续字符串，直到找到最大匹配。如果不相等，index往后<br>移1位，继续计算4字节整数的hash。</p>\n<p>   从上面可以看出，snappy在查找匹配字符串上结合hash表快了不少。并且总是与最近相同字符串的匹配，<br>有可能匹配的不是最大匹配。 snappy有自己的结果编码方式，没有huffman编码。因此snappy相比zlib，<br>压缩更快,但是压缩率要稍低一点。</p>\n<h2 id=\"小结-1\"><a href=\"#小结-1\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>   对于时序数据的压缩，针对每种数据类型无论是压缩率还是计算量肯定还有更有更好的方式。<br>这需要对现有数据进行统计分析，找出隐藏的规律。压缩算法的选择上也不能只追求压缩率，<br>数据在不同的位置应该有不同的压缩策略，在压缩率和性能上取一个合适的平衡。<br>在内存的数据，更高吞吐的压缩算法可能更合适；在落盘的历史数据，更高的压缩率可能更合适。</p>\n<h2 id=\"references\"><a href=\"#references\" class=\"headerlink\" title=\"references\"></a>references</h2><p><a href=\"http://www.cnblogs.com/esingchan/p/3958962.html\" target=\"_blank\" rel=\"noopener\">ZIP压缩算法详细分析及解压实例解释</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>influxdb里持续化数据的文件是tsm格式，上篇有说明，这篇重点说说这个文件里涉及的压缩算法。<br>其中压缩的部分是data block部分。influxdb数据模型里的field_value支持float, int， uint, bool,<br>string等类型，针对每种类型都有对应的压缩方式。时间戳没有像beringei那样和value混合起来一起压缩，<br>而且单独进行压缩存储。因此一共有6种场景的压缩方式。<br>每个block都是包含三部分时间戳压缩后的字节数组长度，时间戳压缩后的字节数组，field_value压缩后的字节数组。</p>\n<h2 id=\"时间戳的压缩\"><a href=\"#时间戳的压缩\" class=\"headerlink\" title=\"时间戳的压缩\"></a>时间戳的压缩</h2><p>beringei的时间戳压缩主要思路是计算出delta-of-delta的值D, 然后不同值预范围的值用对应的bit前缀+最少的bit的<br>D。具体要点如下：</p>\n<ol>\n<li>Header存储起始时间戳T0</li>\n<li>第1个时间戳用14bit存储delta值:T1-T0</li>\n<li>从第2个到最后一个存储delta-of-delta值D: (Tn - Tn-1) - (Tn-1 - Tn-2)</li>\n<li>如果D==0， 用1个bit 0 来存储表示</li>\n<li>如果D∈[-63,64], 用’10’ + 7bit的D来存储</li>\n<li>如果D∈[-255,256], 用’110’ + 9bit的D来存储</li>\n<li>如果D∈[-2047,2048], 用’1110’ + 12bit的D来存储</li>\n<li>如果是其它值，用用’1111’ + 32bit的D来存储</li>\n</ol>\n<p>influxdb里的时间戳压缩，思路是先对一组时间戳进行统计分析，然后根据统计结果进行相应的编码。<br>统计结果包括4个部分，时间戳的delta值数组，delta的最大值，delta间的最大公约数，是否全相等。</p>\n<h3 id=\"RLE-run-length-encode\"><a href=\"#RLE-run-length-encode\" class=\"headerlink\" title=\"RLE (run-length encode)\"></a>RLE (run-length encode)</h3><p>如果delta全相等，则进行RLE压缩。具体压缩方式如下:</p>\n<ul>\n<li>第1个字节前4bit，置为’0010’,表示压缩类型</li>\n<li>第1个字节后4bit，表示最大公约数以10为底的对数</li>\n<li>接着8个字节，表示第一个时间戳</li>\n<li>接着1-8个字节，表示第1个delta值与公约数的除结果</li>\n<li>接着1-8字节，表示重复的delta个数<br>如果有1000个时间戳，delta为1000000000且全相等（单位ns，此处delta为1s），最大公约数1000000000，则<br>一共需要1+8+4+2=14个字节，112bit。  如果是beringei，一共需要64+14+999=1077bit。这种场景下，<br>influxdb的RLE压缩方式更优。</li>\n</ul>\n<h3 id=\"Raw-Pack\"><a href=\"#Raw-Pack\" class=\"headerlink\" title=\"Raw Pack\"></a>Raw Pack</h3><p>如果delta的最大值大于1152921504606846975，则不进行压缩，直接打包原始值。具体方式如下：</p>\n<ul>\n<li>第1个字节前4bit，置为’0000’,表示当前压缩类型。</li>\n<li>后面每个8个字节保存1个时间戳</li>\n</ul>\n<h3 id=\"Simple8b-Pack\"><a href=\"#Simple8b-Pack\" class=\"headerlink\" title=\"Simple8b Pack\"></a>Simple8b Pack</h3><p>其它情况，对delta数组再使用simple8b压缩后存储，具体方式如下:</p>\n<ul>\n<li>第1个字节前4bit，置为’0001’,表示当前压缩类型。</li>\n<li>第1个字节后4bit，表示最大公约数以10为底的对数</li>\n<li>接着8个字节，表示第一个时间戳</li>\n<li>接着对delta数据使用simple8b压缩后的字节数组。如果最大公约数大于1，可以把delta数组里的<br>每个数除以最大公约数后再压缩，这样使用的bit位会更少一些。</li>\n</ul>\n<p>simple8b的思路是，把多个整数打包存在64bit里。</p>\n<ul>\n<li>支持16种打包类型，</li>\n<li>64bit的前4bit表示打包类型</li>\n<li>后面60bit用来存放对应类型可放入的整数。<br>例如[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 25] 这个整数数组一共12数，最大的数是25，需要至少用<br>5bit来表示。 60/5=12 刚好可以保持12个整数。 具体编码如下：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">0110，高4bit， 对应第6个打包类型。</div><div class=\"line\">11001，倒数第1个数，十进制25。使用逆序存放数据。</div><div class=\"line\">01011，倒数第2个数</div><div class=\"line\">01010，倒数第3个数</div><div class=\"line\">01001，倒数第4个数</div><div class=\"line\">01000，倒数第5个数</div><div class=\"line\">00111，倒数第6个数</div><div class=\"line\">00110，倒数第7个数</div><div class=\"line\">00101，倒数第8个数</div><div class=\"line\">00100，倒数第9个数</div><div class=\"line\">00011，倒数第10个数</div><div class=\"line\">00010，倒数第11个数</div><div class=\"line\">00001，倒数第12个数</div><div class=\"line\"></div><div class=\"line\">最终的整数10进制为7830995874016792000，16进制为6cad4941cc520c00</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>从上面可以，simple8b对于值比较小且波动不大的整数压缩较好。如果波动比较大会浪费比较多的bit位。</p>\n<p>如果有1000个时间戳，其中998个delta为1000000000，中间两个连续点出现波动两个分别是<br>1500000000,500000000.最大公约数是500000000，一共需要1+8+4<em>8+8+8=57字节, 457bit。<br>使用beringei需要64+997+36</em>2=1133bit</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><ol>\n<li>influxdb支持的时间戳精度到纳秒，实际中很少用到这么高的精度。如果最低精度到s，可以把时间戳对齐<br>到秒，秒之后的值清零，以提高压缩率。</li>\n<li>当时间戳的delta大部分相同的情况下，influxdb的压缩效果要优于beringei</li>\n</ol>\n<h2 id=\"Int的压缩\"><a href=\"#Int的压缩\" class=\"headerlink\" title=\"Int的压缩\"></a>Int的压缩</h2><p>由于metric的value部分，可以是正数，也可以是负数。而负数高位bit是1，不便于压缩。使用ZigZag编码<br>可以把负数转成正数。对正数，将它乘以2；对负数，将它的数值乘2减1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">64位整数的zigzag编码公式是： uint64(uint64(x&lt;&lt;1)^uint64((int64(x) &gt;&gt; 63)))</div></pre></td></tr></table></figure></p>\n<p>编码后的整数压缩与时间戳压缩类似，分别使用了RLE, RawPack, Simple8b Pack. 不再赘述</p>\n<p>无符号整数与整数压缩方式完全相同，只是存储的block类型不同。</p>\n<h2 id=\"Float压缩\"><a href=\"#Float压缩\" class=\"headerlink\" title=\"Float压缩\"></a>Float压缩</h2><p>对于浮点数的压缩，beringei里使用了XOR编码， influxdb使用了一样的方式。具体要点如下：</p>\n<ul>\n<li>第1个数不压缩，使用64bit</li>\n<li>第二个数开始，与前一个数进行异或，然后统计结果数，非0位前面是0bit的个数（LZ)，非零bit后面0bit的个数(TZ)，<br>中间非0bit的个数(MB)。</li>\n<li>如果异或后的结果为0，则存储’0’，占用1个bit</li>\n<li>如果异或后的结果不为0，按下面结果存储<ul>\n<li>如果LZ和TZ与前一个值的完全一样，存储 ‘10’+ 中间非0bit</li>\n<li>如果LZ和TZ与前一个值不一样，存储’11’,接着5个bit存储LZ，6个bit存储MB，最后存储中间非0bit。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">假设有3个浮点数，二进制形式如下：</div><div class=\"line\">01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)</div><div class=\"line\">01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000  (12.0)</div><div class=\"line\">01000000 00101100 01100110 01100110 01100110 01100110 01100110 01100110  (14.2)</div><div class=\"line\"></div><div class=\"line\">中间结果</div><div class=\"line\">00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</div><div class=\"line\">00000000 00000100 01100110 01100110 01100110 01100110 01100110 01100110</div><div class=\"line\"></div><div class=\"line\">压缩结果</div><div class=\"line\">01000000 00101000 00000000 00000000 00000000 00000000 00000000 00000000</div><div class=\"line\">0</div><div class=\"line\">11 01101 110010 100 01100110 01100110 01100110 01100110 01100110 0110011</div></pre></td></tr></table></figure>\n<p>对于有大量0bit的浮点数，这种方式可以有效减少存储位。</p>\n<h2 id=\"Boolean压缩\"><a href=\"#Boolean压缩\" class=\"headerlink\" title=\"Boolean压缩\"></a>Boolean压缩</h2><p>influxdb支持boolean类型的value值，它的压缩思路就是用每个bit表示1个boolean值。</p>\n<ul>\n<li>每8个bit，即1个字节作为一个单元。</li>\n<li>每编码一个boolean值，先把当前字节往左移1位，后面补0</li>\n<li>如果被编码的boolean为true，再把最后1bit置为1</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">原始值: true, false, false, false, true, true, true, false</div><div class=\"line\">编码后结果: 10001110</div></pre></td></tr></table></figure>\n<h2 id=\"String-压缩\"><a href=\"#String-压缩\" class=\"headerlink\" title=\"String 压缩\"></a>String 压缩</h2><p>对于string类型的value，编码过程如下：</p>\n<ul>\n<li>对于每个值，先在编码器的buf里保存value的长度(UvarInt)</li>\n<li>保存原始的字符串</li>\n<li>遍历完成后，对所有buf里是数据，使用snappy的方式压缩</li>\n</ul>\n<h3 id=\"Snappy压缩\"><a href=\"#Snappy压缩\" class=\"headerlink\" title=\"Snappy压缩\"></a>Snappy压缩</h3><p>  snappy在LZ77基础上发展而来的。lz77的压缩思路是，建立一个滑动窗口，分成两个部分，搜索缓冲区<br>和待编码区。编码器遍历待编码区，从搜索缓冲区找到最大匹配字符串，然后输出(offset, length).<br>offset是当前位置距离匹配字符串的偏移量，length是匹配字符串的长度。 zlib在LZ77基础上，<br>再对LZ77的结果进行huffman编码，以此来提高压缩率。</p>\n<p>   snappy改进了查找匹配字符串的方式。它设计了一个map，key是4字节整数的hash值，value是待压缩字节数组<br>对应整数的index。压缩编码没有了滑动窗口，但是还是要从之前的数据中找到匹配字符串。先计算当位置4个<br>字节整数的hash值，使用这个hash值到map里可以找到相同的hash值的值位置。然后比较两个位置的原始值是否相等<br>如果相等，说明找到开头匹配的字符串，然后继续匹配后续字符串，直到找到最大匹配。如果不相等，index往后<br>移1位，继续计算4字节整数的hash。</p>\n<p>   从上面可以看出，snappy在查找匹配字符串上结合hash表快了不少。并且总是与最近相同字符串的匹配，<br>有可能匹配的不是最大匹配。 snappy有自己的结果编码方式，没有huffman编码。因此snappy相比zlib，<br>压缩更快,但是压缩率要稍低一点。</p>\n<h2 id=\"小结-1\"><a href=\"#小结-1\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>   对于时序数据的压缩，针对每种数据类型无论是压缩率还是计算量肯定还有更有更好的方式。<br>这需要对现有数据进行统计分析，找出隐藏的规律。压缩算法的选择上也不能只追求压缩率，<br>数据在不同的位置应该有不同的压缩策略，在压缩率和性能上取一个合适的平衡。<br>在内存的数据，更高吞吐的压缩算法可能更合适；在落盘的历史数据，更高的压缩率可能更合适。</p>\n<h2 id=\"references\"><a href=\"#references\" class=\"headerlink\" title=\"references\"></a>references</h2><p><a href=\"http://www.cnblogs.com/esingchan/p/3958962.html\" target=\"_blank\" rel=\"noopener\">ZIP压缩算法详细分析及解压实例解释</a></p>\n"},{"title":"think","date":"2018-06-06T03:44:39.000Z","_content":"## lib或组件的引入\n+ 接口使用\n+ 原理，性能概况\n+ 执行流程\n+ 局限性\n+ 改进与提升\n\n## 错的经验\n+ 目标制定方向错误。\n人少打人多，胜率低。总希望能通过技术能力carry，实在希望渺茫。\n+ KPI模糊\nKPI未公开，并与多方沟通一致\n+ 执行计划弱\n按月制定计划，不够细。也没有定期总结调整。\n\n## 对的经验\n+ 对标\n对标同行，了解业内进展和自身情况，有助于建立信心。\n+ 抓细节\n细节是魔鬼。通过具体案例，了解细节，才能加深对新事物的理解，方可使用的得心应手。\n+ 挖掘历史\n通过收集历史信息，版本更替，来加深对事物的理解，方可做出预测。\n\n## 深入理解计算机\n+ 任何计算问题，都可以通过增加一层\"中间层\"来解决。\n+ 增加功能或扩展性时，一般是增加一层; 当进行性能优化重构时，一般时减少一层。\n+ 开发的系统时，运维工具同时开始，减少重复的人工操作。\n","source":"_posts/2018-06-06-think.md","raw":"---\ntitle: think\ndate: 2018-06-06 11:44:39\ntags:\n---\n## lib或组件的引入\n+ 接口使用\n+ 原理，性能概况\n+ 执行流程\n+ 局限性\n+ 改进与提升\n\n## 错的经验\n+ 目标制定方向错误。\n人少打人多，胜率低。总希望能通过技术能力carry，实在希望渺茫。\n+ KPI模糊\nKPI未公开，并与多方沟通一致\n+ 执行计划弱\n按月制定计划，不够细。也没有定期总结调整。\n\n## 对的经验\n+ 对标\n对标同行，了解业内进展和自身情况，有助于建立信心。\n+ 抓细节\n细节是魔鬼。通过具体案例，了解细节，才能加深对新事物的理解，方可使用的得心应手。\n+ 挖掘历史\n通过收集历史信息，版本更替，来加深对事物的理解，方可做出预测。\n\n## 深入理解计算机\n+ 任何计算问题，都可以通过增加一层\"中间层\"来解决。\n+ 增加功能或扩展性时，一般是增加一层; 当进行性能优化重构时，一般时减少一层。\n+ 开发的系统时，运维工具同时开始，减少重复的人工操作。\n","slug":"think","published":1,"updated":"2018-06-13T10:44:58.135Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zs000p3l65forij8yq","content":"<h2 id=\"lib或组件的引入\"><a href=\"#lib或组件的引入\" class=\"headerlink\" title=\"lib或组件的引入\"></a>lib或组件的引入</h2><ul>\n<li>接口使用</li>\n<li>原理，性能概况</li>\n<li>执行流程</li>\n<li>局限性</li>\n<li>改进与提升</li>\n</ul>\n<h2 id=\"错的经验\"><a href=\"#错的经验\" class=\"headerlink\" title=\"错的经验\"></a>错的经验</h2><ul>\n<li>目标制定方向错误。<br>人少打人多，胜率低。总希望能通过技术能力carry，实在希望渺茫。</li>\n<li>KPI模糊<br>KPI未公开，并与多方沟通一致</li>\n<li>执行计划弱<br>按月制定计划，不够细。也没有定期总结调整。</li>\n</ul>\n<h2 id=\"对的经验\"><a href=\"#对的经验\" class=\"headerlink\" title=\"对的经验\"></a>对的经验</h2><ul>\n<li>对标<br>对标同行，了解业内进展和自身情况，有助于建立信心。</li>\n<li>抓细节<br>细节是魔鬼。通过具体案例，了解细节，才能加深对新事物的理解，方可使用的得心应手。</li>\n<li>挖掘历史<br>通过收集历史信息，版本更替，来加深对事物的理解，方可做出预测。</li>\n</ul>\n<h2 id=\"深入理解计算机\"><a href=\"#深入理解计算机\" class=\"headerlink\" title=\"深入理解计算机\"></a>深入理解计算机</h2><ul>\n<li>任何计算问题，都可以通过增加一层”中间层”来解决。</li>\n<li>增加功能或扩展性时，一般是增加一层; 当进行性能优化重构时，一般时减少一层。</li>\n<li>开发的系统时，运维工具同时开始，减少重复的人工操作。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"lib或组件的引入\"><a href=\"#lib或组件的引入\" class=\"headerlink\" title=\"lib或组件的引入\"></a>lib或组件的引入</h2><ul>\n<li>接口使用</li>\n<li>原理，性能概况</li>\n<li>执行流程</li>\n<li>局限性</li>\n<li>改进与提升</li>\n</ul>\n<h2 id=\"错的经验\"><a href=\"#错的经验\" class=\"headerlink\" title=\"错的经验\"></a>错的经验</h2><ul>\n<li>目标制定方向错误。<br>人少打人多，胜率低。总希望能通过技术能力carry，实在希望渺茫。</li>\n<li>KPI模糊<br>KPI未公开，并与多方沟通一致</li>\n<li>执行计划弱<br>按月制定计划，不够细。也没有定期总结调整。</li>\n</ul>\n<h2 id=\"对的经验\"><a href=\"#对的经验\" class=\"headerlink\" title=\"对的经验\"></a>对的经验</h2><ul>\n<li>对标<br>对标同行，了解业内进展和自身情况，有助于建立信心。</li>\n<li>抓细节<br>细节是魔鬼。通过具体案例，了解细节，才能加深对新事物的理解，方可使用的得心应手。</li>\n<li>挖掘历史<br>通过收集历史信息，版本更替，来加深对事物的理解，方可做出预测。</li>\n</ul>\n<h2 id=\"深入理解计算机\"><a href=\"#深入理解计算机\" class=\"headerlink\" title=\"深入理解计算机\"></a>深入理解计算机</h2><ul>\n<li>任何计算问题，都可以通过增加一层”中间层”来解决。</li>\n<li>增加功能或扩展性时，一般是增加一层; 当进行性能优化重构时，一般时减少一层。</li>\n<li>开发的系统时，运维工具同时开始，减少重复的人工操作。</li>\n</ul>\n"},{"title":"monitor_control","date":"2018-06-15T09:59:28.000Z","_content":"","source":"_posts/2018-06-15-monitor-control.md","raw":"---\ntitle: monitor_control\ndate: 2018-06-15 17:59:28\ntags:\n---\n","slug":"monitor-control","published":1,"updated":"2018-06-15T09:59:28.158Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zt000q3l65uu1rnfn7","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"etcd","date":"2018-08-01T09:14:49.000Z","_content":"## cmd\n\n## client\n\n## lease\n\n## watch\n\n## mvcc\n\n## performance\n\n## referens\n[etcd使用经验总结](https://alexstocks.github.io/html/etcd.html)\n[etcd v3命令和API](https://blog.csdn.net/u010278923/article/details/71727682)\n","source":"_posts/2018-08-01-etcd.md","raw":"---\ntitle: etcd\ndate: 2018-08-01 17:14:49\ntags:\n---\n## cmd\n\n## client\n\n## lease\n\n## watch\n\n## mvcc\n\n## performance\n\n## referens\n[etcd使用经验总结](https://alexstocks.github.io/html/etcd.html)\n[etcd v3命令和API](https://blog.csdn.net/u010278923/article/details/71727682)\n","slug":"etcd","published":1,"updated":"2018-08-14T01:51:00.032Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjlohe0zu000r3l65at3wc24b","content":"<h2 id=\"cmd\"><a href=\"#cmd\" class=\"headerlink\" title=\"cmd\"></a>cmd</h2><h2 id=\"client\"><a href=\"#client\" class=\"headerlink\" title=\"client\"></a>client</h2><h2 id=\"lease\"><a href=\"#lease\" class=\"headerlink\" title=\"lease\"></a>lease</h2><h2 id=\"watch\"><a href=\"#watch\" class=\"headerlink\" title=\"watch\"></a>watch</h2><h2 id=\"mvcc\"><a href=\"#mvcc\" class=\"headerlink\" title=\"mvcc\"></a>mvcc</h2><h2 id=\"performance\"><a href=\"#performance\" class=\"headerlink\" title=\"performance\"></a>performance</h2><h2 id=\"referens\"><a href=\"#referens\" class=\"headerlink\" title=\"referens\"></a>referens</h2><p><a href=\"https://alexstocks.github.io/html/etcd.html\" target=\"_blank\" rel=\"noopener\">etcd使用经验总结</a><br><a href=\"https://blog.csdn.net/u010278923/article/details/71727682\" target=\"_blank\" rel=\"noopener\">etcd v3命令和API</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"cmd\"><a href=\"#cmd\" class=\"headerlink\" title=\"cmd\"></a>cmd</h2><h2 id=\"client\"><a href=\"#client\" class=\"headerlink\" title=\"client\"></a>client</h2><h2 id=\"lease\"><a href=\"#lease\" class=\"headerlink\" title=\"lease\"></a>lease</h2><h2 id=\"watch\"><a href=\"#watch\" class=\"headerlink\" title=\"watch\"></a>watch</h2><h2 id=\"mvcc\"><a href=\"#mvcc\" class=\"headerlink\" title=\"mvcc\"></a>mvcc</h2><h2 id=\"performance\"><a href=\"#performance\" class=\"headerlink\" title=\"performance\"></a>performance</h2><h2 id=\"referens\"><a href=\"#referens\" class=\"headerlink\" title=\"referens\"></a>referens</h2><p><a href=\"https://alexstocks.github.io/html/etcd.html\" target=\"_blank\" rel=\"noopener\">etcd使用经验总结</a><br><a href=\"https://blog.csdn.net/u010278923/article/details/71727682\" target=\"_blank\" rel=\"noopener\">etcd v3命令和API</a></p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjlohe0z400003l659ktqtof7","tag_id":"cjlohe0z900023l65q5gkw6fg","_id":"cjlohe0zi000b3l65g32j7ypd"},{"post_id":"cjlohe0z400003l659ktqtof7","tag_id":"cjlohe0zf00063l65zzx491d5","_id":"cjlohe0zk000d3l65l69ccuah"},{"post_id":"cjlohe0zi000a3l655ga5ednl","tag_id":"cjlohe0zf00063l65zzx491d5","_id":"cjlohe0zm000g3l65523636ri"},{"post_id":"cjlohe0z800013l65qkr5aruf","tag_id":"cjlohe0zh00093l657ws0wjoc","_id":"cjlohe0zp000j3l65wkxgi8sg"},{"post_id":"cjlohe0z800013l65qkr5aruf","tag_id":"cjlohe0zk000e3l652j68avz7","_id":"cjlohe0zq000l3l65tov3202d"},{"post_id":"cjlohe0zb00033l65gcyoq3gi","tag_id":"cjloi2rbe000s3l653hjpvtwu","_id":"cjloi2rbf000t3l65mvsx7s7g"}],"Tag":[{"name":"influxdb","_id":"cjlohe0z900023l65q5gkw6fg"},{"name":"tsdb","_id":"cjlohe0zf00063l65zzx491d5"},{"name":"tips","_id":"cjlohe0zh00093l657ws0wjoc"},{"name":"life","_id":"cjlohe0zk000e3l652j68avz7"},{"name":"influxdb sql tsm","_id":"cjloi2rbe000s3l653hjpvtwu"}]}}